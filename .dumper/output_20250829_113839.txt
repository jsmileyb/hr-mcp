Notes:
------
v0.2.0

Directory Structure:
-------------------
/ 
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ instructions/
â”‚       â””â”€â”€ mcp_instructions.instructions.md
â”œâ”€â”€ .pytest_cache/
â”‚   â”œâ”€â”€ v/
â”‚   â”‚   â””â”€â”€ cache/
â”‚   â”‚       â”œâ”€â”€ lastfailed
â”‚   â”‚       â””â”€â”€ nodeids
â”‚   â”œâ”€â”€ CACHEDIR.TAG
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ .source/
â”‚   â”œâ”€â”€ employee-handbook.pdf
â”‚   â””â”€â”€ State-Appendix.pdf
â”œâ”€â”€ .supporting_items/
â”‚   â”œâ”€â”€ .filters/
â”‚   â”‚   â”œâ”€â”€ filter_under_the_hood.py
â”‚   â”‚   â”œâ”€â”€ hr_thinking_filter.py
â”‚   â”‚   â”œâ”€â”€ hr_thinking_filter_02.py
â”‚   â”‚   â”œâ”€â”€ personalization_filter.py
â”‚   â”‚   â””â”€â”€ personalization_filter_logger_info.py
â”‚   â”œâ”€â”€ .instructions/
â”‚   â”‚   â””â”€â”€ 20250829_instructions.md
â”‚   â””â”€â”€ .old_scripts/
â”‚       â”œâ”€â”€ main_backup.py
â”‚       â””â”€â”€ main_clean.py
â”œâ”€â”€ auth/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ graph_auth.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ power_automate_auth.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ service_auth.cpython-312.pyc
â”‚   â”‚   â””â”€â”€ vp_auth.cpython-312.pyc
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ graph_auth.py
â”‚   â”œâ”€â”€ power_automate_auth.py
â”‚   â”œâ”€â”€ service_auth.py
â”‚   â””â”€â”€ vp_auth.py
â”œâ”€â”€ test_scripts/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ test_auth_imports.py
â”‚   â”‚   â””â”€â”€ test_get_service_token.cpython-312-pytest-8.4.1.pyc
â”‚   â”œâ”€â”€ simple_test_service_token.py
â”‚   â”œâ”€â”€ test_current_user_email.py
â”‚   â”œâ”€â”€ test_graph_and_pa.py
â”‚   â”œâ”€â”€ test_graph_token.py
â”‚   â”œâ”€â”€ test_service_token.py
â”‚   â””â”€â”€ test_vp_auth_live.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ api_models.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ config.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ datetime_utils.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ employment_data.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ environment.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ http_client.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ response_processor.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ security.cpython-312.pyc
â”‚   â”‚   â”œâ”€â”€ vacation_data.cpython-312.pyc
â”‚   â”‚   â””â”€â”€ vantagepoint.cpython-312.pyc
â”‚   â”œâ”€â”€ api_models.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ datetime_utils.py
â”‚   â”œâ”€â”€ employment_data.py
â”‚   â”œâ”€â”€ environment.py
â”‚   â”œâ”€â”€ http_client.py
â”‚   â”œâ”€â”€ response_processor.py
â”‚   â”œâ”€â”€ security.py
â”‚   â”œâ”€â”€ vacation_data.py
â”‚   â””â”€â”€ vantagepoint.py
â”œâ”€â”€ .env.sample
â”œâ”€â”€ .python-version
â”œâ”€â”€ compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ install_uv.ps1
â”œâ”€â”€ main.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ REFACTORING_SUMMARY.md
â””â”€â”€ requirements.txt

File Contents:
--------------
File: .\compose.yaml
--------------------------------------------------
Content of .\compose.yaml:
services:
  vantagepoint-server:
    build:
      context: .
    ports:
      - 5001:5001



File: .\install_uv.ps1
--------------------------------------------------
Content of .\install_uv.ps1:
# Check if uv is already installed
try {
    # Refresh PATH to include any recently installed programs
    $env:PATH = [System.Environment]::GetEnvironmentVariable("PATH","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("PATH","User")
    
    # Try to get uv version
    $uvVersion = uv --version 2>$null
    if ($uvVersion) {
        Write-Host "[SUCCESS] uv is already installed: $uvVersion" -ForegroundColor Green
        Write-Host "[INFO] No installation needed - you're all set!" -ForegroundColor Cyan
        exit 0
    }
} catch {
    # uv not found, continue with installation
}

Write-Host "[INFO] Installing uv..." -ForegroundColor Yellow

# Install uv using the official installer
try {
    powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
    
    # Refresh PATH after installation
    $env:PATH = [System.Environment]::GetEnvironmentVariable("PATH","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("PATH","User")
    
    # Verify installation
    $uvVersion = uv --version
    Write-Host "[SUCCESS] Successfully installed uv: $uvVersion" -ForegroundColor Green
    
} catch {
    Write-Host "[ERROR] Failed to install uv: $($_.Exception.Message)" -ForegroundColor Red
    exit 1
}

File: .\main.py
--------------------------------------------------
Content of .\main.py:
from typing import Optional
import os, json, logging, sys, uuid

import httpx

from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

from utils.config import TOOL_NAME
from utils.environment import (
    log_environment_config, 
    validate_required_env,
    get_owui_url,
    get_owui_jwt,
    get_hardcoded_file_id,
    get_debug_mode
)
from utils.api_models import AskReq, AskResp
from utils.employment_data import EmploymentResp, build_employment_payload
from utils.vacation_data import VacationResp
from utils.http_client import ensure_model, post_chat_completions
from utils.response_processor import normalize_owui_response
from auth import (
    get_service_token,
    get_current_user_email,
    get_graph_token_async,
    call_pa_workflow_async,
    get_vantagepoint_token
)
from utils.vantagepoint import get_vacation_days

load_dotenv()

# =========================
# App & Logging
# =========================
app = FastAPI(
    title="HR Handbook and Policy MCP for GIA",
    version="0.0.1",
    description="MCP Server to retrieve HR policies and employee information.",
)

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.DEBUG if get_debug_mode() else logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger(TOOL_NAME)

# =========================
# Config / HTTP client
# =========================
OWUI = get_owui_url()
JWT = get_owui_jwt()
HARDCODED_FILE_ID = get_hardcoded_file_id()

# Optional: map your requested model name to an OWUI-registered model id.
# Example: MODEL_ALIAS_JSON='{"gpt-5":"gpt-5o"}'
MODEL_ALIAS = {"gpt-5": "gpt-5"}  # or "gpt-5o" if that's the registered ID

# Shared async client (init on startup)
client: httpx.AsyncClient | None = None

# Log environment configuration
log_environment_config(logger)

# Validate required environment variables
validate_required_env()


@app.on_event("startup")
async def _startup():
    global client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    logger.info("HTTP client initialized for GIA at %s", OWUI)


@app.on_event("shutdown")
async def _shutdown():
    global client
    if client:
        await client.aclose()
        logger.info("HTTP client closed")


# =========================
# Routes
# =========================
@app.post("/ask-file", response_model=AskResp, summary="Ask HR policy questions using the Employee Handbook")
async def ask_file(req: AskReq = Body(...)):
    """
    Handbook-based HR questions. Use this when the user asks about PTO policy, benefits, time-off rules, or other HR procedures documented in the employee handbook.
    
    Ask HR policy questions against the Employee Handbook via GIA, with optional OpenAI post-processing.

    Returns: 
        A structured response containing the answer to the HR policy question, along with relevant sources from the Employee Handbook.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]

    q_preview = (req.question or "").replace("\n", " ")
    if len(q_preview) > 160:
        q_preview = q_preview[:160] + "â€¦"

    logger.debug(
        "ask_file[%s] incoming model=%s stream=%s q_preview=%r",
        rid,
        req.model,
        bool(req.stream),
        q_preview,
    )

    model_id = await ensure_model(client, req.model, JWT, MODEL_ALIAS)
    logger.debug("ask_file[%s] resolved_model=%s", rid, model_id)

    if not HARDCODED_FILE_ID and get_debug_mode():
        logger.warning(
            "ask_file[%s] HARDCODED_FILE_ID is not set; request may fail", rid
        )

    payload = {
        "model": model_id,
        "stream": bool(req.stream),
        "messages": [{"role": "user", "content": req.question}],
        "files": [{"id": HARDCODED_FILE_ID, "type": "file", "status": "processed"}],
    }
    logger.debug(
        f"~~~ payload: {payload} ~~~",
    )

    owui_resp = await post_chat_completions(client, payload)
    logger.debug(f"~~~ owui_resp: {owui_resp} ~~~")
    logger.debug(
        "ask_file[%s] received OWUI response keys=%s",
        rid,
        (
            list(owui_resp.keys())
            if isinstance(owui_resp, dict)
            else type(owui_resp).__name__
        ),
    )

    # Normalize OWUI output
    normalized_text, sources = normalize_owui_response(owui_resp)
    logger.debug(
        "ask_file[%s] normalized len=%d sources=%d",
        rid,
        len(normalized_text or ""),
        len(sources or []),
    )

    logger.debug("ask_file[%s] done", rid)
    logger.debug(f"This is the normalized_text: {normalized_text}")

    return {
        "normalized_text": normalized_text,
        "sources": sources,
        "instructions": (
            "Your response requires source mapping to the Employee Handbook and must include the page number(s) where the information was found. "
            f"Use {sources} to map page numbers to show employees where to find the information the link to the handbook is: https://gspnet4.sharepoint.com/sites/HR/Shared%20Documents/employee-handbook.pdf. "
            "DO NOT make up content - if you cannot find an answer, state the you cannot find the answer and refer the user to the Employee Handbook, their HRP, or contact hr@greshamsmith.com. "
        ),
    }


@app.post("/get-my-leadership", response_model=EmploymentResp, summary="Get my leadership & employment details")
async def ask_employment_details(req: AskReq = Body(...)):
    """
    Employee-specific leadership details. Use this when the user asks *who* their HRP, Director, MVP/EVP, or CLL is, or requests personal employment details like hire date, employee ID, nomination level/date, or length of service.

    Returns: 
        A structured response containing the employee's leadership details and relevant employment information.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_employment_details[%s] model=%s", rid, req.model)

    # 1) Get token (if your Flow requires it)
    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )

    # 3) Build structured, market-aware response
    payload = build_employment_payload(employee_details)
    return payload


@app.post("/get-my-vacation", response_model=VacationResp, summary="Get my vacation details")
async def ask_vacation_details(req: AskReq = Body(...)):
    """
    Employee-specific vacation details. Use this when the user asks about their vacation balance, upcoming time off, or related inquiries.

    Returns: 
        A structured response containing the employee's vacation details and relevant information.
    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_vacation_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )
    logger.debug(f"This is the employee details: {employee_details}")
    vp_token_response = await get_vantagepoint_token()
    if not vp_token_response:
        raise HTTPException(
            status_code=502, detail="Vantagepoint API token retrieval failed"
        )
    logger.debug(f"[GET Vantagepoint API Token: {vp_token_response}]")
    body = {
        "EEID": employee_details.get("EmployeeID")
    }
    vacation_details = await get_vacation_days(body, vp_token_response.get("access_token"))

    if not vacation_details:
        raise HTTPException(
            status_code=502, detail="Vantagepoint Stored Procedure returned no data"
        )
    
    linked_call = AskReq(
        question=f"What is my PTO accrual rate for {employee_details.get('YearsWithGreshamSmith')} and {employee_details.get('CLL')}",
        model=req.model,
        stream=True
    )
    
    return {
        "employee_id": vacation_details.get("employee_id"),
        "starting_balance": vacation_details.get("starting_balance"),
        "current_balance": vacation_details.get("current_balance"),
        "instructions": (
            "The return values are in hours - show the results in hours and days. Our standard work day is 8 hours. "
            "If no vacation balance is found, refer the user to their HRP or manager - do not offer to refer to the servicedesk@greshamsmith.com."
            f"Refer to the \"/ask-file\" endpoint for a breakdown on accrual details for individual employees using a company tenure using: {linked_call} "
            )
    }


File: .\README.md
--------------------------------------------------
Content of .\README.md:
# HR MCP â€” HR Handbook & Policy MCP for GIA

FastAPI service that answers HR policy questions and returns employee-specific details by integrating:

- GIA/OWUI for RAG over the Employee Handbook
- Microsoft Graph/Power Automate for employee metadata
- Vantagepoint for PTO balances

OpenAPI docs are available at `/docs` and `/redoc` when running locally.

## Features

- Ask HR policy questions with source/page citations: `POST /ask-file`
- Get leadership & employment summary (HRP, Director, MVP/EVP, CLL, tenure, etc.): `POST /get-my-leadership`
- Get your current vacation balance from Vantagepoint: `POST /get-my-vacation`
- One-call PTO answer (balance + handbook accrual explanation with citations): `POST /answer-my-pto`
- Robust model resolution against GIA `/api/models` (handles many payload shapes)
- Flexible handling of OWUI responses (JSON, SSE, NDJSON, or text)

## Requirements

- Python 3.10+
- Access to your GIA/OWUI instance and the Employee Handbook indexed there
- Access to Power Automate (Flow) endpoint used by your tenant
- Access to Vantagepoint and credentials to obtain an API token

## Project Structure

- `main.py` â€” FastAPI app and endpoints
- `auth/` â€” Vantagepoint auth helper (`get_vantagepoint_token`)
- `utils/` â€” Config helpers
- `test_scripts/` â€” Ad-hoc test scripts for local verification
- `requirements.txt` / `pyproject.toml` â€” dependencies
- `Dockerfile`, `compose.yaml` â€” containerization

## Configuration (.env)

Environment variables are loaded via `python-dotenv`.

Minimum required:

- `OWUI_JWT` â€” Bootstrap JWT used to exchange for a service token
- `GIA_URL` â€” Base URL of your GIA/OWUI gateway (e.g., https://gia.example.com)
- `HARDCODED_FILE_ID` â€” File id of the Employee Handbook in GIA
- `PA_URL` â€” Power Automate flow HTTPS endpoint (for employee metadata)
- `VP_BASE_URL` â€” Vantagepoint API base URL
- `VP_SP_GETVACATION` â€” Name of the Vantagepoint stored procedure used for PTO

Optional:

- `OPENAI_API_KEY` â€” If you use any post-processing with OpenAI
- `OPENAI_MODEL` â€” Defaults to `gpt-4o-mini`
- `DEBUG` â€” Set to `1`/`true` for verbose logs
- `GRAPH_TOKEN_URL`, `GRAPH_CLIENT_ID`, `GRAPH_SECRET` â€” If your Flow requires Entra ID token acquisition

Example `.env`:

```
GIA_URL=https://gia.example.com
OWUI_JWT=eyJhbGciOi...
HARDCODED_FILE_ID=handbook-file-id
PA_URL=https://prod-00.westus.logic.azure.com:443/workflows/.../triggers/manual/paths/invoke
VP_BASE_URL=https://vantagepoint.example.com
VP_SP_GETVACATION=HR_GetVacationBalances
DEBUG=1
```

## Install & Run (local)

1. Install dependencies

```bash
pip install -r requirements.txt
```

2. Start the API with Uvicorn (port 5001)

```bash
uvicorn "main:app" --host 0.0.0.0 --port 5001 --reload
```

Visit http://localhost:5001/docs

## Docker

Build and run the container:

```bash
docker build -t hr-mcp .
docker run --rm -p 5001:5001 --env-file .env hr-mcp
```

With Docker Compose (service name: `vantagepoint-server`):

```bash
docker compose up --build
```

The app will be available at http://localhost:5001

## API Summary

### POST /ask-file

Ask HR policy questions against the Employee Handbook in GIA.

- Body: `{ "question": "...", "model": "gpt-5", "stream": true }`
- Returns: `normalized_text`, `sources[]`, and `instructions` prompting citation of page numbers.

### POST /get-my-leadership

Returns leadership and employment summary for the authenticated user (via OWUI auth).

- Returns: `leadership{...}`, `summary{...}` (employee id, display name, email, CLL, tenure, etc.).

### POST /get-my-vacation

Returns current and starting PTO balances from Vantagepoint for the authenticated user.

- Returns: `employee_id`, `starting_balance`, `current_balance`, plus `instructions` to present in hours and days (8h/day).

### POST /answer-my-pto

Combines your PTO balance with a handbook-backed accrual explanation and citations.

- Returns: `vacation{...}`, `accrual_explanation`, `citations[]`, `used_tools`.

## Testing

Pytest is configured in `requirements.txt`.

```bash
pytest -q
```

## Troubleshooting

- 502 from GIA endpoints: verify `OWUI_JWT`, network access to `GIA_URL`, and that the Handbook file id exists and is processed.
- Empty PTO results: confirm Vantagepoint token retrieval and `VP_SP_GETVACATION` name.
- Power Automate errors: check `PA_URL` and, if needed, `GRAPH_*` credentials.

## License

This repo is made available for demonstration purposes only. No license is granted for reuse.


File: .\REFACTORING_SUMMARY.md
--------------------------------------------------
Content of .\REFACTORING_SUMMARY.md:
# HR-MCP Code Refactoring Summary

## Overview

This document summarizes the refactoring performed on the `main.py` file to improve code organization and maintainability by extracting supporting functions into the `utils` directory.

## Changes Made

### 1. Created New Utility Modules

#### `utils/security.py`

- **Function**: `mask_token(token, show_last=10)`
- **Purpose**: Mask sensitive tokens for logging purposes
- **Original location**: Inline function in main.py

#### `utils/datetime_utils.py`

- **Function**: `years_between(iso_date)`
- **Purpose**: Calculate years between an ISO date string and now
- **Original location**: `_years_between()` function in main.py

#### `utils/http_client.py`

- **Functions**:
  - `ensure_model(client, model_name, jwt, model_alias)`
  - `post_chat_completions(client, payload)`
- **Purpose**: HTTP client utilities for interacting with external APIs
- **Original location**: Helper functions in main.py

#### `utils/response_processor.py`

- **Function**: `normalize_owui_response(owui)`
- **Purpose**: Process and normalize API responses from OWUI
- **Original location**: Helper function in main.py

#### `utils/employment_data.py`

- **Models**: `LeadershipInfo`, `EmploymentSummary`, `EmploymentResp`
- **Function**: `build_employment_payload(raw)`
- **Purpose**: Data transformation utilities for employment and HR data
- **Original location**: Pydantic models and helper function in main.py

#### `utils/vacation_data.py`

- **Model**: `VacationResp`
- **Purpose**: Vacation data models
- **Original location**: Pydantic model in main.py

#### `utils/api_models.py`

- **Models**: `AskReq`, `AskResp`
- **Purpose**: API request and response models
- **Original location**: Pydantic models in main.py

#### `utils/environment.py`

- **Functions**:
  - `get_environment_config()`
  - `log_environment_config(logger)`
  - `validate_required_env()`
  - Various environment variable getters
- **Purpose**: Environment configuration and logging utilities
- **Original location**: Inline environment variable handling in main.py

### 2. Updated `main.py`

#### Removed Code:

- All Pydantic model definitions (moved to utils)
- Helper functions (`mask_token`, `ensure_model`, `post_chat_completions`, `_years_between`, `build_employment_payload`, `normalize_owui_response`)
- Inline environment variable handling and logging
- Unused imports

#### Added/Updated:

- Clean imports from utils modules
- Updated function calls to use imported utilities
- Simplified configuration section
- Maintained all original API endpoints and functionality

### 3. File Structure Before vs After

#### Before:

```
main.py (686 lines)
â”œâ”€â”€ Imports
â”œâ”€â”€ App setup
â”œâ”€â”€ Environment configuration
â”œâ”€â”€ Pydantic models
â”œâ”€â”€ Helper functions
â””â”€â”€ API routes
```

#### After:

```
main.py (243 lines)
â”œâ”€â”€ Imports
â”œâ”€â”€ App setup
â”œâ”€â”€ API routes

utils/
â”œâ”€â”€ api_models.py
â”œâ”€â”€ datetime_utils.py
â”œâ”€â”€ employment_data.py
â”œâ”€â”€ environment.py
â”œâ”€â”€ http_client.py
â”œâ”€â”€ response_processor.py
â”œâ”€â”€ security.py
â”œâ”€â”€ vacation_data.py
â””â”€â”€ (existing files)
```

## Benefits

1. **Improved Maintainability**: Code is organized into logical modules
2. **Better Reusability**: Utility functions can be reused across the application
3. **Enhanced Readability**: Main.py is now focused on API route definitions
4. **Easier Testing**: Individual utility functions can be tested in isolation
5. **Reduced File Size**: Main.py reduced from 686 to 243 lines (64% reduction)

## File Summary

- **Main.py**: Now contains only FastAPI app setup and route definitions
- **Utils directory**: Contains 9 utility modules with specialized functionality
- **Backwards Compatibility**: All API endpoints maintain the same interface
- **No Breaking Changes**: External consumers of the API are unaffected

## Validation

- All imports resolve correctly
- No lint errors or compilation issues
- Original functionality preserved
- Clean separation of concerns achieved


File: .\requirements.txt
--------------------------------------------------
Content of .\requirements.txt:
fastapi
uvicorn[standard]
pydantic
httpx
xmltodict
#requests

# FOR TESTING
pytest
pytest-asyncio

# UNUSED
# mcp[cli]>=1.9.4
# httpx



File: .github\instructions\mcp_instructions.instructions.md
--------------------------------------------------
Content of .github\instructions\mcp_instructions.instructions.md:
**All work will eventually connect to an Model Context Protocol (MCP) server. Keep that in mind.

Build all test scripts in the "test_scripts" directory
Build all auth scripts in the "auth" directory
Build all project scripts in the "project" directory
Build all utility/helper scripts in the "utils" directory

AUTH EXAMPLE FOR VANTAGEPOINT (payload will need to be encoded in the request):
```python
# Example of how to authenticate with VantagePoint API
import httpx
import json

url = "https://az-webui-01.global.gsp/api/v1/auths/api_key"

headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer TOKEN_HERE",
}

payload = {}  # Empty dict â†’ same as sending `{}` JSON

with httpx.Client() as client:
    response = client.post(url, headers=headers, json=payload)

print(response.text)




File: .pytest_cache\README.md
--------------------------------------------------
Content of .pytest_cache\README.md:
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.


File: .supporting_items\.filters\filter_under_the_hood.py
--------------------------------------------------
Content of .supporting_items\.filters\filter_under_the_hood.py:
# log_body_filter.py
from typing import Optional
from pydantic import BaseModel, Field
import logging
import json

LOGGER_NAME = "owui.filter.log_body"

def _setup_logger(level: str = "INFO") -> logging.Logger:
    logger = logging.getLogger(LOGGER_NAME)
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
        logger.addHandler(handler)
    logger.setLevel(getattr(logging, level.upper(), logging.INFO))
    return logger

class Filter:
    class Valves(BaseModel):
        LOG_LEVEL: str = Field(default="INFO", description="Logging level (DEBUG, INFO, WARNING, ERROR)")

    def __init__(self):
        self.valves = self.Valves()
        self.logger = _setup_logger(self.valves.LOG_LEVEL)

    # Minimal requirement: just log the request body we receive
    def inlet(
        self,
        body: dict,
        __user__: Optional[dict] = None,
        __event_emitter__=None,  # kept for compatibility; not used
    ) -> dict:
        try:
            self.logger.info("INLET body: %s", json.dumps(body, ensure_ascii=False))
        except Exception as e:
            # Fallback so logging never breaks the pipeline
            self.logger.warning("Failed to JSON-serialize inlet body (%s); raw=%r", e, body)
        return body

    # Optional: log post-LLM body too. Safe no-op otherwise.
    def outlet(
        self,
        body: dict,
        __user__: Optional[dict] = None,
        __event_emitter__=None,
    ) -> dict:
        try:
            self.logger.debug("OUTLET body: %s", json.dumps(body, ensure_ascii=False))
        except Exception as e:
            self.logger.warning("Failed to JSON-serialize outlet body (%s); raw=%r", e, body)
        return body

    # (Optional) If you enable streaming on your model, you can peek at chunks as they pass:
    # def stream(self, event: dict) -> dict:
    #     self.logger.debug("STREAM event keys: %s", list(event.keys()))
    #     return event


File: .supporting_items\.filters\hr_thinking_filter.py
--------------------------------------------------
Content of .supporting_items\.filters\hr_thinking_filter.py:
"""
title: GIA HR Assistant Thinking Indicator
author: Smiley Baltz
version: 0.1.0
description: Displays a fun "Thinking..." indicator while GIA HR Assistant is processing a request.

"""

import time
import asyncio
from typing import Any, Awaitable, Callable
from pydantic import BaseModel, Field
import random
import logging

# Get logger for this module
logger = logging.getLogger(__name__)


# Configure the logger
def setup_logging(log_level: str = "INFO") -> None:
    """
    Configure logging with the specified log level.
    Args:
        log_level (str): Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    """
    # Convert string to logging level constant
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)

    # Remove existing handlers to avoid duplicates
    if logger.handlers:
        logger.handlers.clear()

    # Create console handler with the specified level
    ch = logging.StreamHandler()
    ch.setLevel(numeric_level)

    # Create formatter
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    ch.setFormatter(formatter)

    # Add the handler to the logger
    logger.addHandler(ch)
    logger.setLevel(numeric_level)

    logger.debug("Logger initialized")
    logger.info(f"Echo Pipeline logger is ready (Level: {log_level})")


# Initialize logger with default level
setup_logging()


class Filter:
    class Valves(BaseModel):
        PRIORITY: int = Field(
            title="Priority",
            default=15,
            description="Priority for executing the filter",
        )
        LOG_LEVEL: str = Field(
            title="Logging Level",
            default="INFO",
            description="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
        )
        pass

    def __init__(self):
        self.start_time = None
        self.is_thinking = False
        self.responses = [
            # HR-flavored â€œthinkingâ€ lines
            "Consulting the Employee Handbookâ€¦ page mysteriously marked with a coffee ring.",
            "Running a quick policy checkâ€”because HR loves a good citation.",
            "Verifying PTO mathâ€¦ carry the beach, subtract the meetings.",
            "Herding policies into complianceâ€¦ please hold all confetti.",
            "Syncing with Payrollâ€™s good vibesâ€¦ and their spreadsheets.",
            "Counting PTO beansâ€¦ these ones taste like vacation.",
            "Checking job codes and Jedi codesâ€”both must align.",
            "Drafting a friendly memo to your time off balance.",
            "Phone-a-friend: the Handbook. It always answers (eventually).",
            "Doing the HR two-step: review, document, smile.",
            "Translating HR-ese to humanâ€”may involve snacks.",
            "Auditing time like a timesheet superhero (cape optional).",
            "Pulling your PTO ledger out of the â€˜Do Not Disturbâ€™ folder.",
            "Reconciling â€˜out of officeâ€™ with â€˜out of PTOâ€™ (plot twist pending).",
            "Double-checking accrualsâ€”because decimals have feelings too.",
            "Measuring twice, approving onceâ€”Handbook-approved craftsmanship.",
            "Paging Section 4.2: â€˜Thou shalt hydrate and log PTO.â€™",
            "Calling a brief stand-up with the policies. Theyâ€™reâ€¦ remarkably seated.",
            "Queueing the kindness protocol: clarify, confirm, celebrate.",
            "Polishing the compliance haloâ€”gotta keep it shiny.",
            "Aligning vacation dreams with timesheet realitiesâ€¦ negotiating peace.",
            "Loading the PTO piÃ±ataâ€”stand by for candy math.",
            "Stamping this with â€˜HR Friendlyâ€™ and a small smiley face.",
            "Checking for blackout dates and solar eclipsesâ€”both count sometimes.",
            "Turning pages faster than you can say â€˜work-life balance.â€™",
            "Matching your request with the magical accrual engine.",
            "Consulting the calendar oracleâ€¦ it prefers Mondays less.",
            "Plotting a route from policy to permissionâ€”no tolls.",
            "Running backgroundâ€¦ checks on background checks (just kidding).",
            "Spinning up the â€˜People Ops Optimizerâ€™ (â„¢ not pending).",
            "Writing a tiny kudos note in the margins of compliance.",
            "Counting holidays like theyâ€™re sprinklesâ€”pure joy, zero calories.",
            "Checking carryover rulesâ€”no PTO left behind.",
            "Confirming manager approvals with a wink and a timestamp.",
            "Balancing fairness, fun, and federal guidelinesâ€”easy peasy.",
            "Sweeping the handbook for gotchasâ€”only glitter found.",
            "Reconciling calendarsâ€¦ your beach vs. your boss.",
            "Filing this under â€˜Good Choicesâ€™ (subfolder: PTO).",
            "Clearing it with the spreadsheet guardianâ€”she nods.",
            "Tuning the empathy dial to â€˜perfectly supportiveâ€™.",
            "Proofreading policy punctuationâ€”Oxford comma says hi.",
            "Aligning benefits with benefits of napsâ€”research ongoing.",
            "HR is thinkingâ€¦ and yes, we brought snacks.",
            "Turning on the â€˜vacay radarâ€™â€”signal strong.",
            "Your balance and your plans are getting acquainted.",
            "Checking tenure perksâ€”loyalty has its lounge.",
            "Calibrating fairness matrixâ€¦ equitable and adorable.",
            "Cross-referencing accruals with the laws of physics.",
            "Consulting Captain Complianceâ€”cape confirms.",
        ]

        self.current_response_index = random.randint(0, len(self.responses) - 1)
        self.last_rotation_time = None  # Will be set when inlet is called
        logger.info(
            f"Thinking filter initialized with responses: {len(self.responses)}"
        )


    async def _update_thinking_status(
        self, __event_emitter__: Callable[[Any], Awaitable[None]]
    ):
        """
        Continuously update "Thinking..." status with elapsed time every second.
        """
        logger.debug("Starting thinking status updates")
        while self.is_thinking:
            elapsed_time = int(time.time() - self.start_time)
            current_time = time.time()

            # Initialize last_rotation_time if it's None
            if self.last_rotation_time is None:
                self.last_rotation_time = current_time
                logger.debug("Initialized last_rotation_time")

            # Rotate responses every 1 second (for testing)
            if current_time - self.last_rotation_time >= 3:
                logger.debug(
                    f"Time to rotate! Current index: {self.current_response_index}"
                )
                # Force a different index than the current one
                new_index = self.current_response_index
                while (
                    new_index == self.current_response_index and len(self.responses) > 1
                ):
                    new_index = random.randint(0, len(self.responses) - 1)
                    logger.debug(f"Trying new index: {new_index}")
                self.current_response_index = new_index
                self.last_rotation_time = current_time
                logger.debug(
                    f"Rotated to new response: {self.responses[self.current_response_index]}"
                )

            await __event_emitter__(
                {
                    "type": "status",
                    "data": {
                        "description": self.responses[self.current_response_index],
                        "done": False,
                    },
                }
            )
            await asyncio.sleep(0.5)  # Update more frequently

    async def inlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
    ) -> dict:
        """
        This hook is invoked at the start of processing to show a "Thinking..." indicator.
        """
        logger.debug("Inlet called - starting thinking indicator")
        self.start_time = time.time()
        self.is_thinking = True
        self.last_rotation_time = self.start_time

        # Start a background task to update the "Thinking..." status
        asyncio.create_task(self._update_thinking_status(__event_emitter__))

        return body

    async def outlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
    ) -> dict:
        """
        This hook is invoked after the processing to calculate the elapsed time and show it.
        """
        logger.debug("Outlet called - stopping thinking indicator")
        self.is_thinking = False
        end_time = time.time()
        elapsed_time = end_time - self.start_time

        # Emit final "done" status with total elapsed time
        await __event_emitter__(
            {
                "type": "status",
                "data": {
                    "description": f"Filed the paperwork in {int(elapsed_time)} seconds",
                    "done": True,
                },
            }
        )
        
        return body


File: .supporting_items\.filters\hr_thinking_filter_02.py
--------------------------------------------------
Content of .supporting_items\.filters\hr_thinking_filter_02.py:
"""
title: GIA HR Assistant Thinking Indicator
author: Smiley Baltz
version: 0.0.1
description: Playful HR "Thinking..." indicator with tone, task-type tracks, and first-name injection.
"""

import time
import asyncio
from typing import Any, Awaitable, Callable, Dict, List, Optional
from pydantic import BaseModel, Field
import random
import logging
import re

logger = logging.getLogger(__name__)

# -----------------------------
# Logging
# -----------------------------
def setup_logging(log_level: str = "INFO") -> None:
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)
    if logger.handlers:
        logger.handlers.clear()
    ch = logging.StreamHandler()
    ch.setLevel(numeric_level)
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    logger.setLevel(numeric_level)
    
# -----------------------------
# User redactor (place it here!)
# -----------------------------
def _redact_user(u: Optional[dict]) -> Optional[dict]:
    if not isinstance(u, dict):
        return None
    redact_keys = {"api_key", "oauth_sub", "profile_image_url"}
    return {k: ("<redacted>" if k in redact_keys else v) for k, v in u.items()}


# -----------------------------
# Filter
# -----------------------------
class Filter:
    class Valves(BaseModel):
        PRIORITY: int = Field(
            title="Priority",
            default=15,
            description="Priority for executing the filter",
        )
        LOG_LEVEL: str = Field(
            title="Logging Level",
            default="INFO",
            description="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
        )
        TONE: str = Field(
            title="Tone",
            default="Casual",
            description="Response tone: Casual | Professional | Super Cheerful",
        )
        ROTATE_SECONDS: float = Field(
            title="Rotate Seconds",
            default=3.5,
            description="How often to rotate the message (seconds)",
        )
        SHOW_PATIENCE_HINTS: bool = Field(
            title="Emphasize External System Patience",
            default=True,
            description="If true, inject patient messaging when external systems are involved",
        )

    # -----------------------------
    # Tone/Track Response Library
    # -----------------------------
    TRACKS: Dict[str, Dict[str, List[str]]] = {
        # PTO: time off, balances, accruals, holidays
        "pto": {
            "Casual": [
                "Hey {name}, counting those sweet, sweet accrualsâ€¦ carry the beach, subtract the meetings.",
                "Running PTO mathâ€”no PTO left behind. ðŸ–ï¸",
                "Checking blackout dates and solar eclipsesâ€¦ just in case.",
                "Reconciling â€˜out of officeâ€™ with â€˜out of PTOâ€™â€”plot twist pending.",
                "Paging your accrual engineâ€”it says you deserve sunscreen.",
            ],
            "Professional": [
                "Reviewing PTO accruals and carryover rules for you, {name}.",
                "Confirming balances, holidays, and any blackout dates.",
                "Cross-referencing tenure-based accruals and policy thresholds.",
                "Validating manager approvals and effective dates.",
                "Ensuring fairness and compliance across leave policies.",
            ],
            "Super Cheerful": [
                "ðŸŒž Hey {name}! Your vacation dreams are meeting their balance. Itâ€™s a love story!",
                "Loading the PTO piÃ±ataâ€”stand by for candy math!",
                "Sprinkling holidays like confettiâ€”pure joy, zero calories!",
                "Beach mode negotiating with calendar modeâ€¦ peace talks underway!",
                "Your accruals just high-fived HR. Cute.",
            ],
        },
        # Policy: handbook, guidelines, eligibility, compliance
        "policy": {
            "Casual": [
                "Consulting the Employee Handbookâ€”page mysteriously marked with a coffee ring.",
                "Doing the HR two-step: review, document, smile.",
                "Translating HR-ese to humanâ€”snacks may be involved.",
                "Double-checking decimalsâ€”policies have feelings too.",
                "Phone-a-friend: the Handbook. It always picks up. Eventually.",
            ],
            "Professional": [
                "Locating the relevant section of the Employee Handbook for you, {name}.",
                "Verifying eligibility, scope, and any regional exceptions.",
                "Citing the policy source with version and effective date.",
                "Reconciling policy text with current practiceâ€”consistency matters.",
                "Documenting interpretation and next steps for clarity.",
            ],
            "Super Cheerful": [
                "ðŸ“˜ Handbook huddle! Section {section} is warming up the spotlight. (Weâ€™ll find it, promise.)",
                "Captain Compliance just adjusted their cape. We got this!",
                "Bringing policies and plain English together like besties.",
                "Shining the policy haloâ€”sparkly AND compliant!",
                "Policy pit-stop completeâ€”clarity fuel topped off!",
            ],
        },
        # Payroll: pay periods, taxes, W-2, deductions
        "payroll": {
            "Casual": [
                "Syncing with Payrollâ€™s good vibesâ€¦ and their spreadsheets.",
                "Counting beans that officially countâ€”deductions, taxes, the works.",
                "Matching job codes and Jedi codesâ€”both must align.",
                "Asking the spreadsheet guardian for a blessing. She nods.",
                "Queuing the kindness protocol: clarify, confirm, celebrate.",
            ],
            "Professional": [
                "Reviewing pay period details and applicable deductions for you, {name}.",
                "Confirming tax withholdings and year-to-date values.",
                "Reconciling payroll records with HRIS for accuracy.",
                "Checking effective dates for compensation changes.",
                "Preparing a clean summary you can reference later.",
            ],
            "Super Cheerful": [
                "ðŸ’¸ Payroll party! Your numbers are lining up like champs.",
                "Polishing the compliance halo while the digits dance.",
                "Spreadsheets are doing jazz handsâ€”deductions included!",
                "Numbers confirmed, confetti standing by!",
                "Your pay info and HR are officially on speaking terms. Cute!",
            ],
        },
        # General fallback
        "general": {
            "Casual": [
                "HR is thinkingâ€¦ and yes, we brought snacks.",
                "Filing this under â€˜Good Choicesâ€™ (subfolder: PTO).",
                "Polishing the compliance haloâ€”gotta keep it shiny.",
                "Plotting a route from policy to permissionâ€”no tolls.",
                "Proofreading policy punctuationâ€”Oxford comma says hi.",
            ],
            "Professional": [
                "Reviewing your request and confirming relevant records, {name}.",
                "Reconciling data across HRIS and policy sources.",
                "Preparing a concise, documented response.",
                "Ensuring equitable and consistent application of policy.",
                "Finalizing details for accuracy and clarity.",
            ],
            "Super Cheerful": [
                "âœ¨ Spinning up the People Ops Optimizerâ€”results incoming!",
                "Your request is getting the VIP HR treatment.",
                "Compliance cape on, empathy dial set to â€˜perfectâ€™!",
                "Good news loadingâ€¦ kindness protocol engaged.",
                "Checklist checked. Twice. (Weâ€™re fancy.)",
            ],
        },
    }

    # Patient hints appended/rotated when externals are involved
    PATIENCE_HINTS: List[str] = [
        "Heads up: checking external systems can take a secâ€”real data > fast guesses.",
        "Still syncing with HRIS/Payrollâ€”slower than normal Q&A, but worth the accuracy.",
        "Verifying with live systems (balances, approvals, dates). Thanks for your patience!",
        "External checks runningâ€”coffee break optional, correctness mandatory.",
        "Almost thereâ€”policy meets platform, and platforms like to think.",
    ]

    def __init__(self):
        self.start_time = None
        self.is_thinking = False
        self.current_response_index = 0
        self.last_rotation_time = None
        self.valves = self.Valves()  # default valves until inlet replaces
        setup_logging(self.valves.LOG_LEVEL)

    # -----------------------------
    # Helpers
    # -----------------------------
    @staticmethod
    def _get_first_name(body: dict, user: Optional[dict] = None) -> str:
        """
        Prefer __user__ info (authoritative), then fall back to body fields.
        """
        # 1) __user__ takes precedence
        if isinstance(user, dict):
            # Try 'name' first (full name), fall back to username (rare)
            for key in ("name", "username"):
                val = user.get(key)
                if isinstance(val, str) and val.strip():
                    return val.strip().split()[0]
            # If there's a nested 'info' with a name-like thing
            if isinstance(user.get("info"), dict):
                for key in ("first_name", "given_name"):
                    val = user["info"].get(key)
                    if isinstance(val, str) and val.strip():
                        return val.strip().split()[0]

        # 2) Fall back to body-sourced locations
        candidates = [
            ("employee", "first_name"),
            ("employee", "name"),
            ("user", "first_name"),
            ("user", "name"),
            ("metadata", "employee_first_name"),
            ("metadata", "first_name"),
            ("context", "first_name"),
        ]
        for a, b in candidates:
            try:
                val = (body.get(a) or {}).get(b)
                if isinstance(val, str) and val.strip():
                    return val.strip().split()[0]
            except Exception:
                pass
        return "there"


    @staticmethod
    def _detect_task_track(body: dict) -> str:
        """
        Detect the task type from body.task.type if provided, otherwise fallback to keyword detection.
        """
        # Direct override if provided
        task_obj = body.get("task") or body.get("metadata") or {}
        task_type = None
        if isinstance(task_obj, dict):
            task_type = task_obj.get("type") or task_obj.get("task_type")

        if isinstance(task_type, str):
            t = task_type.strip().lower()
            if t in ["pto", "vacation", "leave", "holiday"]:
                return "pto"
            if t in ["policy", "handbook", "guideline"]:
                return "policy"
            if t in ["payroll", "pay", "compensation"]:
                return "payroll"
            if t in ["general", "other"]:
                return "general"

        # --- fallback keyword detection ---
        text_fields = []
        for k in ("query", "prompt", "text", "message"):
            v = body.get(k)
            if isinstance(v, str):
                text_fields.append(v)
        for scope in ("metadata", "context"):
            v = body.get(scope, {})
            for kk, vv in (v.items() if isinstance(v, dict) else []):
                if isinstance(vv, str):
                    text_fields.append(vv)

        hay = " ".join(text_fields).lower()

        # keywords
        pto_kw = ["pto", "vacation", "time off", "leave", "holiday", "accrual"]
        policy_kw = ["policy", "handbook", "guideline", "procedure", "benefit", "eligibility"]
        payroll_kw = ["payroll", "pay", "paystub", "w-2", "w2", "withholding", "deduction", "tax"]

        def has_any(words: List[str]) -> bool:
            return any(w in hay for w in words)

        if has_any(pto_kw):
            return "pto"
        if has_any(payroll_kw):
            return "payroll"
        if has_any(policy_kw):
            return "policy"
        return "general"


    @staticmethod
    def _externals_involved(body: dict) -> bool:
        """
        Only treat the task as 'external' if the upstream explicitly says so.

        Signals (in order of precedence):
          1) body.task.requires_external == True
          2) body.task.systems or body.task.endpoints is a non-empty list
          3) body.metadata.requires_external == True  (optional backstop)
        """
        task = body.get("task") if isinstance(body.get("task"), dict) else {}
        meta = body.get("metadata") if isinstance(body.get("metadata"), dict) else {}

        # 1) Primary explicit flag
        if isinstance(task.get("requires_external"), bool) and task["requires_external"]:
            return True

        # 2) Non-empty system lists also imply external checks
        for key in ("systems", "endpoints"):
            val = task.get(key)
            if isinstance(val, (list, tuple)) and len(val) > 0:
                return True

        # 3) Optional backstop if your pipeline prefers metadata
        if isinstance(meta.get("requires_external"), bool) and meta["requires_external"]:
            return True

        # Otherwise, we do NOT show patience hints
        return False


    @staticmethod
    def _normalize_tone(tone: str) -> str:
        t = (tone or "").strip().lower()
        if t.startswith("pro"):
            return "Professional"
        if t.startswith("super"):
            return "Super Cheerful"
        return "Casual"

    def _pick_message(self, track: str, tone: str, name: str) -> str:
        tone_key = self._normalize_tone(tone)
        library = self.TRACKS.get(track, self.TRACKS["general"]).get(tone_key, self.TRACKS["general"]["Casual"])
        msg = library[self.current_response_index % len(library)]
        return msg.format(name=name, section="4.2")

    # -----------------------------
    # Async updaters
    # -----------------------------
    async def _update_thinking_status(
        self,
        __event_emitter__: Callable[[Any], Awaitable[None]],
        body: dict,
        user: Optional[dict] = None,
    ):
        logger.debug("Starting thinking status updates")
        self.is_thinking = True
        self.start_time = time.time()
        self.last_rotation_time = self.start_time
        name = self._get_first_name(body, user)  # <<â€” now uses __user__ first
        track = self._detect_task_track(body)
        externals = self._externals_involved(body)
        tone = self.valves.TONE

        patience_index = 0
        patience_gap = 2  # rotate a patience note every other cycle if externals

        while self.is_thinking:
            now = time.time()
            if now - self.last_rotation_time >= float(self.valves.ROTATE_SECONDS):
                self.current_response_index += 1
                self.last_rotation_time = now

            base_line = self._pick_message(track, tone, name)

            if self.valves.SHOW_PATIENCE_HINTS and externals:
                if (self.current_response_index % patience_gap) == 0:
                    hint = self.PATIENCE_HINTS[patience_index % len(self.PATIENCE_HINTS)]
                    patience_index += 1
                    line = f"{base_line}  {hint}"
                else:
                    line = base_line
            else:
                line = base_line

            await __event_emitter__({"type": "status", "data": {"description": line, "done": False}})
            await asyncio.sleep(0.5)


    # -----------------------------
    # Open WebUI hooks
    # -----------------------------
    async def inlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
        __user__: Optional[dict] = None,
    ) -> dict:
        """
        Invoked at the start of processing to show a "Thinking..." indicator.
        """
        if "valves" in body and isinstance(body["valves"], dict):
            try:
                self.valves = self.Valves(**{**self.Valves().dict(), **body["valves"]})
            except Exception:
                self.valves = self.Valves()

        setup_logging(self.valves.LOG_LEVEL)

        # Safe, redacted log for debugging (wonâ€™t leak keys/images)
        logger.debug(f"Inlet called; user={_redact_user(__user__)}")

        # spin background updater
        asyncio.create_task(self._update_thinking_status(__event_emitter__, body, __user__))
        return body


    async def outlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
        __user__: Optional[dict] = None,
    ) -> dict:
        """
        Invoked after processing to stop the indicator and summarize duration.
        """
        logger.debug("Outlet called - stopping HR thinking indicator")
        self.is_thinking = False
        end_time = time.time()
        elapsed = int(max(0, end_time - (self.start_time or end_time)))

        await __event_emitter__(
            {
                "type": "status",
                "data": {
                    "description": f"Filed the paperwork in {elapsed} seconds",
                    "done": True,
                },
            }
        )
        return body



File: .supporting_items\.filters\personalization_filter.py
--------------------------------------------------
Content of .supporting_items\.filters\personalization_filter.py:
"""
title: GIA Personalization
version: 0.1.1
"""

import logging
import pytz
from datetime import datetime
from pydantic import BaseModel, Field
from typing import Optional

# Get a module-level logger
logger = logging.getLogger(__name__)
# Optional: basic config if your app doesn't set logging up elsewhere.
# Safe to remove if your framework already configures logging.
if not logging.getLogger().hasHandlers():
    logging.basicConfig(
        level=logging.DEBUG, format="%(asctime)s %(levelname)s [%(name)s] %(message)s"
    )


class Filter:
    class Valves(BaseModel):
        system_message: str = Field(
            default="""        
        <context>
        - You are chatting with {{USER_NAME}}.
        </context>

        Use personalized responses with this context when appropriate. 
        For example, when answering question from the user, you can say "I'm here to help you with that {{FIRST_NAME}}, or "That's in interesting point, {{FIRST_NAME}}.
        If asked to be more formal, you should respond with {{USER_NAME}}, or if the user asks for a name, you should respond with {{USER_NAME}}.

        """.replace(
                "\n", " "
            ).strip(),
            description="System Message",
        )

    def __init__(self):
        self.valves = self.Valves()

    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # Be defensive: __user__ might be None or missing "name"
        user_name = (__user__ or {}).get("name") or ""
        first_name = user_name.split(" ")[0] if user_name else ""

        # Debug info
        if len(body.get("messages", [])) > 1:
            logger.debug("Messages array length: %s", len(body["messages"]))
        logger.debug("%s user payload: %s", "^" * 25, __user__)
        logger.debug("Request body: %s", body)
        logger.debug("User name: %s", user_name)

        messages = body.get("messages", [])

        system_prompt = next(
            (message for message in messages if message.get("role") == "system"),
            None,
        )
        if system_prompt:
            template = system_prompt.get("content", "")
        else:
            logger.debug("No system message. Using fallback template.")
            template = self.valves.system_message

        # Personalize
        template = template.replace("{{USER_NAME}}", user_name or "Unknown")
        template = template.replace("{{FIRST_NAME}}", first_name or "Unknown")

        if system_prompt:
            system_prompt["content"] = template
        else:
            system_prompt = {"role": "system", "content": template}

        filtered_messages = [system_prompt] + [
            message for message in messages if message.get("role") != "system"
        ]
        body["messages"] = filtered_messages
        return body


File: .supporting_items\.filters\personalization_filter_logger_info.py
--------------------------------------------------
Content of .supporting_items\.filters\personalization_filter_logger_info.py:
"""
title: GIA Personalization
version: 0.1.1
"""

import logging
import pytz
from datetime import datetime
from pydantic import BaseModel, Field
from typing import Optional

# Get a module-level logger
logger = logging.getLogger(__name__)
# Optional: basic config if your app doesn't set logging up elsewhere.
# Safe to remove if your framework already configures logging.
if not logging.getLogger().hasHandlers():
    logging.basicConfig(
        level=logging.DEBUG, format="%(asctime)s %(levelname)s [%(name)s] %(message)s"
    )


class Filter:
    class Valves(BaseModel):
        system_message: str = Field(
            default="""        
        <context>
        - You are chatting with {{USER_NAME}}.
        </context>

        Use personalized responses with this context when appropriate. 
        For example, when answering question from the user, you can say "I'm here to help you with that {{FIRST_NAME}}, or "That's in interesting point, {{FIRST_NAME}}.
        If asked to be more formal, you should respond with {{USER_NAME}}, or if the user asks for a name, you should respond with {{USER_NAME}}.

        """.replace(
                "\n", " "
            ).strip(),
            description="System Message",
        )

    def __init__(self):
        self.valves = self.Valves()

    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # Be defensive: __user__ might be None or missing "name"
        user_name = (__user__ or {}).get("name") or ""
        first_name = user_name.split(" ")[0] if user_name else ""

        # Debug info
        if len(body.get("messages", [])) > 1:
            logger.info("Messages array length: %s", len(body["messages"]))
        logger.info("%s user payload: %s", "^" * 25, __user__)
        logger.info("Request body: %s", body)
        logger.info("User name: %s", user_name)

        messages = body.get("messages", [])

        system_prompt = next(
            (message for message in messages if message.get("role") == "system"),
            None,
        )
        if system_prompt:
            template = system_prompt.get("content", "")
        else:
            logger.info("No system message. Using fallback template.")
            template = self.valves.system_message

        # Personalize
        template = template.replace("{{USER_NAME}}", user_name or "Unknown")
        template = template.replace("{{FIRST_NAME}}", first_name or "Unknown")

        if system_prompt:
            system_prompt["content"] = template
        else:
            system_prompt = {"role": "system", "content": template}

        filtered_messages = [system_prompt] + [
            message for message in messages if message.get("role") != "system"
        ]
        body["messages"] = filtered_messages
        return body


File: .supporting_items\.instructions\20250829_instructions.md
--------------------------------------------------
Content of .supporting_items\.instructions\20250829_instructions.md:
# GIA (Genuine Ingenuity Assistant) â€” HR Policy Assistant Instructions

## Role & Behavior

Your name is **GIA (Genuine Ingenuity Assistant)**, and you are a helpful, knowledgeable, and professional AI assistant designed to support **Gresham Smith employees**. You provide accurate, concise, and context-aware information specifically focused on:

- HR policies and procedures
- Employee information (leadership structure, HR Partner (HRP) assignments, tenure, etc.)
- PTO and vacation balance details
- Supporting information from approved systems (Employee Handbook, Power Automate, Vantagepoint)

If a question falls outside your training or access scope, provide alternative support options, but do not invent content or references.

---

## AI Usage Compliance

You must strictly follow **Gresham Smith's AI usage guidelines** (established August 31, 2023). This assistant complies with the Governance Policy related to AI use. Employees can review the full policy here: **Gresham Smith AI Policy**.

---

## Scope & Capabilities

GIA integrates with multiple systems to provide employees with accurate answers:

- **Employee Handbook (via GIA/OWUI)** â€” HR policy questions with page/source citations.
- **Leadership & Employment Data (via Power Automate)** â€” HRP, Director, MVP/EVP, CLL, tenure, etc.
- **PTO Balances (via Vantagepoint)** â€” starting and current vacation balances.
- **Combined PTO Answer** â€” balance + handbook accrual explanation with citations.

### System Endpoints

- `POST /ask-file` â€” Ask HR policy questions (Handbook, with citations)
- `POST /get-my-leadership` â€” Leadership & employment summary
- `POST /get-my-vacation` â€” Current PTO balances
- `POST /answer-my-pto` â€” PTO balance + accrual explanation with citations

### Limitations

- You cannot create or export files (Word, Excel, PowerPoint, PDF). Politely decline such requests and direct users to SharePoint or their HRP.

---

## Boundaries

- Do not provide medical, legal, or financial advice beyond what is documented internally.
- Do not speculate on confidential, private, or unknown data.
- If unsure, respond with: _â€œIâ€™m not certain about that. Would you like me to help you find someone who can assist?â€_ and refer them to the **Gresham Smith Human Resources HR department**: [hr@greshamsmith.com](mailto:hr@greshamsmith.com)
- Summarize lengthy content but offer full documents or links when available.

---

## Source Verification & Citations

- Always cite real, verifiable sources when referencing policies, studies, or documents.
- Provide direct URLs, DOIs, or reputable references when available.
- Never fabricate citations.
- If unsure about a source, state the uncertainty clearly.
- If no authoritative source is available, explain this transparently.

---

## Tone & Style

- Use a **friendly, respectful, and supportive tone**.
- Adapt tone based on user style:

  - Casual: _â€œHey! Totally, hereâ€™s what you needâ€¦â€_
  - Formal: _â€œCertainly. Based on the provided policyâ€¦â€_

- Use **headers, bullet points, and formatting** for clarity.

---

## Memory & Context

- Maintain context across the conversation to improve efficiency.
- Ask clarifying questions if a request lacks detail.

---

## Confidentiality & Compliance

- Never share or infer confidential, proprietary, or restricted information without clear authorization.
- Log or flag conversations that may indicate potential misuse or policy violations per AI usage guidelines.


File: .supporting_items\.old_scripts\main_backup.py
--------------------------------------------------
Content of .supporting_items\.old_scripts\main_backup.py:
from typing import Optional
import os, json, logging, sys, uuid

import httpx

from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

from utils.config import TOOL_NAME
from utils.environment import (
    get_environment_config, 
    log_environment_config, 
    validate_required_env,
    get_owui_url,
    get_owui_jwt,
    get_hardcoded_file_id,
    get_debug_mode
)
from utils.api_models import AskReq, AskResp
from utils.employment_data import EmploymentResp, build_employment_payload
from utils.vacation_data import VacationResp
from utils.http_client import ensure_model, post_chat_completions
from utils.response_processor import normalize_owui_response
from auth import (
    get_service_token,
    get_current_user_email,
    get_graph_token_async,
    call_pa_workflow_async,
    get_vantagepoint_token
)
from utils.vantagepoint import get_vacation_days

load_dotenv()

# =========================
# App & Logging
# =========================
app = FastAPI(
    title="HR Handbook and Policy MCP for GIA",
    version="0.0.1",
    description="MCP Server to retrieve HR policies and employee information.",
)

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.DEBUG if get_debug_mode() else logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger(TOOL_NAME)

# =========================
# Config / HTTP client
# =========================
OWUI = get_owui_url()
JWT = get_owui_jwt()
HARDCODED_FILE_ID = get_hardcoded_file_id()
# Log environment configuration
log_environment_config(logger)

# Validate required environment variables
validate_required_env()

# Optional: map your requested model name to an OWUI-registered model id.
# Example: MODEL_ALIAS_JSON='{"gpt-5":"gpt-5o"}'
MODEL_ALIAS = {"gpt-5": "gpt-5"}  # or "gpt-5o" if thatâ€™s the registered ID

# Shared async client (init on startup)
client: httpx.AsyncClient | None = None


@app.on_event("startup")
async def _startup():
    global client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    logger.info("HTTP client initialized for GIA at %s", OWUI)


@app.on_event("shutdown")
async def _shutdown():
    global client
    if client:
        await client.aclose()
        logger.info("HTTP client closed")


# =========================
# Pydantic models
# =========================
class AskReq(BaseModel):
    question: str = Field(..., description="User question")
    model: str = Field(
        "gpt-5", description="Model id as registered in GIA (/api/models)"
    )
    stream: bool = Field(True, description="Use streamed responses (server-side)")


class AskResp(BaseModel):
    normalized_text: Optional[str] = None
    sources: Optional[list] = None
    instructions: Optional[str] = None


class LeadershipInfo(BaseModel):
    hrp_employee_id: Optional[str] = None
    hrp_name: Optional[str] = None
    hrp_email: Optional[str] = None
    director_id: Optional[str] = None
    director_name: Optional[str] = None
    director_email: Optional[str] = None
    mvp_id: Optional[str] = None
    mvp_name: Optional[str] = None
    mvp_email: Optional[str] = None
    evp_id: Optional[str] = None
    evp_name: Optional[str] = None
    evp_email: Optional[str] = None


class EmploymentSummary(BaseModel):
    employee_id: Optional[str] = None
    display_name: Optional[str] = None
    email: Optional[str] = None
    cll: Optional[str] = None
    market: Optional[str] = None
    department: Optional[str] = None
    nomination_level: Optional[str] = None
    nomination_date: Optional[str] = None
    latest_hire_date: Optional[str] = None
    original_hire_date: Optional[str] = None
    years_with_gresham_smith: Optional[float] = None
    los_years: Optional[float] = None


class EmploymentResp(BaseModel):
    # What weâ€™ll send back from /get-my-leadership (aka ask_employment_details)
    leadership: LeadershipInfo
    summary: EmploymentSummary


class VacationResp(BaseModel):
    employee_id: Optional[str] = None
    starting_balance: Optional[float] = None
    current_balance: Optional[float] = None
    instructions: Optional[str] = None

# =========================
# Routes
# =========================
@app.post("/ask-file",response_model=AskResp,summary="Ask HR policy questions using the Employee Handbook")
async def ask_file(req: AskReq = Body(...)):
    """
    Handbook-based HR questions. Use this when the user asks about PTO policy, benefits, time-off rules, or other HR procedures documented in the employee handbook.
    
    Ask HR policy questions against the Employee Handbook via GIA, with optional OpenAI post-processing.

    Returns: 
        A structured response containing the answer to the HR policy question, along with relevant sources from the Employee Handbook.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]

    q_preview = (req.question or "").replace("\n", " ")
    if len(q_preview) > 160:
        q_preview = q_preview[:160] + "â€¦"

    logger.debug(
        "ask_file[%s] incoming model=%s stream=%s q_preview=%r",
        rid,
        req.model,
        bool(req.stream),
        q_preview,
    )

    key = await get_service_token(client, JWT)
    model_id = await ensure_model(client, req.model, JWT, MODEL_ALIAS)
    logger.debug("ask_file[%s] resolved_model=%s", rid, model_id)

    if not HARDCODED_FILE_ID and get_debug_mode():
        logger.warning(
            "ask_file[%s] HARDCODED_FILE_ID is not set; request may fail", rid
        )

    payload = {
        "model": model_id,
        "stream": bool(req.stream),
        "messages": [{"role": "user", "content": req.question}],
        "files": [{"id": HARDCODED_FILE_ID, "type": "file", "status": "processed"}],
    }
    logger.debug(
        f"~~~ payload: {payload} ~~~",
    )

    owui_resp = await post_chat_completions(client, payload)
    logger.debug(f"~~~ owui_resp: {owui_resp} ~~~")
    logger.debug(
        "ask_file[%s] received OWUI response keys=%s",
        rid,
        (
            list(owui_resp.keys())
            if isinstance(owui_resp, dict)
            else type(owui_resp).__name__
        ),
    )

    # Normalize OWUI output
    normalized_text, sources = normalize_owui_response(owui_resp)
    logger.debug(
        "ask_file[%s] normalized len=%d sources=%d",
        rid,
        len(normalized_text or ""),
        len(sources or []),
    )

    logger.debug("ask_file[%s] done", rid)
    logger.debug(f"This is the normalized_text: {normalized_text}")

    return {
        "normalized_text": normalized_text,
        "sources": sources,
        "instructions": (
            "Your response requires source mapping to the Employee Handbook and must include the page number(s) where the information was found. "
            f"Use {sources} to map page numbers to show employees where to find the information the link to the handbook is: https://gspnet4.sharepoint.com/sites/HR/Shared%20Documents/employee-handbook.pdf. "
            "DO NOT make up content - if you cannot find an answer, state the you cannot find the answer and refer the user to the Employee Handbook, their HRP, or contact hr@greshamsmith.com. "
        ),
    }


@app.post("/get-my-leadership",response_model=EmploymentResp,summary="Get my leadership & employment details")
async def ask_employment_details(req: AskReq = Body(...)):
    """
    Employee-specific leadership details. Use this when the user asks *who* their HRP, Director, MVP/EVP, or CLL is, or requests personal employment details like hire date, employee ID, nomination level/date, or length of service.

    Returns: 
        A structured response containing the employee's leadership details and relevant employment information.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_employment_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    # 1) Get token (if your Flow requires it)
    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )

    # 3) Build structured, market-aware response
    payload = build_employment_payload(employee_details)
    return payload

@app.post("/get-my-vacation", response_model=VacationResp, summary="Get my vacation details")
async def ask_vacation_details(req: AskReq = Body(...)):
    """
    Employee-specific vacation details. Use this when the user asks about their vacation balance, upcoming time off, or related inquiries.

    Returns: 
        A structured response containing the employee's vacation details and relevant information.
    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_vacation_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )
    logger.debug(f"This is the employee details: {employee_details}")
    vp_token_response = await get_vantagepoint_token()
    if not vp_token_response:
        raise HTTPException(
            status_code=502, detail="Vantagepoint API token retrieval failed"
        )
    logger.debug(f"[GET Vantagepoint API Token: {vp_token_response}]")
    body = {
        "EEID": employee_details.get("EmployeeID")
    }
    vacation_details = await get_vacation_days(body, vp_token_response.get("access_token"))

    if not vacation_details:
        raise HTTPException(
            status_code=502, detail="Vantagepoint Stored Procedure returned no data"
        )
    
    linked_call = AskReq(
        question=f"What is my PTO accrual rate for {employee_details.get('YearsWithGreshamSmith')} and {employee_details.get('CLL')}",
        model=req.model,
        stream=True
    )
    
    return {
        "employee_id": vacation_details.get("employee_id"),
        "starting_balance": vacation_details.get("starting_balance"),
        "current_balance": vacation_details.get("current_balance"),
        "instructions": (
            "The return values are in hours - show the results in hours and days. Our standard work day is 8 hours. "
            "If no vacation balance is found, refer the user to their HRP or manager - do not offer to refer to the servicedesk@greshamsmith.com."
            f"Refer to the \"/ask-file\" endpoint for a breakdown on accrual details for individual employees using a company tenure using: {linked_call} "
            )
    }



File: .supporting_items\.old_scripts\main_clean.py
--------------------------------------------------
Content of .supporting_items\.old_scripts\main_clean.py:
from typing import Optional
import os, json, logging, sys, uuid

import httpx

from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

from utils.config import TOOL_NAME
from utils.environment import (
    log_environment_config, 
    validate_required_env,
    get_owui_url,
    get_owui_jwt,
    get_hardcoded_file_id,
    get_debug_mode
)
from utils.api_models import AskReq, AskResp
from utils.employment_data import EmploymentResp, build_employment_payload
from utils.vacation_data import VacationResp
from utils.http_client import ensure_model, post_chat_completions
from utils.response_processor import normalize_owui_response
from auth import (
    get_service_token,
    get_current_user_email,
    get_graph_token_async,
    call_pa_workflow_async,
    get_vantagepoint_token
)
from utils.vantagepoint import get_vacation_days

load_dotenv()

# =========================
# App & Logging
# =========================
app = FastAPI(
    title="HR Handbook and Policy MCP for GIA",
    version="0.0.1",
    description="MCP Server to retrieve HR policies and employee information.",
)

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.DEBUG if get_debug_mode() else logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger(TOOL_NAME)

# =========================
# Config / HTTP client
# =========================
OWUI = get_owui_url()
JWT = get_owui_jwt()
HARDCODED_FILE_ID = get_hardcoded_file_id()

# Optional: map your requested model name to an OWUI-registered model id.
# Example: MODEL_ALIAS_JSON='{"gpt-5":"gpt-5o"}'
MODEL_ALIAS = {"gpt-5": "gpt-5"}  # or "gpt-5o" if that's the registered ID

# Shared async client (init on startup)
client: httpx.AsyncClient | None = None

# Log environment configuration
log_environment_config(logger)

# Validate required environment variables
validate_required_env()


@app.on_event("startup")
async def _startup():
    global client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    logger.info("HTTP client initialized for GIA at %s", OWUI)


@app.on_event("shutdown")
async def _shutdown():
    global client
    if client:
        await client.aclose()
        logger.info("HTTP client closed")


# =========================
# Routes
# =========================
@app.post("/ask-file", response_model=AskResp, summary="Ask HR policy questions using the Employee Handbook")
async def ask_file(req: AskReq = Body(...)):
    """
    Handbook-based HR questions. Use this when the user asks about PTO policy, benefits, time-off rules, or other HR procedures documented in the employee handbook.
    
    Ask HR policy questions against the Employee Handbook via GIA, with optional OpenAI post-processing.

    Returns: 
        A structured response containing the answer to the HR policy question, along with relevant sources from the Employee Handbook.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]

    q_preview = (req.question or "").replace("\n", " ")
    if len(q_preview) > 160:
        q_preview = q_preview[:160] + "â€¦"

    logger.debug(
        "ask_file[%s] incoming model=%s stream=%s q_preview=%r",
        rid,
        req.model,
        bool(req.stream),
        q_preview,
    )

    key = await get_service_token(client, JWT)
    model_id = await ensure_model(client, req.model, JWT, MODEL_ALIAS)
    logger.debug("ask_file[%s] resolved_model=%s", rid, model_id)

    if not HARDCODED_FILE_ID and get_debug_mode():
        logger.warning(
            "ask_file[%s] HARDCODED_FILE_ID is not set; request may fail", rid
        )

    payload = {
        "model": model_id,
        "stream": bool(req.stream),
        "messages": [{"role": "user", "content": req.question}],
        "files": [{"id": HARDCODED_FILE_ID, "type": "file", "status": "processed"}],
    }
    logger.debug(
        f"~~~ payload: {payload} ~~~",
    )

    owui_resp = await post_chat_completions(client, payload)
    logger.debug(f"~~~ owui_resp: {owui_resp} ~~~")
    logger.debug(
        "ask_file[%s] received OWUI response keys=%s",
        rid,
        (
            list(owui_resp.keys())
            if isinstance(owui_resp, dict)
            else type(owui_resp).__name__
        ),
    )

    # Normalize OWUI output
    normalized_text, sources = normalize_owui_response(owui_resp)
    logger.debug(
        "ask_file[%s] normalized len=%d sources=%d",
        rid,
        len(normalized_text or ""),
        len(sources or []),
    )

    logger.debug("ask_file[%s] done", rid)
    logger.debug(f"This is the normalized_text: {normalized_text}")

    return {
        "normalized_text": normalized_text,
        "sources": sources,
        "instructions": (
            "Your response requires source mapping to the Employee Handbook and must include the page number(s) where the information was found. "
            f"Use {sources} to map page numbers to show employees where to find the information the link to the handbook is: https://gspnet4.sharepoint.com/sites/HR/Shared%20Documents/employee-handbook.pdf. "
            "DO NOT make up content - if you cannot find an answer, state the you cannot find the answer and refer the user to the Employee Handbook, their HRP, or contact hr@greshamsmith.com. "
        ),
    }


@app.post("/get-my-leadership", response_model=EmploymentResp, summary="Get my leadership & employment details")
async def ask_employment_details(req: AskReq = Body(...)):
    """
    Employee-specific leadership details. Use this when the user asks *who* their HRP, Director, MVP/EVP, or CLL is, or requests personal employment details like hire date, employee ID, nomination level/date, or length of service.

    Returns: 
        A structured response containing the employee's leadership details and relevant employment information.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_employment_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    # 1) Get token (if your Flow requires it)
    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )

    # 3) Build structured, market-aware response
    payload = build_employment_payload(employee_details)
    return payload


@app.post("/get-my-vacation", response_model=VacationResp, summary="Get my vacation details")
async def ask_vacation_details(req: AskReq = Body(...)):
    """
    Employee-specific vacation details. Use this when the user asks about their vacation balance, upcoming time off, or related inquiries.

    Returns: 
        A structured response containing the employee's vacation details and relevant information.
    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_vacation_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )
    logger.debug(f"This is the employee details: {employee_details}")
    vp_token_response = await get_vantagepoint_token()
    if not vp_token_response:
        raise HTTPException(
            status_code=502, detail="Vantagepoint API token retrieval failed"
        )
    logger.debug(f"[GET Vantagepoint API Token: {vp_token_response}]")
    body = {
        "EEID": employee_details.get("EmployeeID")
    }
    vacation_details = await get_vacation_days(body, vp_token_response.get("access_token"))

    if not vacation_details:
        raise HTTPException(
            status_code=502, detail="Vantagepoint Stored Procedure returned no data"
        )
    
    linked_call = AskReq(
        question=f"What is my PTO accrual rate for {employee_details.get('YearsWithGreshamSmith')} and {employee_details.get('CLL')}",
        model=req.model,
        stream=True
    )
    
    return {
        "employee_id": vacation_details.get("employee_id"),
        "starting_balance": vacation_details.get("starting_balance"),
        "current_balance": vacation_details.get("current_balance"),
        "instructions": (
            "The return values are in hours - show the results in hours and days. Our standard work day is 8 hours. "
            "If no vacation balance is found, refer the user to their HRP or manager - do not offer to refer to the servicedesk@greshamsmith.com."
            f"Refer to the \"/ask-file\" endpoint for a breakdown on accrual details for individual employees using a company tenure using: {linked_call} "
            )
    }


File: auth\graph_auth.py
--------------------------------------------------
Content of auth\graph_auth.py:
# Microsoft Graph Authentication Script
import httpx
import logging
import os
from typing import Optional
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

async def get_graph_token_async() -> Optional[str]:
    """
    Acquire Microsoft Graph token for client credentials flow.
    Returns access token or None if acquisition fails.
    """
    GRAPH_TOKEN_URL = os.environ.get("GRAPH_TOKEN_URL")
    GRAPH_CLIENT_ID = os.environ.get("GRAPH_CLIENT_ID")
    GRAPH_SECRET = os.environ.get("GRAPH_SECRET")
    
    if not all([GRAPH_TOKEN_URL, GRAPH_CLIENT_ID, GRAPH_SECRET]):
        logger.error("GRAPH_* env vars missing; cannot acquire token")
        return None

    data = {
        "grant_type": "client_credentials",
        "client_id": GRAPH_CLIENT_ID,
        "client_secret": GRAPH_SECRET,
        # Power Automate resource (Flow) â€“ confirm in your tenant; this often works:
        "scope": "https://service.flow.microsoft.com//.default",
    }

    try:
        async with httpx.AsyncClient(timeout=30) as ac:
            r = await ac.post(
                GRAPH_TOKEN_URL,
                data=data,
                headers={"Content-Type": "application/x-www-form-urlencoded"},
            )
        r.raise_for_status()
        token = r.json().get("access_token")
        if not token:
            logger.error("No access_token in token response: %s", r.text[:400])
        return token
    except httpx.HTTPError as e:
        logger.error("Failed to obtain token: %s", e)
        return None


File: auth\power_automate_auth.py
--------------------------------------------------
Content of auth\power_automate_auth.py:
# Power Automate Workflow Authentication and Communication Script
import httpx
import logging
import json
import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

async def call_pa_workflow_async(payload: Dict[str, Any], token: Optional[str]) -> Optional[Dict[str, Any]]:
    """
    Call Power Automate workflow with optional authentication token.
    
    Args:
        payload: JSON payload to send to the workflow
        token: Optional bearer token for authentication
        
    Returns:
        Response JSON dict or None if call fails
    """
    logger.debug(f"call_pa_workflow_async payload: {json.dumps(payload, indent=2)} token: {'set' if token else 'unset'}")
    
    PA_URL = os.environ.get("PA_URL")
    if not PA_URL:
        logger.error("PA_URL not set")
        return None

    headers = {"Content-Type": "application/json"}
    # If your Flow is protected by Entra ID / custom connector, include the bearer:
    if token:
        headers["Authorization"] = f"Bearer {token}"

    try:
        async with httpx.AsyncClient(timeout=60) as ac:
            # r = await ac.post(PA_URL, json=payload, headers=headers)
            r = await ac.post(PA_URL, json=payload)
        if r.status_code == 200:
            return r.json()
        logger.error("PA workflow call failed %s: %s", r.status_code, r.text[:400])
        return None
    except httpx.HTTPError as e:
        logger.error("PA workflow call error: %s", e)
        return None


File: auth\service_auth.py
--------------------------------------------------
Content of auth\service_auth.py:
# Service Authentication Script
import httpx
import logging
import os
from fastapi import HTTPException
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

async def get_service_token(client: httpx.AsyncClient, jwt: str) -> str:
    """
    Exchange the bootstrap JWT for a service/API token via /api/v1/auths/api_key.
    Caches the token. Returns (token, token_type).
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")

    # Your env expects GET here; Accept JSON; client already has Bearer <JWT>
    try:
        r = await client.get("/api/v1/auths/api_key", headers={"Accept": "application/json", "Authorization": f"Bearer {jwt}"})
        r.raise_for_status()
        payload = r.json()
    except httpx.HTTPError as e:
        logger.error("Failed to fetch /api/v1/auths/api_key: %s", e)
        raise HTTPException(status_code=502, detail=f"GIA /api/v1/auths/api_key error: {e}")
    except Exception as e:
        logger.exception("Non-HTTP error parsing /api/v1/auths/api_key")
        raise HTTPException(status_code=502, detail=f"Bad /api/v1/auths/api_key payload: {e}")

    # Token fields per your sample: { "token": "...", "token_type": "Bearer", "email": ... }
    key = payload.get("api_key")
    if not key:
        raise HTTPException(status_code=502, detail="No 'api_key' in /api/v1/auths/ response")

    logger.debug(f"Returned key is: {key}")
    return key


async def get_current_user_email(client: httpx.AsyncClient, key: str) -> str:
    """
    Fetch the authenticated user's email from OWUI /api/v1/auths/.
    Uses service token if available, otherwise the bootstrap JWT.
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")

    # We can also refresh service token here; but GET works with JWT in many setups.
    try:
        r = await client.get("/api/v1/auths/", headers={"Accept": "application/json", "Authorization": f"Bearer {key}"})
        r.raise_for_status()
        payload = r.json()
    except httpx.HTTPError as e:
        logger.error("Failed to fetch /api/v1/auths/: %s", e)
        raise HTTPException(status_code=502, detail=f"GIA /api/v1/auths/ error: {e}")

    if not payload:
        raise HTTPException(status_code=502, detail="No payload in /api/v1/auths/ response")
    return payload


File: auth\vp_auth.py
--------------------------------------------------
Content of auth\vp_auth.py:
# Vantagepoint Authentication Script
import httpx
from utils import config
from urllib.parse import urlencode
import os
from dotenv import load_dotenv

load_dotenv()

VP_BASE_URL = os.environ.get("VP_BASE_URL")
VP_USERNAME = os.environ.get("VP_USERNAME")
VP_PASSWORD = os.environ.get("VP_PASSWORD")
VP_DATABASE = os.environ.get("VP_DATABASE")
VP_CLIENT_ID = os.environ.get("VP_CLIENT_ID")
VP_CLIENT_SECRET = os.environ.get("VP_CLIENT_SECRET")

async def get_vantagepoint_token():
    """
    Authenticate with Vantagepoint API and return the access token response.
    """
    url = f"{VP_BASE_URL}/api/token"
    payload_dict = {
        "Username": VP_USERNAME,
        "Password": VP_PASSWORD,
        "grant_type": "password",
        "Integrated": "N",
        "database": VP_DATABASE,
        "Client_Id": VP_CLIENT_ID,
        "client_secret": VP_CLIENT_SECRET,
    }
    payload = urlencode(payload_dict)
    headers = {
        "Content-Type": "application/x-www-form-urlencoded"
    }
    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers, data=payload)
        response.raise_for_status()
        return response.json()

if __name__ == "__main__":
    import asyncio
    token_response = asyncio.run(get_vantagepoint_token())
    print(token_response)


File: auth\__init__.py
--------------------------------------------------
Content of auth\__init__.py:
# Authentication Module - Central import for all auth functions
"""
Authentication module providing centralized access to all authentication functions.
Import this module to access authentication functionality across the application.
"""

from .service_auth import get_service_token, get_current_user_email
from .graph_auth import get_graph_token_async
from .power_automate_auth import call_pa_workflow_async
from .vp_auth import get_vantagepoint_token

__all__ = [
    'get_service_token',
    'get_current_user_email', 
    'get_graph_token_async',
    'call_pa_workflow_async',
    'get_vantagepoint_token'
]


File: test_scripts\simple_test_service_token.py
--------------------------------------------------
Content of test_scripts\simple_test_service_token.py:
"""
Simple test script for the get_service_token function.
This is a basic test to verify the service token functionality.
"""
import sys
import os
import asyncio
import httpx
from dotenv import load_dotenv

# Add the parent directory to the path so we can import from main
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

load_dotenv()

async def test_service_token():
    """Simple test for get_service_token function"""
    from main import OWUI, JWT
    
    print("Testing get_service_token()...")
    print(f"GIA URL: {OWUI}")
    print(f"JWT available: {'Yes' if JWT else 'No'}")
    
    if not JWT:
        print("ERROR: OWUI_JWT environment variable is required!")
        return
    
    # Initialize HTTP client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    
    try:
        # Import and test the function
        from main import get_service_token
        
        # Set the global client (since the function expects it)
        import main
        main.client = client
        
        # Call the function
        service_token = await get_service_token()
        
        if service_token:
            print(f"âœ… Success! Service token obtained")
            print(f"Token length: {len(service_token)}")
            print(f"Token preview: {service_token[:30]}...")
            
            # Test the token with a simple API call
            headers = {"Accept": "application/json", "Authorization": f"Bearer {service_token}"}
            response = await client.get("/api/models", headers=headers)
            
            print(f"API test status: {response.status_code}")
            if response.status_code == 200:
                print("âœ… Service token works with API!")
                print(f"Response data: {response.json()}")
            else:
                print(f"âš ï¸  API call returned: {response.status_code}")
                
        else:
            print("âŒ Failed to obtain service token")
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await client.aclose()


if __name__ == "__main__":
    asyncio.run(test_service_token())


File: test_scripts\test_current_user_email.py
--------------------------------------------------
Content of test_scripts\test_current_user_email.py:
"""
Test script for the get_current_user_email function.
This script tests the live get_current_user_email function to identify and fix issues.
"""
import sys
import os
import asyncio
import httpx
from dotenv import load_dotenv

# Add the parent directory to the path so we can import from main
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Load environment variables
load_dotenv()

async def test_get_current_user_email():
    """Test the get_current_user_email function directly"""
    try:
        # Import the function and required variables
        from main import get_current_user_email, get_service_token, OWUI, JWT
        
        print("=" * 60)
        print("TESTING get_current_user_email() FUNCTION")
        print("=" * 60)
        
        # Check environment setup
        print(f"GIA_URL (OWUI): {OWUI}")
        print(f"JWT available: {'Yes' if JWT else 'No'}")
        print()
        
        if not JWT:
            print("âŒ ERROR: OWUI_JWT environment variable is not set!")
            return False
        
        # Initialize the HTTP client (mimicking the startup event)
        print("ðŸ”„ Initializing HTTP client...")
        import main
        main.client = httpx.AsyncClient(
            base_url=OWUI,
            headers={"Authorization": f"Bearer {JWT}"},
            timeout=60,
        )
        print("âœ… HTTP client initialized")
        
        print()
        print("ðŸ”„ First, getting service token...")
        
        # Get service token first
        service_token = await get_service_token()
        
        if service_token:
            print("âœ… Service token obtained")
            print(f"Service token preview: {service_token[:20] + '...' if len(service_token) > 20 else service_token}")
            
            print()
            print("ðŸ”„ Testing get_current_user_email() with service token...")
            
            # Test with service token
            try:
                email = await get_current_user_email(service_token)
                print(f"âœ… SUCCESS: Email obtained with service token: {email}")
            except Exception as e:
                print(f"âŒ FAILED with service token: {e}")
                print(f"Exception type: {type(e).__name__}")
                import traceback
                traceback.print_exc()
            
            print()
            print("ðŸ”„ Testing get_current_user_email() with JWT...")
            
            # Test with JWT
            try:
                email = await get_current_user_email(JWT)
                print(f"âœ… SUCCESS: Email obtained with JWT: {email}")
                return True
            except Exception as e:
                print(f"âŒ FAILED with JWT: {e}")
                print(f"Exception type: {type(e).__name__}")
                import traceback
                traceback.print_exc()
                return False
        else:
            print("âŒ Could not obtain service token")
            return False
            
    except Exception as e:
        print(f"âŒ ERROR during testing: {str(e)}")
        print(f"Exception type: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Clean up the client if we created it
        import main
        if hasattr(main, 'client') and main.client:
            await main.client.aclose()
            print("ðŸ§¹ HTTP client closed")


if __name__ == "__main__":
    # Run the async main function
    result = asyncio.run(test_get_current_user_email())
    
    # Exit with appropriate code
    sys.exit(0 if result else 1)


File: test_scripts\test_graph_and_pa.py
--------------------------------------------------
Content of test_scripts\test_graph_and_pa.py:
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from main import get_graph_token, call_pa_workflow

def main():
    email = "smiley.baltz@greshamsmith.com"
    print(f"Testing get_graph_token()...")
    token = get_graph_token()
    print(f"Token: {token}")
    if not token:
        print("Failed to obtain token. Aborting workflow call.")
        return
    print(f"Testing call_pa_workflow() with email: {email}")
    response = call_pa_workflow(email)
    print(f"Workflow response: {response}")

if __name__ == "__main__":
    main()


File: test_scripts\test_graph_token.py
--------------------------------------------------
Content of test_scripts\test_graph_token.py:
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from main import get_graph_token

def main():
    token = get_graph_token()
    if token:
        print(f"Access token: {token}")
    else:
        print("Failed to obtain token.")

if __name__ == "__main__":
    main()


File: test_scripts\test_service_token.py
--------------------------------------------------
Content of test_scripts\test_service_token.py:
"""
Test script for the get_service_token function.
This script tests the live get_service_token function to ensure it's returning actual data from the app instance.
"""
import sys
import os
import asyncio
import httpx
from dotenv import load_dotenv

# Add the parent directory to the path so we can import from main
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Load environment variables
load_dotenv()

async def test_get_service_token():
    """Test the get_service_token function directly"""
    try:
        # Import the function and required variables
        from main import get_service_token, OWUI, JWT
        
        print("=" * 60)
        print("TESTING get_service_token() FUNCTION")
        print("=" * 60)
        
        # Check environment setup
        print(f"GIA_URL (OWUI): {OWUI}")
        print(f"JWT available: {'Yes' if JWT else 'No'}")
        print(f"JWT preview: {JWT[:20] + '...' if JWT and len(JWT) > 20 else 'Not available'}")
        print()
        
        if not JWT:
            print("âŒ ERROR: OWUI_JWT environment variable is not set!")
            return False
        
        # Initialize the HTTP client (mimicking the startup event)
        print("ðŸ”„ Initializing HTTP client...")
        global client
        from main import client
        if client is None:
            client = httpx.AsyncClient(
                base_url=OWUI,
                headers={"Authorization": f"Bearer {JWT}"},
                timeout=60,
            )
            print("âœ… HTTP client initialized")
        else:
            print("âœ… HTTP client already initialized")
        
        print()
        print("ðŸ”„ Testing get_service_token()...")
        
        # Call the function
        service_token = await get_service_token()
        
        if service_token:
            print("âœ… SUCCESS: Service token obtained!")
            print(f"Token type: {type(service_token)}")
            print(f"Token length: {len(service_token) if isinstance(service_token, str) else 'N/A'}")
            print(f"Token preview: {service_token[:20] + '...' if isinstance(service_token, str) and len(service_token) > 20 else service_token}")
            
            # Validate token format (should be a non-empty string)
            if isinstance(service_token, str) and len(service_token) > 0:
                print("âœ… Token format validation: PASSED")
                return True
            else:
                print("âŒ Token format validation: FAILED - Token should be a non-empty string")
                return False
        else:
            print("âŒ FAILED: No service token obtained")
            return False
            
    except Exception as e:
        print(f"âŒ ERROR during testing: {str(e)}")
        print(f"Exception type: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Clean up the client if we created it
        if 'client' in locals() and client:
            await client.aclose()
            print("ðŸ§¹ HTTP client closed")


async def test_service_token_with_api_call():
    """Test using the service token to make an actual API call"""
    try:
        from main import get_service_token, OWUI, JWT
        
        print("\n" + "=" * 60)
        print("TESTING SERVICE TOKEN WITH API CALL")
        print("=" * 60)
        
        # Initialize client
        client = httpx.AsyncClient(
            base_url=OWUI,
            headers={"Authorization": f"Bearer {JWT}"},
            timeout=60,
        )
        
        # Get service token
        print("ðŸ”„ Getting service token...")
        service_token = await get_service_token()
        
        if not service_token:
            print("âŒ Could not obtain service token for API test")
            return False
        
        print("âœ… Service token obtained for API test")
        
        # Test the token by making an API call to /api/models
        print("ðŸ”„ Testing service token with /api/models endpoint...")
        
        try:
            headers = {
                "Accept": "application/json",
                "Authorization": f"Bearer {service_token}"
            }
            
            response = await client.get("/api/models", headers=headers)
            
            print(f"API Response Status: {response.status_code}")
            
            if response.status_code == 200:
                print("âœ… SUCCESS: Service token works with API!")
                
                # Try to parse the response
                try:
                    data = response.json()
                    print(f"Response type: {type(data)}")
                    if isinstance(data, list):
                        print(f"Number of models: {len(data)}")
                        if data:
                            print(f"First model preview: {data[0] if len(str(data[0])) < 100 else str(data[0])[:100] + '...'}")
                    elif isinstance(data, dict):
                        print(f"Response keys: {list(data.keys())}")
                    else:
                        print(f"Response preview: {str(data)[:200]}...")
                except Exception as parse_error:
                    print(f"âš ï¸  Could not parse JSON response: {parse_error}")
                    print(f"Raw response (first 200 chars): {response.text[:200]}...")
                
                return True
            else:
                print(f"âŒ API call failed with status {response.status_code}")
                print(f"Response: {response.text[:200]}...")
                return False
                
        except httpx.HTTPError as api_error:
            print(f"âŒ HTTP error during API call: {api_error}")
            return False
            
    except Exception as e:
        print(f"âŒ ERROR during API testing: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        if 'client' in locals() and client:
            await client.aclose()


async def main():
    """Main test function"""
    print("ðŸš€ Starting Service Token Test Suite")
    print(f"Timestamp: {asyncio.get_event_loop().time()}")
    print()
    
    # Test 1: Basic service token functionality
    test1_result = await test_get_service_token()
    
    # Test 2: Service token with actual API call
    test2_result = await test_service_token_with_api_call()
    
    # Summary
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    print(f"Test 1 (get_service_token): {'âœ… PASSED' if test1_result else 'âŒ FAILED'}")
    print(f"Test 2 (API call with token): {'âœ… PASSED' if test2_result else 'âŒ FAILED'}")
    
    overall_result = test1_result and test2_result
    print(f"\nOverall Result: {'âœ… ALL TESTS PASSED' if overall_result else 'âŒ SOME TESTS FAILED'}")
    
    return overall_result


if __name__ == "__main__":
    # Run the async main function
    result = asyncio.run(main())
    
    # Exit with appropriate code
    sys.exit(0 if result else 1)


File: test_scripts\test_vp_auth_live.py
--------------------------------------------------
Content of test_scripts\test_vp_auth_live.py:
#!/usr/bin/env python3
"""
Live test script for Vantagepoint Authentication
Tests the actual authentication endpoint with real credentials
"""

import sys
import os
from datetime import datetime
import json

# Add the parent directory to the path so we can import from auth module
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from auth.vp_auth import get_vantagepoint_token
import httpx

def test_vp_authentication():
    """
    Test the Vantagepoint authentication with live data
    """
    print("=" * 60)
    print("VANTAGEPOINT AUTHENTICATION LIVE TEST")
    print("=" * 60)
    print(f"Test started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Check if required environment variables are set
    required_env_vars = [
        "VP_BASE_URL",
        "VP_USERNAME", 
        "VP_PASSWORD",
        "VP_DATABASE",
        "VP_CLIENT_ID",
        "VP_CLIENT_SECRET"
    ]
    
    print("Checking environment variables...")
    missing_vars = []
    for var in required_env_vars:
        value = os.environ.get(var)
        if value:
            if var in ["VP_PASSWORD", "VP_CLIENT_SECRET"]:
                print(f"âœ“ {var}: {'*' * len(value)}")  # Mask sensitive data
            else:
                print(f"âœ“ {var}: {value}")
        else:
            missing_vars.append(var)
            print(f"âœ— {var}: NOT SET")
    
    if missing_vars:
        print(f"\nERROR: Missing required environment variables: {', '.join(missing_vars)}")
        print("Please set these variables in your .env file or environment.")
        return False
    
    print("\n" + "-" * 60)
    print("ATTEMPTING AUTHENTICATION...")
    print("-" * 60)
    
    try:
        # Call the authentication function
        token_response = get_vantagepoint_token()
        
        print("âœ“ Authentication successful!")
        print("\nResponse details:")
        print("-" * 30)
        
        # Pretty print the response
        for key, value in token_response.items():
            if key.lower() in ['access_token', 'refresh_token', 'token']:
                # Mask tokens for security but show first/last few characters
                if isinstance(value, str) and len(value) > 10:
                    masked_value = f"{value[:6]}...{value[-6:]}"
                    print(f"{key}: {masked_value}")
                else:
                    print(f"{key}: {'*' * 8}")
            else:
                print(f"{key}: {value}")
        
        # Additional token analysis
        print("\n" + "-" * 30)
        print("TOKEN ANALYSIS:")
        print("-" * 30)
        
        if 'access_token' in token_response:
            token = token_response['access_token']
            print(f"Access token length: {len(token)} characters")
            print(f"Token type: {type(token).__name__}")
        
        if 'expires_in' in token_response:
            expires_in = token_response['expires_in']
            print(f"Token expires in: {expires_in} seconds ({expires_in/3600:.1f} hours)")
        
        if 'token_type' in token_response:
            print(f"Token type: {token_response['token_type']}")
        
        return True
        
    except httpx.HTTPStatusError as e:
        print(f"âœ— HTTP Error occurred:")
        print(f"  Status Code: {e.response.status_code}")
        print(f"  Reason: {e.response.reason_phrase}")
        print(f"  URL: {e.request.url}")
        
        try:
            error_detail = e.response.json()
            print(f"  Error Detail: {json.dumps(error_detail, indent=2)}")
        except:
            print(f"  Response Text: {e.response.text}")
        
        return False
        
    except httpx.RequestError as e:
        print(f"âœ— Request Error occurred:")
        print(f"  Error: {str(e)}")
        print("  This could be a network connectivity issue or invalid URL.")
        return False
        
    except Exception as e:
        print(f"âœ— Unexpected error occurred:")
        print(f"  Error Type: {type(e).__name__}")
        print(f"  Error Message: {str(e)}")
        return False

def test_endpoint_connectivity():
    """
    Test basic connectivity to the Vantagepoint endpoint
    """
    print("\n" + "=" * 60)
    print("ENDPOINT CONNECTIVITY TEST")
    print("=" * 60)
    
    base_url = os.environ.get("VP_BASE_URL")
    if not base_url:
        print("âœ— VP_BASE_URL not set")
        return False
    
    print(f"Testing connectivity to: {base_url}")
    
    try:
        # Test basic connectivity
        response = httpx.get(base_url, timeout=10.0)
        print(f"âœ“ Endpoint is reachable")
        print(f"  Status Code: {response.status_code}")
        print(f"  Response Headers: {dict(response.headers)}")
        return True
        
    except httpx.TimeoutException:
        print(f"âœ— Timeout connecting to {base_url}")
        return False
        
    except httpx.RequestError as e:
        print(f"âœ— Connection error: {str(e)}")
        return False
        
    except Exception as e:
        print(f"âœ— Unexpected error: {str(e)}")
        return False

if __name__ == "__main__":
    print("Starting Vantagepoint Authentication Live Tests...")
    print()
    
    # Test endpoint connectivity first
    connectivity_ok = test_endpoint_connectivity()
    
    # Test authentication
    auth_ok = test_vp_authentication()
    
    # Summary
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    print(f"Endpoint Connectivity: {'âœ“ PASS' if connectivity_ok else 'âœ— FAIL'}")
    print(f"Authentication Test: {'âœ“ PASS' if auth_ok else 'âœ— FAIL'}")
    print(f"Overall Result: {'âœ“ ALL TESTS PASSED' if (connectivity_ok and auth_ok) else 'âœ— SOME TESTS FAILED'}")
    print(f"Test completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Exit with appropriate code
    sys.exit(0 if (connectivity_ok and auth_ok) else 1)


File: test_scripts\__pycache__\test_auth_imports.py
--------------------------------------------------
Content of test_scripts\__pycache__\test_auth_imports.py:
# Test script to verify auth module imports work correctly
"""
Simple test to verify that all authentication functions can be imported correctly
from the new auth module structure.
"""

try:
    # Test importing from the main auth module
    from auth import (
        get_service_token,
        get_current_user_email,
        get_graph_token_async,
        call_pa_workflow_async,
        get_vantagepoint_token
    )
    print("âœ… Successfully imported all auth functions from main auth module")
    
    # Test importing from individual modules
    from auth.service_auth import get_service_token, get_current_user_email
    from auth.graph_auth import get_graph_token_async
    from auth.power_automate_auth import call_pa_workflow_async
    from auth.vp_auth import get_vantagepoint_token
    print("âœ… Successfully imported all auth functions from individual modules")
    
    # Test importing vantagepoint utilities
    from utils.vantagepoint import get_vacation_days
    print("âœ… Successfully imported vantagepoint utilities")
    
    print("\nðŸŽ‰ All authentication modules are properly structured and importable!")
    
except ImportError as e:
    print(f"âŒ Import error: {e}")
except Exception as e:
    print(f"âŒ Unexpected error: {e}")


File: utils\api_models.py
--------------------------------------------------
Content of utils\api_models.py:
# Pydantic models for API requests and responses
from typing import Optional, List
from pydantic import BaseModel, Field


class AskReq(BaseModel):
    question: str = Field(..., description="User question")
    model: str = Field(
        "gpt-5", description="Model id as registered in GIA (/api/models)"
    )
    stream: bool = Field(True, description="Use streamed responses (server-side)")


class AskResp(BaseModel):
    normalized_text: Optional[str] = None
    sources: Optional[list] = None
    instructions: Optional[str] = None


File: utils\config.py
--------------------------------------------------
Content of utils\config.py:
# app/config.py

import os
from dotenv import load_dotenv

# Load .env once at startup
load_dotenv()

# Access values globally
TOOL_NAME = "GIA:HR POLICY"

File: utils\datetime_utils.py
--------------------------------------------------
Content of utils\datetime_utils.py:
# Date and time utilities
from typing import Optional
from datetime import datetime, timezone


def years_between(iso_date: Optional[str]) -> Optional[float]:
    """
    Calculate years between an ISO date string and now.
    
    Args:
        iso_date: ISO format date string
        
    Returns:
        Number of years as float, or None if date is invalid
    """
    if not iso_date:
        return None
    try:
        dt = datetime.fromisoformat(iso_date.replace("Z", "")).replace(
            tzinfo=timezone.utc
        )
        now = datetime.now(timezone.utc)
        return round((now - dt).days / 365.25, 2)
    except Exception:
        return None


File: utils\employment_data.py
--------------------------------------------------
Content of utils\employment_data.py:
# Data transformation utilities for employment and HR data
from typing import Optional
from pydantic import BaseModel, Field
from utils.datetime_utils import years_between


class LeadershipInfo(BaseModel):
    hrp_employee_id: Optional[str] = None
    hrp_name: Optional[str] = None
    hrp_email: Optional[str] = None
    director_id: Optional[str] = None
    director_name: Optional[str] = None
    director_email: Optional[str] = None
    mvp_id: Optional[str] = None
    mvp_name: Optional[str] = None
    mvp_email: Optional[str] = None
    evp_id: Optional[str] = None
    evp_name: Optional[str] = None
    evp_email: Optional[str] = None


class EmploymentSummary(BaseModel):
    employee_id: Optional[str] = None
    display_name: Optional[str] = None
    email: Optional[str] = None
    cll: Optional[str] = None
    market: Optional[str] = None
    department: Optional[str] = None
    nomination_level: Optional[str] = None
    nomination_date: Optional[str] = None
    latest_hire_date: Optional[str] = None
    original_hire_date: Optional[str] = None
    years_with_gresham_smith: Optional[float] = None
    los_years: Optional[float] = None


class EmploymentResp(BaseModel):
    # What we'll send back from /get-my-leadership (aka ask_employment_details)
    leadership: LeadershipInfo
    summary: EmploymentSummary


def build_employment_payload(raw: dict) -> EmploymentResp:
    """
    Build structured employment response from raw employee data.
    
    Args:
        raw: Raw employee data dictionary
        
    Returns:
        EmploymentResp: Structured employment response
    """
    # Pull top-level fields with safe defaults
    market = (raw or {}).get("Market")
    leadership = LeadershipInfo(
        hrp_employee_id=raw.get("hrpEmployeeID"),
        hrp_name=raw.get("hrpName"),
        hrp_email=raw.get("hrpEmail"),
        director_id=raw.get("Director_ID"),
        director_name=raw.get("Director_Name"),
        director_email=raw.get("Director_Email"),
        mvp_id=raw.get("MVP_ID"),
        mvp_name=raw.get("MVP_Name"),
        mvp_email=raw.get("MVP_Email"),
        evp_id=raw.get("EVP_ID"),
        evp_name=raw.get("EVP_Name"),
        evp_email=raw.get("EVP_Email"),
    )

    # If NOT Corporate Services, we care about MVP/EVP; otherwise Director is primary.
    if market and market.strip().lower() != "corporate services":
        # If MVP/EVP missing, keep Director as fallback (already populated)
        pass  # data is already in the model
    else:
        # Corporate Services â†’ Director path (already in model)
        pass

    summary = EmploymentSummary(
        employee_id=raw.get("EmployeeID"),
        display_name=raw.get("DisplayName"),
        email=raw.get("Email"),
        cll=raw.get("CLL"),
        market=market,
        department=raw.get("Department"),
        nomination_level=raw.get("NominationLevel"),
        nomination_date=raw.get("NominationDate"),
        latest_hire_date=raw.get("LatestHireDate"),
        original_hire_date=raw.get("OriginalHireDate"),
        years_with_gresham_smith=raw.get("YearsWithGreshamSmith"),
        los_years=years_between(raw.get("LatestHireDate")),
    )

    return EmploymentResp(leadership=leadership, summary=summary)


File: utils\environment.py
--------------------------------------------------
Content of utils\environment.py:
# Environment configuration and logging utilities
import os
import json
import logging
from typing import Dict, Any
from dotenv import load_dotenv
from utils.security import mask_token

load_dotenv()


def get_environment_config() -> Dict[str, Any]:
    """
    Load and return environment configuration with masked sensitive values for logging.
    
    Returns:
        Dict containing environment configuration
    """
    return {
        "GIA_URL": os.environ.get("GIA_URL", "http://localhost:8080"),
        "OWUI_JWT": mask_token(os.environ.get("OWUI_JWT"), 10),
        "HARDCODED_FILE_ID": os.environ.get("HARDCODED_FILE_ID"),
        "OPENAI_API_KEY": mask_token(os.environ.get("OPENAI_API_KEY"), 10),
        "OPENAI_MODEL": os.environ.get("OPENAI_MODEL", "gpt-4o-mini"),
        "DEBUG": os.environ.get("DEBUG", False),
        "VP_BASE_URL": os.environ.get("VP_BASE_URL"),
        "VP_SP_GETVACATION": os.environ.get("VP_SP_GETVACATION"),
    }


def log_environment_config(logger: logging.Logger) -> None:
    """
    Log environment configuration with masked sensitive values.
    
    Args:
        logger: Logger instance to use for logging
    """
    env_vars = get_environment_config()
    logger.debug("Loaded environment variables:\n%s", json.dumps(env_vars, indent=2))


def validate_required_env() -> None:
    """
    Validate that required environment variables are set.
    
    Raises:
        RuntimeError: If required environment variables are missing
    """
    jwt = os.environ.get("OWUI_JWT")
    if not jwt:
        raise RuntimeError("OWUI_JWT is required in the environment.")


# Environment variable getters
def get_owui_url() -> str:
    return os.environ.get("GIA_URL", "http://localhost:8080")


def get_owui_jwt() -> str:
    return os.environ.get("OWUI_JWT", "")


def get_hardcoded_file_id() -> str:
    return os.environ.get("HARDCODED_FILE_ID", "")


def get_openai_api_key() -> str:
    return os.environ.get("OPENAI_API_KEY", "")


def get_openai_model() -> str:
    return os.environ.get("OPENAI_MODEL", "gpt-4o-mini")


def get_debug_mode() -> bool:
    return bool(os.environ.get("DEBUG", False))


def get_vp_base_url() -> str:
    return os.environ.get("VP_BASE_URL", "")


def get_vp_procedure() -> str:
    return os.environ.get("VP_SP_GETVACATION", "")


File: utils\http_client.py
--------------------------------------------------
Content of utils\http_client.py:
# HTTP client utilities for interacting with external APIs
import json
import logging
from typing import Dict, Any
import httpx
from fastapi import HTTPException

logger = logging.getLogger(__name__)


async def ensure_model(client: httpx.AsyncClient, model_name: str, jwt: str, model_alias: Dict[str, str]) -> str:
    """
    Ensure OWUI recognizes the requested model. Applies MODEL_ALIAS mapping.
    Handles payloads that are:
      - ["gpt-5","gpt-4o", ...]
      - [{"id":"gpt-5"}, {"name":"gpt-4o"}, ...]
      - {"models":[...]} / {"data":[...]} wrappers
      - dict-of-dicts keyed by model id
      - or even a JSON string body (sigh)
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")

    desired = model_alias.get(model_name, model_name)

    # Make sure we have the service token
    from auth import get_service_token
    await get_service_token(client, jwt)

    desired = model_alias.get(model_name, model_name)
    try:
        r = await client.get("/api/models", headers={"Accept": "application/json", "Authorization": f"Bearer {jwt}"})
        r.raise_for_status()
        payload = r.json()
    except httpx.HTTPError as e:
        logger.error("Failed to fetch models from GIA: %s", e)
        raise HTTPException(status_code=502, detail=f"GIA /api/models error: {e}")
    except Exception as e:
        logger.exception("Non-HTTP error parsing /api/models")
        raise HTTPException(status_code=502, detail=f"Bad /api/models payload: {e}")

    models_set: set[str] = set()

    def add_from_list(items):
        for item in items:
            if isinstance(item, str):
                models_set.add(item)
            elif isinstance(item, dict):
                for k in ("id", "name", "model", "slug"):
                    v = item.get(k)
                    if isinstance(v, str):
                        models_set.add(v)

    if isinstance(payload, list):
        add_from_list(payload)
    elif isinstance(payload, dict):
        for key in ("models", "data", "items", "result"):
            v = payload.get(key)
            if isinstance(v, list):
                add_from_list(v)
        if not models_set:
            # dict-of-dicts: {"gpt-5": {...}, "gpt-4o": {...}}
            if payload and all(isinstance(v, (dict, str)) for v in payload.values()):
                models_set.update(map(str, payload.keys()))
        if not models_set:
            for k in ("id", "name", "model", "slug"):
                v = payload.get(k)
                if isinstance(v, str):
                    models_set.add(v)
    elif isinstance(payload, str):
        try:
            inner = json.loads(payload)
            if isinstance(inner, list):
                add_from_list(inner)
            elif isinstance(inner, dict):
                for key in ("models", "data", "items", "result"):
                    v = inner.get(key)
                    if isinstance(v, list):
                        add_from_list(v)
        except Exception:
            models_set.add(payload)

    if not models_set:
        logger.error("Unexpected /api/models payload: %r", payload)
        raise HTTPException(status_code=502, detail="Unexpected /api/models payload")

    if desired in models_set:
        return desired

    logger.warning(
        "Requested model '%s' not registered. Available: %s",
        desired,
        sorted(models_set),
    )
    raise HTTPException(
        status_code=400,
        detail={
            "error": f"Model '{model_name}' is not registered in GIA",
            "alias_applied": desired if desired != model_name else None,
            "available_models": sorted(models_set),
        },
    )


async def post_chat_completions(client: httpx.AsyncClient, payload: dict) -> dict:
    """
    Call OWUI /api/chat/completions and be tolerant:
    - JSON response
    - SSE-ish text/event-stream containing 'data: {json}'
    - NDJSON
    - text/plain with JSON as text
    - empty body (error)
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")
    try:
        # Ask politely for JSON
        r = await client.post(
            "/api/chat/completions",
            json=payload,
            headers={"Accept": "application/json"},
        )
        r.raise_for_status()
    except httpx.HTTPStatusError as e:
        logger.error(
            "OWUI /api/chat/completions %s: %s", e.response.status_code, e.response.text
        )
        raise HTTPException(status_code=e.response.status_code, detail=e.response.text)
    except httpx.HTTPError as e:
        logger.error("HTTP error calling /api/chat/completions: %s", e)
        raise HTTPException(status_code=502, detail=str(e))

    ctype = (r.headers.get("content-type") or "").lower()

    # JSON happy path
    if "application/json" in ctype:
        try:
            return r.json()
        except Exception as e:
            logger.error(
                "JSON parse failed despite application/json. Body (first 400): %r",
                r.text[:400],
            )
            raise HTTPException(
                status_code=502, detail=f"Bad JSON from /api/chat/completions: {e}"
            )

    # SSE stream
    if "text/event-stream" in ctype or "stream" in ctype:
        text = r.text
        events = []
        for line in text.splitlines():
            line = line.strip()
            if not line or not line.startswith("data:"):
                continue
            chunk = line[5:].strip()
            if chunk == "[DONE]":
                break
            try:
                events.append(json.loads(chunk))
            except Exception:
                logger.debug("Non-JSON SSE line: %r", line)
        if events:
            return {"stream": events}
        logger.error(
            "SSE response had no JSON 'data:' lines. First 400: %r", text[:400]
        )
        raise HTTPException(
            status_code=502, detail="Empty/invalid SSE body from /api/chat/completions"
        )

    # NDJSON
    if "ndjson" in ctype:
        objs = []
        for line in r.text.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                objs.append(json.loads(line))
            except Exception:
                logger.debug("Non-JSON NDJSON line: %r", line[:200])
        if objs:
            return {"ndjson": objs}
        raise HTTPException(
            status_code=502, detail="Invalid NDJSON body from /api/chat/completions"
        )

    # text/plain or unknown content-type
    txt = r.text.strip()
    if txt:
        try:
            return json.loads(txt)
        except Exception:
            logger.warning(
                "Non-JSON response (ctype=%s). Returning raw_text. First 400: %r",
                ctype,
                txt[:400],
            )
            return {"raw_text": txt, "content_type": ctype or None}

    logger.error("Empty 200 OK response from /api/chat/completions")
    raise HTTPException(
        status_code=502, detail="Empty response from /api/chat/completions"
    )


File: utils\response_processor.py
--------------------------------------------------
Content of utils\response_processor.py:
# Response processing utilities
import json
import logging
from typing import Tuple, List, Any

logger = logging.getLogger(__name__)


def normalize_owui_response(owui: dict) -> Tuple[str, list]:
    """
    Returns (assistant_text, sources_list)

    Supports:
      - {"stream": [ { "sources":[... ] }, {chunk}, {chunk}, ... ] }
      - {"raw_text": "..."} (fallback from post_chat_completions)
      - {"ndjson": [...]}  (rare)
      - Plain {"choices":[...]} JSON (if OWUI ever returns full JSON)
    """
    text_parts: list[str] = []
    sources: list[Any] = []

    if not isinstance(owui, dict):
        return (str(owui), sources)

    # 1) Stream shape
    if "stream" in owui and isinstance(owui["stream"], list):
        for i, item in enumerate(owui["stream"]):
            # first element often contains retrieval sources
            if i == 0 and isinstance(item, dict) and "sources" in item:
                try:
                    sources = item["sources"]
                except Exception:
                    sources = []
            # subsequent chunks with token deltas
            if isinstance(item, dict):
                for ch in item.get("choices", []):
                    delta = (ch or {}).get("delta") or {}
                    c = delta.get("content")
                    if isinstance(c, str):
                        text_parts.append(c)
        return ("".join(text_parts).strip(), sources)

    # 2) Raw text fallback
    if "raw_text" in owui:
        return (str(owui["raw_text"]).strip(), sources)

    # 3) NDJSON fallback
    if "ndjson" in owui and isinstance(owui["ndjson"], list):
        for line in owui["ndjson"]:
            if isinstance(line, dict):
                content = (((line.get("choices") or [{}])[0]).get("delta") or {}).get(
                    "content"
                )
                if isinstance(content, str):
                    text_parts.append(content)
        return ("".join(text_parts).strip(), sources)

    # 4) OpenAI-like full JSON (unlikely via OWUI, but harmless)
    if "choices" in owui:
        try:
            content = (((owui.get("choices") or [{}])[0]).get("message") or {}).get(
                "content"
            )
            if isinstance(content, str):
                return (content.strip(), sources)
        except Exception:
            pass

    logger.debug("Response from GIA: %r", owui)

    # last resort: stringify
    return (json.dumps(owui, ensure_ascii=False), sources)


File: utils\security.py
--------------------------------------------------
Content of utils\security.py:
# Security and token utilities
from typing import Optional


def mask_token(token: str | None, show_last: int = 10) -> str | None:
    """
    Mask sensitive tokens for logging purposes.
    
    Args:
        token: The token to mask
        show_last: Number of characters to show at the end
        
    Returns:
        Masked token string or None if token is None
    """
    if not token:
        return None
    if len(token) <= show_last:
        return "*" * len(token)
    return "*" * (len(token) - show_last) + token[-show_last:]


File: utils\vacation_data.py
--------------------------------------------------
Content of utils\vacation_data.py:
# Vacation data models and utilities
from typing import Optional
from pydantic import BaseModel


class VacationResp(BaseModel):
    employee_id: Optional[str] = None
    starting_balance: Optional[float] = None
    current_balance: Optional[float] = None
    instructions: Optional[str] = None


File: utils\vantagepoint.py
--------------------------------------------------
Content of utils\vantagepoint.py:
# Vantagepoint API utilities for vacation and employee data
import httpx
import logging
import json
import os
import re
import xmltodict
from typing import Optional, Dict, Any
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

VP_BASE_URL = os.environ.get("VP_BASE_URL")
PROCEDURE = os.environ.get("VP_SP_GETVACATION")

async def get_vacation_days(payload: Dict[str, Any], token: Optional[str]) -> Optional[Dict[str, Any]]:
    """
    Get vacation days for a specific employee using the Vantagepoint API.
    
    Args:
        payload (dict): Request payload containing employee information
        token (str): Access token for Vantagepoint API
        
    Returns:
        dict: Parsed vacation data or None if the API call fails
        
    Raises:
        httpx.HTTPError: If the API call fails
    """
    access_token = token
    
    url = f"{VP_BASE_URL}/api/Utilities/InvokeCustom/{PROCEDURE}"
    
    logger.debug(f"[GET /get_vacation_days] Request URL: {url}")
    logger.debug(f"[GET /get_vacation_days] Payload: {payload}")
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Accept": "application/xml",
        "Content-Type": "application/json"
    }
    
    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers, json=payload)
        response.raise_for_status()
    
    xml = response.text
    # Remove leading/trailing quotes if present
    xml = xml.strip()
    if xml.startswith('"') and xml.endswith('"'):
        xml = xml[1:-1]
    
    # Handle escaped characters - decode them properly
    xml = xml.encode().decode('unicode_escape')
    
    # Remove the schema block
    xml = re.sub(r'<xs:schema.*?</xs:schema>', '', xml, flags=re.DOTALL)
    # Remove empty <Table></Table> elements
    xml = re.sub(r'<Table>\s*</Table>', '', xml, flags=re.DOTALL)
    # Remove any control characters (non-printable)
    xml = re.sub(r'[^\x09\x0A\x0D\x20-\x7E]+', '', xml)
    # Strip leading/trailing whitespace again
    xml = xml.strip()
    
    logger.debug(f"[GET /get_vacation_days] Cleaned XML: {xml[:500]}...")  # Log first 500 chars for brevity
    
    # Parse the XML to dict
    parsed_xml = xmltodict.parse(xml)
    
    # Extract vacation balance data and clean up field names
    try:
        # Navigate to the Table data
        new_dataset = parsed_xml.get('NewDataSet', {})
        table_data = new_dataset.get('Table', {})
        
        # Extract and clean up the vacation data
        vacation_data = {
            "employee_id": table_data.get('Employee'),
            "starting_balance": float(table_data.get('Starting_x0020_Balance', 0)) if table_data.get('Starting_x0020_Balance') else None,
            "current_balance": float(table_data.get('Current_x0020_Balance', 0)) if table_data.get('Current_x0020_Balance') else None
        }
        
        logger.debug(f"Extracted vacation data: {vacation_data}")
        return vacation_data
        
    except Exception as e:
        logger.error(f"Error parsing vacation XML data: {e}")
        logger.debug(f"Parsed XML structure: {parsed_xml}")
        # Return the raw parsed XML as fallback
        return parsed_xml


