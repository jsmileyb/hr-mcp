Notes:
------
v0.2.0

Directory Structure:
-------------------
/ 
├── .github/
│   └── instructions/
│       └── mcp_instructions.instructions.md
├── .pytest_cache/
│   ├── v/
│   │   └── cache/
│   │       ├── lastfailed
│   │       └── nodeids
│   ├── CACHEDIR.TAG
│   └── README.md
├── .source/
│   ├── employee-handbook.pdf
│   └── State-Appendix.pdf
├── .supporting_items/
│   ├── .filters/
│   │   ├── filter_under_the_hood.py
│   │   ├── hr_thinking_filter.py
│   │   ├── hr_thinking_filter_02.py
│   │   ├── personalization_filter.py
│   │   └── personalization_filter_logger_info.py
│   ├── .instructions/
│   │   └── 20250829_instructions.md
│   └── .old_scripts/
│       ├── main_backup.py
│       └── main_clean.py
├── auth/
│   ├── __pycache__/
│   │   ├── __init__.cpython-312.pyc
│   │   ├── graph_auth.cpython-312.pyc
│   │   ├── power_automate_auth.cpython-312.pyc
│   │   ├── service_auth.cpython-312.pyc
│   │   └── vp_auth.cpython-312.pyc
│   ├── __init__.py
│   ├── graph_auth.py
│   ├── power_automate_auth.py
│   ├── service_auth.py
│   └── vp_auth.py
├── test_scripts/
│   ├── __pycache__/
│   │   ├── test_auth_imports.py
│   │   └── test_get_service_token.cpython-312-pytest-8.4.1.pyc
│   ├── simple_test_service_token.py
│   ├── test_current_user_email.py
│   ├── test_graph_and_pa.py
│   ├── test_graph_token.py
│   ├── test_service_token.py
│   └── test_vp_auth_live.py
├── utils/
│   ├── __pycache__/
│   │   ├── api_models.cpython-312.pyc
│   │   ├── config.cpython-312.pyc
│   │   ├── datetime_utils.cpython-312.pyc
│   │   ├── employment_data.cpython-312.pyc
│   │   ├── environment.cpython-312.pyc
│   │   ├── http_client.cpython-312.pyc
│   │   ├── response_processor.cpython-312.pyc
│   │   ├── security.cpython-312.pyc
│   │   ├── vacation_data.cpython-312.pyc
│   │   └── vantagepoint.cpython-312.pyc
│   ├── api_models.py
│   ├── config.py
│   ├── datetime_utils.py
│   ├── employment_data.py
│   ├── environment.py
│   ├── http_client.py
│   ├── response_processor.py
│   ├── security.py
│   ├── vacation_data.py
│   └── vantagepoint.py
├── .env.sample
├── .python-version
├── compose.yaml
├── Dockerfile
├── install_uv.ps1
├── main.py
├── pyproject.toml
├── README.md
├── REFACTORING_SUMMARY.md
└── requirements.txt

File Contents:
--------------
File: .\compose.yaml
--------------------------------------------------
Content of .\compose.yaml:
services:
  vantagepoint-server:
    build:
      context: .
    ports:
      - 5001:5001



File: .\install_uv.ps1
--------------------------------------------------
Content of .\install_uv.ps1:
# Check if uv is already installed
try {
    # Refresh PATH to include any recently installed programs
    $env:PATH = [System.Environment]::GetEnvironmentVariable("PATH","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("PATH","User")
    
    # Try to get uv version
    $uvVersion = uv --version 2>$null
    if ($uvVersion) {
        Write-Host "[SUCCESS] uv is already installed: $uvVersion" -ForegroundColor Green
        Write-Host "[INFO] No installation needed - you're all set!" -ForegroundColor Cyan
        exit 0
    }
} catch {
    # uv not found, continue with installation
}

Write-Host "[INFO] Installing uv..." -ForegroundColor Yellow

# Install uv using the official installer
try {
    powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
    
    # Refresh PATH after installation
    $env:PATH = [System.Environment]::GetEnvironmentVariable("PATH","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("PATH","User")
    
    # Verify installation
    $uvVersion = uv --version
    Write-Host "[SUCCESS] Successfully installed uv: $uvVersion" -ForegroundColor Green
    
} catch {
    Write-Host "[ERROR] Failed to install uv: $($_.Exception.Message)" -ForegroundColor Red
    exit 1
}

File: .\main.py
--------------------------------------------------
Content of .\main.py:
from typing import Optional
import os, json, logging, sys, uuid

import httpx

from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

from utils.config import TOOL_NAME
from utils.environment import (
    log_environment_config, 
    validate_required_env,
    get_owui_url,
    get_owui_jwt,
    get_hardcoded_file_id,
    get_debug_mode
)
from utils.api_models import AskReq, AskResp
from utils.employment_data import EmploymentResp, build_employment_payload
from utils.vacation_data import VacationResp
from utils.http_client import ensure_model, post_chat_completions
from utils.response_processor import normalize_owui_response
from auth import (
    get_service_token,
    get_current_user_email,
    get_graph_token_async,
    call_pa_workflow_async,
    get_vantagepoint_token
)
from utils.vantagepoint import get_vacation_days

load_dotenv()

# =========================
# App & Logging
# =========================
app = FastAPI(
    title="HR Handbook and Policy MCP for GIA",
    version="0.0.1",
    description="MCP Server to retrieve HR policies and employee information.",
)

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.DEBUG if get_debug_mode() else logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger(TOOL_NAME)

# =========================
# Config / HTTP client
# =========================
OWUI = get_owui_url()
JWT = get_owui_jwt()
HARDCODED_FILE_ID = get_hardcoded_file_id()

# Optional: map your requested model name to an OWUI-registered model id.
# Example: MODEL_ALIAS_JSON='{"gpt-5":"gpt-5o"}'
MODEL_ALIAS = {"gpt-5": "gpt-5"}  # or "gpt-5o" if that's the registered ID

# Shared async client (init on startup)
client: httpx.AsyncClient | None = None

# Log environment configuration
log_environment_config(logger)

# Validate required environment variables
validate_required_env()


@app.on_event("startup")
async def _startup():
    global client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    logger.info("HTTP client initialized for GIA at %s", OWUI)


@app.on_event("shutdown")
async def _shutdown():
    global client
    if client:
        await client.aclose()
        logger.info("HTTP client closed")


# =========================
# Routes
# =========================
@app.post("/ask-file", response_model=AskResp, summary="Ask HR policy questions using the Employee Handbook")
async def ask_file(req: AskReq = Body(...)):
    """
    Handbook-based HR questions. Use this when the user asks about PTO policy, benefits, time-off rules, or other HR procedures documented in the employee handbook.
    
    Ask HR policy questions against the Employee Handbook via GIA, with optional OpenAI post-processing.

    Returns: 
        A structured response containing the answer to the HR policy question, along with relevant sources from the Employee Handbook.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]

    q_preview = (req.question or "").replace("\n", " ")
    if len(q_preview) > 160:
        q_preview = q_preview[:160] + "…"

    logger.debug(
        "ask_file[%s] incoming model=%s stream=%s q_preview=%r",
        rid,
        req.model,
        bool(req.stream),
        q_preview,
    )

    model_id = await ensure_model(client, req.model, JWT, MODEL_ALIAS)
    logger.debug("ask_file[%s] resolved_model=%s", rid, model_id)

    if not HARDCODED_FILE_ID and get_debug_mode():
        logger.warning(
            "ask_file[%s] HARDCODED_FILE_ID is not set; request may fail", rid
        )

    payload = {
        "model": model_id,
        "stream": bool(req.stream),
        "messages": [{"role": "user", "content": req.question}],
        "files": [{"id": HARDCODED_FILE_ID, "type": "file", "status": "processed"}],
    }
    logger.debug(
        f"~~~ payload: {payload} ~~~",
    )

    owui_resp = await post_chat_completions(client, payload)
    logger.debug(f"~~~ owui_resp: {owui_resp} ~~~")
    logger.debug(
        "ask_file[%s] received OWUI response keys=%s",
        rid,
        (
            list(owui_resp.keys())
            if isinstance(owui_resp, dict)
            else type(owui_resp).__name__
        ),
    )

    # Normalize OWUI output
    normalized_text, sources = normalize_owui_response(owui_resp)
    logger.debug(
        "ask_file[%s] normalized len=%d sources=%d",
        rid,
        len(normalized_text or ""),
        len(sources or []),
    )

    logger.debug("ask_file[%s] done", rid)
    logger.debug(f"This is the normalized_text: {normalized_text}")

    return {
        "normalized_text": normalized_text,
        "sources": sources,
        "instructions": (
            "Your response requires source mapping to the Employee Handbook and must include the page number(s) where the information was found. "
            f"Use {sources} to map page numbers to show employees where to find the information the link to the handbook is: https://gspnet4.sharepoint.com/sites/HR/Shared%20Documents/employee-handbook.pdf. "
            "DO NOT make up content - if you cannot find an answer, state the you cannot find the answer and refer the user to the Employee Handbook, their HRP, or contact hr@greshamsmith.com. "
        ),
    }


@app.post("/get-my-leadership", response_model=EmploymentResp, summary="Get my leadership & employment details")
async def ask_employment_details(req: AskReq = Body(...)):
    """
    Employee-specific leadership details. Use this when the user asks *who* their HRP, Director, MVP/EVP, or CLL is, or requests personal employment details like hire date, employee ID, nomination level/date, or length of service.

    Returns: 
        A structured response containing the employee's leadership details and relevant employment information.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_employment_details[%s] model=%s", rid, req.model)

    # 1) Get token (if your Flow requires it)
    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )

    # 3) Build structured, market-aware response
    payload = build_employment_payload(employee_details)
    return payload


@app.post("/get-my-vacation", response_model=VacationResp, summary="Get my vacation details")
async def ask_vacation_details(req: AskReq = Body(...)):
    """
    Employee-specific vacation details. Use this when the user asks about their vacation balance, upcoming time off, or related inquiries.

    Returns: 
        A structured response containing the employee's vacation details and relevant information.
    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_vacation_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )
    logger.debug(f"This is the employee details: {employee_details}")
    vp_token_response = await get_vantagepoint_token()
    if not vp_token_response:
        raise HTTPException(
            status_code=502, detail="Vantagepoint API token retrieval failed"
        )
    logger.debug(f"[GET Vantagepoint API Token: {vp_token_response}]")
    body = {
        "EEID": employee_details.get("EmployeeID")
    }
    vacation_details = await get_vacation_days(body, vp_token_response.get("access_token"))

    if not vacation_details:
        raise HTTPException(
            status_code=502, detail="Vantagepoint Stored Procedure returned no data"
        )
    
    linked_call = AskReq(
        question=f"What is my PTO accrual rate for {employee_details.get('YearsWithGreshamSmith')} and {employee_details.get('CLL')}",
        model=req.model,
        stream=True
    )
    
    return {
        "employee_id": vacation_details.get("employee_id"),
        "starting_balance": vacation_details.get("starting_balance"),
        "current_balance": vacation_details.get("current_balance"),
        "instructions": (
            "The return values are in hours - show the results in hours and days. Our standard work day is 8 hours. "
            "If no vacation balance is found, refer the user to their HRP or manager - do not offer to refer to the servicedesk@greshamsmith.com."
            f"Refer to the \"/ask-file\" endpoint for a breakdown on accrual details for individual employees using a company tenure using: {linked_call} "
            )
    }


File: .\README.md
--------------------------------------------------
Content of .\README.md:
# HR MCP — HR Handbook & Policy MCP for GIA

FastAPI service that answers HR policy questions and returns employee-specific details by integrating:

- GIA/OWUI for RAG over the Employee Handbook
- Microsoft Graph/Power Automate for employee metadata
- Vantagepoint for PTO balances

OpenAPI docs are available at `/docs` and `/redoc` when running locally.

## Features

- Ask HR policy questions with source/page citations: `POST /ask-file`
- Get leadership & employment summary (HRP, Director, MVP/EVP, CLL, tenure, etc.): `POST /get-my-leadership`
- Get your current vacation balance from Vantagepoint: `POST /get-my-vacation`
- One-call PTO answer (balance + handbook accrual explanation with citations): `POST /answer-my-pto`
- Robust model resolution against GIA `/api/models` (handles many payload shapes)
- Flexible handling of OWUI responses (JSON, SSE, NDJSON, or text)

## Requirements

- Python 3.10+
- Access to your GIA/OWUI instance and the Employee Handbook indexed there
- Access to Power Automate (Flow) endpoint used by your tenant
- Access to Vantagepoint and credentials to obtain an API token

## Project Structure

- `main.py` — FastAPI app and endpoints
- `auth/` — Vantagepoint auth helper (`get_vantagepoint_token`)
- `utils/` — Config helpers
- `test_scripts/` — Ad-hoc test scripts for local verification
- `requirements.txt` / `pyproject.toml` — dependencies
- `Dockerfile`, `compose.yaml` — containerization

## Configuration (.env)

Environment variables are loaded via `python-dotenv`.

Minimum required:

- `OWUI_JWT` — Bootstrap JWT used to exchange for a service token
- `GIA_URL` — Base URL of your GIA/OWUI gateway (e.g., https://gia.example.com)
- `HARDCODED_FILE_ID` — File id of the Employee Handbook in GIA
- `PA_URL` — Power Automate flow HTTPS endpoint (for employee metadata)
- `VP_BASE_URL` — Vantagepoint API base URL
- `VP_SP_GETVACATION` — Name of the Vantagepoint stored procedure used for PTO

Optional:

- `OPENAI_API_KEY` — If you use any post-processing with OpenAI
- `OPENAI_MODEL` — Defaults to `gpt-4o-mini`
- `DEBUG` — Set to `1`/`true` for verbose logs
- `GRAPH_TOKEN_URL`, `GRAPH_CLIENT_ID`, `GRAPH_SECRET` — If your Flow requires Entra ID token acquisition

Example `.env`:

```
GIA_URL=https://gia.example.com
OWUI_JWT=eyJhbGciOi...
HARDCODED_FILE_ID=handbook-file-id
PA_URL=https://prod-00.westus.logic.azure.com:443/workflows/.../triggers/manual/paths/invoke
VP_BASE_URL=https://vantagepoint.example.com
VP_SP_GETVACATION=HR_GetVacationBalances
DEBUG=1
```

## Install & Run (local)

1. Install dependencies

```bash
pip install -r requirements.txt
```

2. Start the API with Uvicorn (port 5001)

```bash
uvicorn "main:app" --host 0.0.0.0 --port 5001 --reload
```

Visit http://localhost:5001/docs

## Docker

Build and run the container:

```bash
docker build -t hr-mcp .
docker run --rm -p 5001:5001 --env-file .env hr-mcp
```

With Docker Compose (service name: `vantagepoint-server`):

```bash
docker compose up --build
```

The app will be available at http://localhost:5001

## API Summary

### POST /ask-file

Ask HR policy questions against the Employee Handbook in GIA.

- Body: `{ "question": "...", "model": "gpt-5", "stream": true }`
- Returns: `normalized_text`, `sources[]`, and `instructions` prompting citation of page numbers.

### POST /get-my-leadership

Returns leadership and employment summary for the authenticated user (via OWUI auth).

- Returns: `leadership{...}`, `summary{...}` (employee id, display name, email, CLL, tenure, etc.).

### POST /get-my-vacation

Returns current and starting PTO balances from Vantagepoint for the authenticated user.

- Returns: `employee_id`, `starting_balance`, `current_balance`, plus `instructions` to present in hours and days (8h/day).

### POST /answer-my-pto

Combines your PTO balance with a handbook-backed accrual explanation and citations.

- Returns: `vacation{...}`, `accrual_explanation`, `citations[]`, `used_tools`.

## Testing

Pytest is configured in `requirements.txt`.

```bash
pytest -q
```

## Troubleshooting

- 502 from GIA endpoints: verify `OWUI_JWT`, network access to `GIA_URL`, and that the Handbook file id exists and is processed.
- Empty PTO results: confirm Vantagepoint token retrieval and `VP_SP_GETVACATION` name.
- Power Automate errors: check `PA_URL` and, if needed, `GRAPH_*` credentials.

## License

This repo is made available for demonstration purposes only. No license is granted for reuse.


File: .\REFACTORING_SUMMARY.md
--------------------------------------------------
Content of .\REFACTORING_SUMMARY.md:
# HR-MCP Code Refactoring Summary

## Overview

This document summarizes the refactoring performed on the `main.py` file to improve code organization and maintainability by extracting supporting functions into the `utils` directory.

## Changes Made

### 1. Created New Utility Modules

#### `utils/security.py`

- **Function**: `mask_token(token, show_last=10)`
- **Purpose**: Mask sensitive tokens for logging purposes
- **Original location**: Inline function in main.py

#### `utils/datetime_utils.py`

- **Function**: `years_between(iso_date)`
- **Purpose**: Calculate years between an ISO date string and now
- **Original location**: `_years_between()` function in main.py

#### `utils/http_client.py`

- **Functions**:
  - `ensure_model(client, model_name, jwt, model_alias)`
  - `post_chat_completions(client, payload)`
- **Purpose**: HTTP client utilities for interacting with external APIs
- **Original location**: Helper functions in main.py

#### `utils/response_processor.py`

- **Function**: `normalize_owui_response(owui)`
- **Purpose**: Process and normalize API responses from OWUI
- **Original location**: Helper function in main.py

#### `utils/employment_data.py`

- **Models**: `LeadershipInfo`, `EmploymentSummary`, `EmploymentResp`
- **Function**: `build_employment_payload(raw)`
- **Purpose**: Data transformation utilities for employment and HR data
- **Original location**: Pydantic models and helper function in main.py

#### `utils/vacation_data.py`

- **Model**: `VacationResp`
- **Purpose**: Vacation data models
- **Original location**: Pydantic model in main.py

#### `utils/api_models.py`

- **Models**: `AskReq`, `AskResp`
- **Purpose**: API request and response models
- **Original location**: Pydantic models in main.py

#### `utils/environment.py`

- **Functions**:
  - `get_environment_config()`
  - `log_environment_config(logger)`
  - `validate_required_env()`
  - Various environment variable getters
- **Purpose**: Environment configuration and logging utilities
- **Original location**: Inline environment variable handling in main.py

### 2. Updated `main.py`

#### Removed Code:

- All Pydantic model definitions (moved to utils)
- Helper functions (`mask_token`, `ensure_model`, `post_chat_completions`, `_years_between`, `build_employment_payload`, `normalize_owui_response`)
- Inline environment variable handling and logging
- Unused imports

#### Added/Updated:

- Clean imports from utils modules
- Updated function calls to use imported utilities
- Simplified configuration section
- Maintained all original API endpoints and functionality

### 3. File Structure Before vs After

#### Before:

```
main.py (686 lines)
├── Imports
├── App setup
├── Environment configuration
├── Pydantic models
├── Helper functions
└── API routes
```

#### After:

```
main.py (243 lines)
├── Imports
├── App setup
├── API routes

utils/
├── api_models.py
├── datetime_utils.py
├── employment_data.py
├── environment.py
├── http_client.py
├── response_processor.py
├── security.py
├── vacation_data.py
└── (existing files)
```

## Benefits

1. **Improved Maintainability**: Code is organized into logical modules
2. **Better Reusability**: Utility functions can be reused across the application
3. **Enhanced Readability**: Main.py is now focused on API route definitions
4. **Easier Testing**: Individual utility functions can be tested in isolation
5. **Reduced File Size**: Main.py reduced from 686 to 243 lines (64% reduction)

## File Summary

- **Main.py**: Now contains only FastAPI app setup and route definitions
- **Utils directory**: Contains 9 utility modules with specialized functionality
- **Backwards Compatibility**: All API endpoints maintain the same interface
- **No Breaking Changes**: External consumers of the API are unaffected

## Validation

- All imports resolve correctly
- No lint errors or compilation issues
- Original functionality preserved
- Clean separation of concerns achieved


File: .\requirements.txt
--------------------------------------------------
Content of .\requirements.txt:
fastapi
uvicorn[standard]
pydantic
httpx
xmltodict
#requests

# FOR TESTING
pytest
pytest-asyncio

# UNUSED
# mcp[cli]>=1.9.4
# httpx



File: .github\instructions\mcp_instructions.instructions.md
--------------------------------------------------
Content of .github\instructions\mcp_instructions.instructions.md:
**All work will eventually connect to an Model Context Protocol (MCP) server. Keep that in mind.

Build all test scripts in the "test_scripts" directory
Build all auth scripts in the "auth" directory
Build all project scripts in the "project" directory
Build all utility/helper scripts in the "utils" directory

AUTH EXAMPLE FOR VANTAGEPOINT (payload will need to be encoded in the request):
```python
# Example of how to authenticate with VantagePoint API
import httpx
import json

url = "https://az-webui-01.global.gsp/api/v1/auths/api_key"

headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer TOKEN_HERE",
}

payload = {}  # Empty dict → same as sending `{}` JSON

with httpx.Client() as client:
    response = client.post(url, headers=headers, json=payload)

print(response.text)




File: .pytest_cache\README.md
--------------------------------------------------
Content of .pytest_cache\README.md:
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.


File: .supporting_items\.filters\filter_under_the_hood.py
--------------------------------------------------
Content of .supporting_items\.filters\filter_under_the_hood.py:
# log_body_filter.py
from typing import Optional
from pydantic import BaseModel, Field
import logging
import json

LOGGER_NAME = "owui.filter.log_body"

def _setup_logger(level: str = "INFO") -> logging.Logger:
    logger = logging.getLogger(LOGGER_NAME)
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
        logger.addHandler(handler)
    logger.setLevel(getattr(logging, level.upper(), logging.INFO))
    return logger

class Filter:
    class Valves(BaseModel):
        LOG_LEVEL: str = Field(default="INFO", description="Logging level (DEBUG, INFO, WARNING, ERROR)")

    def __init__(self):
        self.valves = self.Valves()
        self.logger = _setup_logger(self.valves.LOG_LEVEL)

    # Minimal requirement: just log the request body we receive
    def inlet(
        self,
        body: dict,
        __user__: Optional[dict] = None,
        __event_emitter__=None,  # kept for compatibility; not used
    ) -> dict:
        try:
            self.logger.info("INLET body: %s", json.dumps(body, ensure_ascii=False))
        except Exception as e:
            # Fallback so logging never breaks the pipeline
            self.logger.warning("Failed to JSON-serialize inlet body (%s); raw=%r", e, body)
        return body

    # Optional: log post-LLM body too. Safe no-op otherwise.
    def outlet(
        self,
        body: dict,
        __user__: Optional[dict] = None,
        __event_emitter__=None,
    ) -> dict:
        try:
            self.logger.debug("OUTLET body: %s", json.dumps(body, ensure_ascii=False))
        except Exception as e:
            self.logger.warning("Failed to JSON-serialize outlet body (%s); raw=%r", e, body)
        return body

    # (Optional) If you enable streaming on your model, you can peek at chunks as they pass:
    # def stream(self, event: dict) -> dict:
    #     self.logger.debug("STREAM event keys: %s", list(event.keys()))
    #     return event


File: .supporting_items\.filters\hr_thinking_filter.py
--------------------------------------------------
Content of .supporting_items\.filters\hr_thinking_filter.py:
"""
title: GIA HR Assistant Thinking Indicator
author: Smiley Baltz
version: 0.1.0
description: Displays a fun "Thinking..." indicator while GIA HR Assistant is processing a request.

"""

import time
import asyncio
from typing import Any, Awaitable, Callable
from pydantic import BaseModel, Field
import random
import logging

# Get logger for this module
logger = logging.getLogger(__name__)


# Configure the logger
def setup_logging(log_level: str = "INFO") -> None:
    """
    Configure logging with the specified log level.
    Args:
        log_level (str): Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    """
    # Convert string to logging level constant
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)

    # Remove existing handlers to avoid duplicates
    if logger.handlers:
        logger.handlers.clear()

    # Create console handler with the specified level
    ch = logging.StreamHandler()
    ch.setLevel(numeric_level)

    # Create formatter
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    ch.setFormatter(formatter)

    # Add the handler to the logger
    logger.addHandler(ch)
    logger.setLevel(numeric_level)

    logger.debug("Logger initialized")
    logger.info(f"Echo Pipeline logger is ready (Level: {log_level})")


# Initialize logger with default level
setup_logging()


class Filter:
    class Valves(BaseModel):
        PRIORITY: int = Field(
            title="Priority",
            default=15,
            description="Priority for executing the filter",
        )
        LOG_LEVEL: str = Field(
            title="Logging Level",
            default="INFO",
            description="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
        )
        pass

    def __init__(self):
        self.start_time = None
        self.is_thinking = False
        self.responses = [
            # HR-flavored “thinking” lines
            "Consulting the Employee Handbook… page mysteriously marked with a coffee ring.",
            "Running a quick policy check—because HR loves a good citation.",
            "Verifying PTO math… carry the beach, subtract the meetings.",
            "Herding policies into compliance… please hold all confetti.",
            "Syncing with Payroll’s good vibes… and their spreadsheets.",
            "Counting PTO beans… these ones taste like vacation.",
            "Checking job codes and Jedi codes—both must align.",
            "Drafting a friendly memo to your time off balance.",
            "Phone-a-friend: the Handbook. It always answers (eventually).",
            "Doing the HR two-step: review, document, smile.",
            "Translating HR-ese to human—may involve snacks.",
            "Auditing time like a timesheet superhero (cape optional).",
            "Pulling your PTO ledger out of the ‘Do Not Disturb’ folder.",
            "Reconciling ‘out of office’ with ‘out of PTO’ (plot twist pending).",
            "Double-checking accruals—because decimals have feelings too.",
            "Measuring twice, approving once—Handbook-approved craftsmanship.",
            "Paging Section 4.2: ‘Thou shalt hydrate and log PTO.’",
            "Calling a brief stand-up with the policies. They’re… remarkably seated.",
            "Queueing the kindness protocol: clarify, confirm, celebrate.",
            "Polishing the compliance halo—gotta keep it shiny.",
            "Aligning vacation dreams with timesheet realities… negotiating peace.",
            "Loading the PTO piñata—stand by for candy math.",
            "Stamping this with ‘HR Friendly’ and a small smiley face.",
            "Checking for blackout dates and solar eclipses—both count sometimes.",
            "Turning pages faster than you can say ‘work-life balance.’",
            "Matching your request with the magical accrual engine.",
            "Consulting the calendar oracle… it prefers Mondays less.",
            "Plotting a route from policy to permission—no tolls.",
            "Running background… checks on background checks (just kidding).",
            "Spinning up the ‘People Ops Optimizer’ (™ not pending).",
            "Writing a tiny kudos note in the margins of compliance.",
            "Counting holidays like they’re sprinkles—pure joy, zero calories.",
            "Checking carryover rules—no PTO left behind.",
            "Confirming manager approvals with a wink and a timestamp.",
            "Balancing fairness, fun, and federal guidelines—easy peasy.",
            "Sweeping the handbook for gotchas—only glitter found.",
            "Reconciling calendars… your beach vs. your boss.",
            "Filing this under ‘Good Choices’ (subfolder: PTO).",
            "Clearing it with the spreadsheet guardian—she nods.",
            "Tuning the empathy dial to ‘perfectly supportive’.",
            "Proofreading policy punctuation—Oxford comma says hi.",
            "Aligning benefits with benefits of naps—research ongoing.",
            "HR is thinking… and yes, we brought snacks.",
            "Turning on the ‘vacay radar’—signal strong.",
            "Your balance and your plans are getting acquainted.",
            "Checking tenure perks—loyalty has its lounge.",
            "Calibrating fairness matrix… equitable and adorable.",
            "Cross-referencing accruals with the laws of physics.",
            "Consulting Captain Compliance—cape confirms.",
        ]

        self.current_response_index = random.randint(0, len(self.responses) - 1)
        self.last_rotation_time = None  # Will be set when inlet is called
        logger.info(
            f"Thinking filter initialized with responses: {len(self.responses)}"
        )


    async def _update_thinking_status(
        self, __event_emitter__: Callable[[Any], Awaitable[None]]
    ):
        """
        Continuously update "Thinking..." status with elapsed time every second.
        """
        logger.debug("Starting thinking status updates")
        while self.is_thinking:
            elapsed_time = int(time.time() - self.start_time)
            current_time = time.time()

            # Initialize last_rotation_time if it's None
            if self.last_rotation_time is None:
                self.last_rotation_time = current_time
                logger.debug("Initialized last_rotation_time")

            # Rotate responses every 1 second (for testing)
            if current_time - self.last_rotation_time >= 3:
                logger.debug(
                    f"Time to rotate! Current index: {self.current_response_index}"
                )
                # Force a different index than the current one
                new_index = self.current_response_index
                while (
                    new_index == self.current_response_index and len(self.responses) > 1
                ):
                    new_index = random.randint(0, len(self.responses) - 1)
                    logger.debug(f"Trying new index: {new_index}")
                self.current_response_index = new_index
                self.last_rotation_time = current_time
                logger.debug(
                    f"Rotated to new response: {self.responses[self.current_response_index]}"
                )

            await __event_emitter__(
                {
                    "type": "status",
                    "data": {
                        "description": self.responses[self.current_response_index],
                        "done": False,
                    },
                }
            )
            await asyncio.sleep(0.5)  # Update more frequently

    async def inlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
    ) -> dict:
        """
        This hook is invoked at the start of processing to show a "Thinking..." indicator.
        """
        logger.debug("Inlet called - starting thinking indicator")
        self.start_time = time.time()
        self.is_thinking = True
        self.last_rotation_time = self.start_time

        # Start a background task to update the "Thinking..." status
        asyncio.create_task(self._update_thinking_status(__event_emitter__))

        return body

    async def outlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
    ) -> dict:
        """
        This hook is invoked after the processing to calculate the elapsed time and show it.
        """
        logger.debug("Outlet called - stopping thinking indicator")
        self.is_thinking = False
        end_time = time.time()
        elapsed_time = end_time - self.start_time

        # Emit final "done" status with total elapsed time
        await __event_emitter__(
            {
                "type": "status",
                "data": {
                    "description": f"Filed the paperwork in {int(elapsed_time)} seconds",
                    "done": True,
                },
            }
        )
        
        return body


File: .supporting_items\.filters\hr_thinking_filter_02.py
--------------------------------------------------
Content of .supporting_items\.filters\hr_thinking_filter_02.py:
"""
title: GIA HR Assistant Thinking Indicator
author: Smiley Baltz
version: 0.0.1
description: Playful HR "Thinking..." indicator with tone, task-type tracks, and first-name injection.
"""

import time
import asyncio
from typing import Any, Awaitable, Callable, Dict, List, Optional
from pydantic import BaseModel, Field
import random
import logging
import re

logger = logging.getLogger(__name__)

# -----------------------------
# Logging
# -----------------------------
def setup_logging(log_level: str = "INFO") -> None:
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)
    if logger.handlers:
        logger.handlers.clear()
    ch = logging.StreamHandler()
    ch.setLevel(numeric_level)
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    logger.setLevel(numeric_level)
    
# -----------------------------
# User redactor (place it here!)
# -----------------------------
def _redact_user(u: Optional[dict]) -> Optional[dict]:
    if not isinstance(u, dict):
        return None
    redact_keys = {"api_key", "oauth_sub", "profile_image_url"}
    return {k: ("<redacted>" if k in redact_keys else v) for k, v in u.items()}


# -----------------------------
# Filter
# -----------------------------
class Filter:
    class Valves(BaseModel):
        PRIORITY: int = Field(
            title="Priority",
            default=15,
            description="Priority for executing the filter",
        )
        LOG_LEVEL: str = Field(
            title="Logging Level",
            default="INFO",
            description="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
        )
        TONE: str = Field(
            title="Tone",
            default="Casual",
            description="Response tone: Casual | Professional | Super Cheerful",
        )
        ROTATE_SECONDS: float = Field(
            title="Rotate Seconds",
            default=3.5,
            description="How often to rotate the message (seconds)",
        )
        SHOW_PATIENCE_HINTS: bool = Field(
            title="Emphasize External System Patience",
            default=True,
            description="If true, inject patient messaging when external systems are involved",
        )

    # -----------------------------
    # Tone/Track Response Library
    # -----------------------------
    TRACKS: Dict[str, Dict[str, List[str]]] = {
        # PTO: time off, balances, accruals, holidays
        "pto": {
            "Casual": [
                "Hey {name}, counting those sweet, sweet accruals… carry the beach, subtract the meetings.",
                "Running PTO math—no PTO left behind. 🏖️",
                "Checking blackout dates and solar eclipses… just in case.",
                "Reconciling ‘out of office’ with ‘out of PTO’—plot twist pending.",
                "Paging your accrual engine—it says you deserve sunscreen.",
            ],
            "Professional": [
                "Reviewing PTO accruals and carryover rules for you, {name}.",
                "Confirming balances, holidays, and any blackout dates.",
                "Cross-referencing tenure-based accruals and policy thresholds.",
                "Validating manager approvals and effective dates.",
                "Ensuring fairness and compliance across leave policies.",
            ],
            "Super Cheerful": [
                "🌞 Hey {name}! Your vacation dreams are meeting their balance. It’s a love story!",
                "Loading the PTO piñata—stand by for candy math!",
                "Sprinkling holidays like confetti—pure joy, zero calories!",
                "Beach mode negotiating with calendar mode… peace talks underway!",
                "Your accruals just high-fived HR. Cute.",
            ],
        },
        # Policy: handbook, guidelines, eligibility, compliance
        "policy": {
            "Casual": [
                "Consulting the Employee Handbook—page mysteriously marked with a coffee ring.",
                "Doing the HR two-step: review, document, smile.",
                "Translating HR-ese to human—snacks may be involved.",
                "Double-checking decimals—policies have feelings too.",
                "Phone-a-friend: the Handbook. It always picks up. Eventually.",
            ],
            "Professional": [
                "Locating the relevant section of the Employee Handbook for you, {name}.",
                "Verifying eligibility, scope, and any regional exceptions.",
                "Citing the policy source with version and effective date.",
                "Reconciling policy text with current practice—consistency matters.",
                "Documenting interpretation and next steps for clarity.",
            ],
            "Super Cheerful": [
                "📘 Handbook huddle! Section {section} is warming up the spotlight. (We’ll find it, promise.)",
                "Captain Compliance just adjusted their cape. We got this!",
                "Bringing policies and plain English together like besties.",
                "Shining the policy halo—sparkly AND compliant!",
                "Policy pit-stop complete—clarity fuel topped off!",
            ],
        },
        # Payroll: pay periods, taxes, W-2, deductions
        "payroll": {
            "Casual": [
                "Syncing with Payroll’s good vibes… and their spreadsheets.",
                "Counting beans that officially count—deductions, taxes, the works.",
                "Matching job codes and Jedi codes—both must align.",
                "Asking the spreadsheet guardian for a blessing. She nods.",
                "Queuing the kindness protocol: clarify, confirm, celebrate.",
            ],
            "Professional": [
                "Reviewing pay period details and applicable deductions for you, {name}.",
                "Confirming tax withholdings and year-to-date values.",
                "Reconciling payroll records with HRIS for accuracy.",
                "Checking effective dates for compensation changes.",
                "Preparing a clean summary you can reference later.",
            ],
            "Super Cheerful": [
                "💸 Payroll party! Your numbers are lining up like champs.",
                "Polishing the compliance halo while the digits dance.",
                "Spreadsheets are doing jazz hands—deductions included!",
                "Numbers confirmed, confetti standing by!",
                "Your pay info and HR are officially on speaking terms. Cute!",
            ],
        },
        # General fallback
        "general": {
            "Casual": [
                "HR is thinking… and yes, we brought snacks.",
                "Filing this under ‘Good Choices’ (subfolder: PTO).",
                "Polishing the compliance halo—gotta keep it shiny.",
                "Plotting a route from policy to permission—no tolls.",
                "Proofreading policy punctuation—Oxford comma says hi.",
            ],
            "Professional": [
                "Reviewing your request and confirming relevant records, {name}.",
                "Reconciling data across HRIS and policy sources.",
                "Preparing a concise, documented response.",
                "Ensuring equitable and consistent application of policy.",
                "Finalizing details for accuracy and clarity.",
            ],
            "Super Cheerful": [
                "✨ Spinning up the People Ops Optimizer—results incoming!",
                "Your request is getting the VIP HR treatment.",
                "Compliance cape on, empathy dial set to ‘perfect’!",
                "Good news loading… kindness protocol engaged.",
                "Checklist checked. Twice. (We’re fancy.)",
            ],
        },
    }

    # Patient hints appended/rotated when externals are involved
    PATIENCE_HINTS: List[str] = [
        "Heads up: checking external systems can take a sec—real data > fast guesses.",
        "Still syncing with HRIS/Payroll—slower than normal Q&A, but worth the accuracy.",
        "Verifying with live systems (balances, approvals, dates). Thanks for your patience!",
        "External checks running—coffee break optional, correctness mandatory.",
        "Almost there—policy meets platform, and platforms like to think.",
    ]

    def __init__(self):
        self.start_time = None
        self.is_thinking = False
        self.current_response_index = 0
        self.last_rotation_time = None
        self.valves = self.Valves()  # default valves until inlet replaces
        setup_logging(self.valves.LOG_LEVEL)

    # -----------------------------
    # Helpers
    # -----------------------------
    @staticmethod
    def _get_first_name(body: dict, user: Optional[dict] = None) -> str:
        """
        Prefer __user__ info (authoritative), then fall back to body fields.
        """
        # 1) __user__ takes precedence
        if isinstance(user, dict):
            # Try 'name' first (full name), fall back to username (rare)
            for key in ("name", "username"):
                val = user.get(key)
                if isinstance(val, str) and val.strip():
                    return val.strip().split()[0]
            # If there's a nested 'info' with a name-like thing
            if isinstance(user.get("info"), dict):
                for key in ("first_name", "given_name"):
                    val = user["info"].get(key)
                    if isinstance(val, str) and val.strip():
                        return val.strip().split()[0]

        # 2) Fall back to body-sourced locations
        candidates = [
            ("employee", "first_name"),
            ("employee", "name"),
            ("user", "first_name"),
            ("user", "name"),
            ("metadata", "employee_first_name"),
            ("metadata", "first_name"),
            ("context", "first_name"),
        ]
        for a, b in candidates:
            try:
                val = (body.get(a) or {}).get(b)
                if isinstance(val, str) and val.strip():
                    return val.strip().split()[0]
            except Exception:
                pass
        return "there"


    @staticmethod
    def _detect_task_track(body: dict) -> str:
        """
        Detect the task type from body.task.type if provided, otherwise fallback to keyword detection.
        """
        # Direct override if provided
        task_obj = body.get("task") or body.get("metadata") or {}
        task_type = None
        if isinstance(task_obj, dict):
            task_type = task_obj.get("type") or task_obj.get("task_type")

        if isinstance(task_type, str):
            t = task_type.strip().lower()
            if t in ["pto", "vacation", "leave", "holiday"]:
                return "pto"
            if t in ["policy", "handbook", "guideline"]:
                return "policy"
            if t in ["payroll", "pay", "compensation"]:
                return "payroll"
            if t in ["general", "other"]:
                return "general"

        # --- fallback keyword detection ---
        text_fields = []
        for k in ("query", "prompt", "text", "message"):
            v = body.get(k)
            if isinstance(v, str):
                text_fields.append(v)
        for scope in ("metadata", "context"):
            v = body.get(scope, {})
            for kk, vv in (v.items() if isinstance(v, dict) else []):
                if isinstance(vv, str):
                    text_fields.append(vv)

        hay = " ".join(text_fields).lower()

        # keywords
        pto_kw = ["pto", "vacation", "time off", "leave", "holiday", "accrual"]
        policy_kw = ["policy", "handbook", "guideline", "procedure", "benefit", "eligibility"]
        payroll_kw = ["payroll", "pay", "paystub", "w-2", "w2", "withholding", "deduction", "tax"]

        def has_any(words: List[str]) -> bool:
            return any(w in hay for w in words)

        if has_any(pto_kw):
            return "pto"
        if has_any(payroll_kw):
            return "payroll"
        if has_any(policy_kw):
            return "policy"
        return "general"


    @staticmethod
    def _externals_involved(body: dict) -> bool:
        """
        Only treat the task as 'external' if the upstream explicitly says so.

        Signals (in order of precedence):
          1) body.task.requires_external == True
          2) body.task.systems or body.task.endpoints is a non-empty list
          3) body.metadata.requires_external == True  (optional backstop)
        """
        task = body.get("task") if isinstance(body.get("task"), dict) else {}
        meta = body.get("metadata") if isinstance(body.get("metadata"), dict) else {}

        # 1) Primary explicit flag
        if isinstance(task.get("requires_external"), bool) and task["requires_external"]:
            return True

        # 2) Non-empty system lists also imply external checks
        for key in ("systems", "endpoints"):
            val = task.get(key)
            if isinstance(val, (list, tuple)) and len(val) > 0:
                return True

        # 3) Optional backstop if your pipeline prefers metadata
        if isinstance(meta.get("requires_external"), bool) and meta["requires_external"]:
            return True

        # Otherwise, we do NOT show patience hints
        return False


    @staticmethod
    def _normalize_tone(tone: str) -> str:
        t = (tone or "").strip().lower()
        if t.startswith("pro"):
            return "Professional"
        if t.startswith("super"):
            return "Super Cheerful"
        return "Casual"

    def _pick_message(self, track: str, tone: str, name: str) -> str:
        tone_key = self._normalize_tone(tone)
        library = self.TRACKS.get(track, self.TRACKS["general"]).get(tone_key, self.TRACKS["general"]["Casual"])
        msg = library[self.current_response_index % len(library)]
        return msg.format(name=name, section="4.2")

    # -----------------------------
    # Async updaters
    # -----------------------------
    async def _update_thinking_status(
        self,
        __event_emitter__: Callable[[Any], Awaitable[None]],
        body: dict,
        user: Optional[dict] = None,
    ):
        logger.debug("Starting thinking status updates")
        self.is_thinking = True
        self.start_time = time.time()
        self.last_rotation_time = self.start_time
        name = self._get_first_name(body, user)  # <<— now uses __user__ first
        track = self._detect_task_track(body)
        externals = self._externals_involved(body)
        tone = self.valves.TONE

        patience_index = 0
        patience_gap = 2  # rotate a patience note every other cycle if externals

        while self.is_thinking:
            now = time.time()
            if now - self.last_rotation_time >= float(self.valves.ROTATE_SECONDS):
                self.current_response_index += 1
                self.last_rotation_time = now

            base_line = self._pick_message(track, tone, name)

            if self.valves.SHOW_PATIENCE_HINTS and externals:
                if (self.current_response_index % patience_gap) == 0:
                    hint = self.PATIENCE_HINTS[patience_index % len(self.PATIENCE_HINTS)]
                    patience_index += 1
                    line = f"{base_line}  {hint}"
                else:
                    line = base_line
            else:
                line = base_line

            await __event_emitter__({"type": "status", "data": {"description": line, "done": False}})
            await asyncio.sleep(0.5)


    # -----------------------------
    # Open WebUI hooks
    # -----------------------------
    async def inlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
        __user__: Optional[dict] = None,
    ) -> dict:
        """
        Invoked at the start of processing to show a "Thinking..." indicator.
        """
        if "valves" in body and isinstance(body["valves"], dict):
            try:
                self.valves = self.Valves(**{**self.Valves().dict(), **body["valves"]})
            except Exception:
                self.valves = self.Valves()

        setup_logging(self.valves.LOG_LEVEL)

        # Safe, redacted log for debugging (won’t leak keys/images)
        logger.debug(f"Inlet called; user={_redact_user(__user__)}")

        # spin background updater
        asyncio.create_task(self._update_thinking_status(__event_emitter__, body, __user__))
        return body


    async def outlet(
        self,
        body: dict,
        __event_emitter__: Callable[[Any], Awaitable[None]] = None,
        __user__: Optional[dict] = None,
    ) -> dict:
        """
        Invoked after processing to stop the indicator and summarize duration.
        """
        logger.debug("Outlet called - stopping HR thinking indicator")
        self.is_thinking = False
        end_time = time.time()
        elapsed = int(max(0, end_time - (self.start_time or end_time)))

        await __event_emitter__(
            {
                "type": "status",
                "data": {
                    "description": f"Filed the paperwork in {elapsed} seconds",
                    "done": True,
                },
            }
        )
        return body



File: .supporting_items\.filters\personalization_filter.py
--------------------------------------------------
Content of .supporting_items\.filters\personalization_filter.py:
"""
title: GIA Personalization
version: 0.1.1
"""

import logging
import pytz
from datetime import datetime
from pydantic import BaseModel, Field
from typing import Optional

# Get a module-level logger
logger = logging.getLogger(__name__)
# Optional: basic config if your app doesn't set logging up elsewhere.
# Safe to remove if your framework already configures logging.
if not logging.getLogger().hasHandlers():
    logging.basicConfig(
        level=logging.DEBUG, format="%(asctime)s %(levelname)s [%(name)s] %(message)s"
    )


class Filter:
    class Valves(BaseModel):
        system_message: str = Field(
            default="""        
        <context>
        - You are chatting with {{USER_NAME}}.
        </context>

        Use personalized responses with this context when appropriate. 
        For example, when answering question from the user, you can say "I'm here to help you with that {{FIRST_NAME}}, or "That's in interesting point, {{FIRST_NAME}}.
        If asked to be more formal, you should respond with {{USER_NAME}}, or if the user asks for a name, you should respond with {{USER_NAME}}.

        """.replace(
                "\n", " "
            ).strip(),
            description="System Message",
        )

    def __init__(self):
        self.valves = self.Valves()

    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # Be defensive: __user__ might be None or missing "name"
        user_name = (__user__ or {}).get("name") or ""
        first_name = user_name.split(" ")[0] if user_name else ""

        # Debug info
        if len(body.get("messages", [])) > 1:
            logger.debug("Messages array length: %s", len(body["messages"]))
        logger.debug("%s user payload: %s", "^" * 25, __user__)
        logger.debug("Request body: %s", body)
        logger.debug("User name: %s", user_name)

        messages = body.get("messages", [])

        system_prompt = next(
            (message for message in messages if message.get("role") == "system"),
            None,
        )
        if system_prompt:
            template = system_prompt.get("content", "")
        else:
            logger.debug("No system message. Using fallback template.")
            template = self.valves.system_message

        # Personalize
        template = template.replace("{{USER_NAME}}", user_name or "Unknown")
        template = template.replace("{{FIRST_NAME}}", first_name or "Unknown")

        if system_prompt:
            system_prompt["content"] = template
        else:
            system_prompt = {"role": "system", "content": template}

        filtered_messages = [system_prompt] + [
            message for message in messages if message.get("role") != "system"
        ]
        body["messages"] = filtered_messages
        return body


File: .supporting_items\.filters\personalization_filter_logger_info.py
--------------------------------------------------
Content of .supporting_items\.filters\personalization_filter_logger_info.py:
"""
title: GIA Personalization
version: 0.1.1
"""

import logging
import pytz
from datetime import datetime
from pydantic import BaseModel, Field
from typing import Optional

# Get a module-level logger
logger = logging.getLogger(__name__)
# Optional: basic config if your app doesn't set logging up elsewhere.
# Safe to remove if your framework already configures logging.
if not logging.getLogger().hasHandlers():
    logging.basicConfig(
        level=logging.DEBUG, format="%(asctime)s %(levelname)s [%(name)s] %(message)s"
    )


class Filter:
    class Valves(BaseModel):
        system_message: str = Field(
            default="""        
        <context>
        - You are chatting with {{USER_NAME}}.
        </context>

        Use personalized responses with this context when appropriate. 
        For example, when answering question from the user, you can say "I'm here to help you with that {{FIRST_NAME}}, or "That's in interesting point, {{FIRST_NAME}}.
        If asked to be more formal, you should respond with {{USER_NAME}}, or if the user asks for a name, you should respond with {{USER_NAME}}.

        """.replace(
                "\n", " "
            ).strip(),
            description="System Message",
        )

    def __init__(self):
        self.valves = self.Valves()

    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # Be defensive: __user__ might be None or missing "name"
        user_name = (__user__ or {}).get("name") or ""
        first_name = user_name.split(" ")[0] if user_name else ""

        # Debug info
        if len(body.get("messages", [])) > 1:
            logger.info("Messages array length: %s", len(body["messages"]))
        logger.info("%s user payload: %s", "^" * 25, __user__)
        logger.info("Request body: %s", body)
        logger.info("User name: %s", user_name)

        messages = body.get("messages", [])

        system_prompt = next(
            (message for message in messages if message.get("role") == "system"),
            None,
        )
        if system_prompt:
            template = system_prompt.get("content", "")
        else:
            logger.info("No system message. Using fallback template.")
            template = self.valves.system_message

        # Personalize
        template = template.replace("{{USER_NAME}}", user_name or "Unknown")
        template = template.replace("{{FIRST_NAME}}", first_name or "Unknown")

        if system_prompt:
            system_prompt["content"] = template
        else:
            system_prompt = {"role": "system", "content": template}

        filtered_messages = [system_prompt] + [
            message for message in messages if message.get("role") != "system"
        ]
        body["messages"] = filtered_messages
        return body


File: .supporting_items\.instructions\20250829_instructions.md
--------------------------------------------------
Content of .supporting_items\.instructions\20250829_instructions.md:
# GIA (Genuine Ingenuity Assistant) — HR Policy Assistant Instructions

## Role & Behavior

Your name is **GIA (Genuine Ingenuity Assistant)**, and you are a helpful, knowledgeable, and professional AI assistant designed to support **Gresham Smith employees**. You provide accurate, concise, and context-aware information specifically focused on:

- HR policies and procedures
- Employee information (leadership structure, HR Partner (HRP) assignments, tenure, etc.)
- PTO and vacation balance details
- Supporting information from approved systems (Employee Handbook, Power Automate, Vantagepoint)

If a question falls outside your training or access scope, provide alternative support options, but do not invent content or references.

---

## AI Usage Compliance

You must strictly follow **Gresham Smith's AI usage guidelines** (established August 31, 2023). This assistant complies with the Governance Policy related to AI use. Employees can review the full policy here: **Gresham Smith AI Policy**.

---

## Scope & Capabilities

GIA integrates with multiple systems to provide employees with accurate answers:

- **Employee Handbook (via GIA/OWUI)** — HR policy questions with page/source citations.
- **Leadership & Employment Data (via Power Automate)** — HRP, Director, MVP/EVP, CLL, tenure, etc.
- **PTO Balances (via Vantagepoint)** — starting and current vacation balances.
- **Combined PTO Answer** — balance + handbook accrual explanation with citations.

### System Endpoints

- `POST /ask-file` — Ask HR policy questions (Handbook, with citations)
- `POST /get-my-leadership` — Leadership & employment summary
- `POST /get-my-vacation` — Current PTO balances
- `POST /answer-my-pto` — PTO balance + accrual explanation with citations

### Limitations

- You cannot create or export files (Word, Excel, PowerPoint, PDF). Politely decline such requests and direct users to SharePoint or their HRP.

---

## Boundaries

- Do not provide medical, legal, or financial advice beyond what is documented internally.
- Do not speculate on confidential, private, or unknown data.
- If unsure, respond with: _“I’m not certain about that. Would you like me to help you find someone who can assist?”_ and refer them to the **Gresham Smith Human Resources HR department**: [hr@greshamsmith.com](mailto:hr@greshamsmith.com)
- Summarize lengthy content but offer full documents or links when available.

---

## Source Verification & Citations

- Always cite real, verifiable sources when referencing policies, studies, or documents.
- Provide direct URLs, DOIs, or reputable references when available.
- Never fabricate citations.
- If unsure about a source, state the uncertainty clearly.
- If no authoritative source is available, explain this transparently.

---

## Tone & Style

- Use a **friendly, respectful, and supportive tone**.
- Adapt tone based on user style:

  - Casual: _“Hey! Totally, here’s what you need…”_
  - Formal: _“Certainly. Based on the provided policy…”_

- Use **headers, bullet points, and formatting** for clarity.

---

## Memory & Context

- Maintain context across the conversation to improve efficiency.
- Ask clarifying questions if a request lacks detail.

---

## Confidentiality & Compliance

- Never share or infer confidential, proprietary, or restricted information without clear authorization.
- Log or flag conversations that may indicate potential misuse or policy violations per AI usage guidelines.


File: .supporting_items\.old_scripts\main_backup.py
--------------------------------------------------
Content of .supporting_items\.old_scripts\main_backup.py:
from typing import Optional
import os, json, logging, sys, uuid

import httpx

from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

from utils.config import TOOL_NAME
from utils.environment import (
    get_environment_config, 
    log_environment_config, 
    validate_required_env,
    get_owui_url,
    get_owui_jwt,
    get_hardcoded_file_id,
    get_debug_mode
)
from utils.api_models import AskReq, AskResp
from utils.employment_data import EmploymentResp, build_employment_payload
from utils.vacation_data import VacationResp
from utils.http_client import ensure_model, post_chat_completions
from utils.response_processor import normalize_owui_response
from auth import (
    get_service_token,
    get_current_user_email,
    get_graph_token_async,
    call_pa_workflow_async,
    get_vantagepoint_token
)
from utils.vantagepoint import get_vacation_days

load_dotenv()

# =========================
# App & Logging
# =========================
app = FastAPI(
    title="HR Handbook and Policy MCP for GIA",
    version="0.0.1",
    description="MCP Server to retrieve HR policies and employee information.",
)

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.DEBUG if get_debug_mode() else logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger(TOOL_NAME)

# =========================
# Config / HTTP client
# =========================
OWUI = get_owui_url()
JWT = get_owui_jwt()
HARDCODED_FILE_ID = get_hardcoded_file_id()
# Log environment configuration
log_environment_config(logger)

# Validate required environment variables
validate_required_env()

# Optional: map your requested model name to an OWUI-registered model id.
# Example: MODEL_ALIAS_JSON='{"gpt-5":"gpt-5o"}'
MODEL_ALIAS = {"gpt-5": "gpt-5"}  # or "gpt-5o" if that’s the registered ID

# Shared async client (init on startup)
client: httpx.AsyncClient | None = None


@app.on_event("startup")
async def _startup():
    global client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    logger.info("HTTP client initialized for GIA at %s", OWUI)


@app.on_event("shutdown")
async def _shutdown():
    global client
    if client:
        await client.aclose()
        logger.info("HTTP client closed")


# =========================
# Pydantic models
# =========================
class AskReq(BaseModel):
    question: str = Field(..., description="User question")
    model: str = Field(
        "gpt-5", description="Model id as registered in GIA (/api/models)"
    )
    stream: bool = Field(True, description="Use streamed responses (server-side)")


class AskResp(BaseModel):
    normalized_text: Optional[str] = None
    sources: Optional[list] = None
    instructions: Optional[str] = None


class LeadershipInfo(BaseModel):
    hrp_employee_id: Optional[str] = None
    hrp_name: Optional[str] = None
    hrp_email: Optional[str] = None
    director_id: Optional[str] = None
    director_name: Optional[str] = None
    director_email: Optional[str] = None
    mvp_id: Optional[str] = None
    mvp_name: Optional[str] = None
    mvp_email: Optional[str] = None
    evp_id: Optional[str] = None
    evp_name: Optional[str] = None
    evp_email: Optional[str] = None


class EmploymentSummary(BaseModel):
    employee_id: Optional[str] = None
    display_name: Optional[str] = None
    email: Optional[str] = None
    cll: Optional[str] = None
    market: Optional[str] = None
    department: Optional[str] = None
    nomination_level: Optional[str] = None
    nomination_date: Optional[str] = None
    latest_hire_date: Optional[str] = None
    original_hire_date: Optional[str] = None
    years_with_gresham_smith: Optional[float] = None
    los_years: Optional[float] = None


class EmploymentResp(BaseModel):
    # What we’ll send back from /get-my-leadership (aka ask_employment_details)
    leadership: LeadershipInfo
    summary: EmploymentSummary


class VacationResp(BaseModel):
    employee_id: Optional[str] = None
    starting_balance: Optional[float] = None
    current_balance: Optional[float] = None
    instructions: Optional[str] = None

# =========================
# Routes
# =========================
@app.post("/ask-file",response_model=AskResp,summary="Ask HR policy questions using the Employee Handbook")
async def ask_file(req: AskReq = Body(...)):
    """
    Handbook-based HR questions. Use this when the user asks about PTO policy, benefits, time-off rules, or other HR procedures documented in the employee handbook.
    
    Ask HR policy questions against the Employee Handbook via GIA, with optional OpenAI post-processing.

    Returns: 
        A structured response containing the answer to the HR policy question, along with relevant sources from the Employee Handbook.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]

    q_preview = (req.question or "").replace("\n", " ")
    if len(q_preview) > 160:
        q_preview = q_preview[:160] + "…"

    logger.debug(
        "ask_file[%s] incoming model=%s stream=%s q_preview=%r",
        rid,
        req.model,
        bool(req.stream),
        q_preview,
    )

    key = await get_service_token(client, JWT)
    model_id = await ensure_model(client, req.model, JWT, MODEL_ALIAS)
    logger.debug("ask_file[%s] resolved_model=%s", rid, model_id)

    if not HARDCODED_FILE_ID and get_debug_mode():
        logger.warning(
            "ask_file[%s] HARDCODED_FILE_ID is not set; request may fail", rid
        )

    payload = {
        "model": model_id,
        "stream": bool(req.stream),
        "messages": [{"role": "user", "content": req.question}],
        "files": [{"id": HARDCODED_FILE_ID, "type": "file", "status": "processed"}],
    }
    logger.debug(
        f"~~~ payload: {payload} ~~~",
    )

    owui_resp = await post_chat_completions(client, payload)
    logger.debug(f"~~~ owui_resp: {owui_resp} ~~~")
    logger.debug(
        "ask_file[%s] received OWUI response keys=%s",
        rid,
        (
            list(owui_resp.keys())
            if isinstance(owui_resp, dict)
            else type(owui_resp).__name__
        ),
    )

    # Normalize OWUI output
    normalized_text, sources = normalize_owui_response(owui_resp)
    logger.debug(
        "ask_file[%s] normalized len=%d sources=%d",
        rid,
        len(normalized_text or ""),
        len(sources or []),
    )

    logger.debug("ask_file[%s] done", rid)
    logger.debug(f"This is the normalized_text: {normalized_text}")

    return {
        "normalized_text": normalized_text,
        "sources": sources,
        "instructions": (
            "Your response requires source mapping to the Employee Handbook and must include the page number(s) where the information was found. "
            f"Use {sources} to map page numbers to show employees where to find the information the link to the handbook is: https://gspnet4.sharepoint.com/sites/HR/Shared%20Documents/employee-handbook.pdf. "
            "DO NOT make up content - if you cannot find an answer, state the you cannot find the answer and refer the user to the Employee Handbook, their HRP, or contact hr@greshamsmith.com. "
        ),
    }


@app.post("/get-my-leadership",response_model=EmploymentResp,summary="Get my leadership & employment details")
async def ask_employment_details(req: AskReq = Body(...)):
    """
    Employee-specific leadership details. Use this when the user asks *who* their HRP, Director, MVP/EVP, or CLL is, or requests personal employment details like hire date, employee ID, nomination level/date, or length of service.

    Returns: 
        A structured response containing the employee's leadership details and relevant employment information.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_employment_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    # 1) Get token (if your Flow requires it)
    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )

    # 3) Build structured, market-aware response
    payload = build_employment_payload(employee_details)
    return payload

@app.post("/get-my-vacation", response_model=VacationResp, summary="Get my vacation details")
async def ask_vacation_details(req: AskReq = Body(...)):
    """
    Employee-specific vacation details. Use this when the user asks about their vacation balance, upcoming time off, or related inquiries.

    Returns: 
        A structured response containing the employee's vacation details and relevant information.
    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_vacation_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )
    logger.debug(f"This is the employee details: {employee_details}")
    vp_token_response = await get_vantagepoint_token()
    if not vp_token_response:
        raise HTTPException(
            status_code=502, detail="Vantagepoint API token retrieval failed"
        )
    logger.debug(f"[GET Vantagepoint API Token: {vp_token_response}]")
    body = {
        "EEID": employee_details.get("EmployeeID")
    }
    vacation_details = await get_vacation_days(body, vp_token_response.get("access_token"))

    if not vacation_details:
        raise HTTPException(
            status_code=502, detail="Vantagepoint Stored Procedure returned no data"
        )
    
    linked_call = AskReq(
        question=f"What is my PTO accrual rate for {employee_details.get('YearsWithGreshamSmith')} and {employee_details.get('CLL')}",
        model=req.model,
        stream=True
    )
    
    return {
        "employee_id": vacation_details.get("employee_id"),
        "starting_balance": vacation_details.get("starting_balance"),
        "current_balance": vacation_details.get("current_balance"),
        "instructions": (
            "The return values are in hours - show the results in hours and days. Our standard work day is 8 hours. "
            "If no vacation balance is found, refer the user to their HRP or manager - do not offer to refer to the servicedesk@greshamsmith.com."
            f"Refer to the \"/ask-file\" endpoint for a breakdown on accrual details for individual employees using a company tenure using: {linked_call} "
            )
    }



File: .supporting_items\.old_scripts\main_clean.py
--------------------------------------------------
Content of .supporting_items\.old_scripts\main_clean.py:
from typing import Optional
import os, json, logging, sys, uuid

import httpx

from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

from utils.config import TOOL_NAME
from utils.environment import (
    log_environment_config, 
    validate_required_env,
    get_owui_url,
    get_owui_jwt,
    get_hardcoded_file_id,
    get_debug_mode
)
from utils.api_models import AskReq, AskResp
from utils.employment_data import EmploymentResp, build_employment_payload
from utils.vacation_data import VacationResp
from utils.http_client import ensure_model, post_chat_completions
from utils.response_processor import normalize_owui_response
from auth import (
    get_service_token,
    get_current_user_email,
    get_graph_token_async,
    call_pa_workflow_async,
    get_vantagepoint_token
)
from utils.vantagepoint import get_vacation_days

load_dotenv()

# =========================
# App & Logging
# =========================
app = FastAPI(
    title="HR Handbook and Policy MCP for GIA",
    version="0.0.1",
    description="MCP Server to retrieve HR policies and employee information.",
)

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.DEBUG if get_debug_mode() else logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stdout,
)
logger = logging.getLogger(TOOL_NAME)

# =========================
# Config / HTTP client
# =========================
OWUI = get_owui_url()
JWT = get_owui_jwt()
HARDCODED_FILE_ID = get_hardcoded_file_id()

# Optional: map your requested model name to an OWUI-registered model id.
# Example: MODEL_ALIAS_JSON='{"gpt-5":"gpt-5o"}'
MODEL_ALIAS = {"gpt-5": "gpt-5"}  # or "gpt-5o" if that's the registered ID

# Shared async client (init on startup)
client: httpx.AsyncClient | None = None

# Log environment configuration
log_environment_config(logger)

# Validate required environment variables
validate_required_env()


@app.on_event("startup")
async def _startup():
    global client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    logger.info("HTTP client initialized for GIA at %s", OWUI)


@app.on_event("shutdown")
async def _shutdown():
    global client
    if client:
        await client.aclose()
        logger.info("HTTP client closed")


# =========================
# Routes
# =========================
@app.post("/ask-file", response_model=AskResp, summary="Ask HR policy questions using the Employee Handbook")
async def ask_file(req: AskReq = Body(...)):
    """
    Handbook-based HR questions. Use this when the user asks about PTO policy, benefits, time-off rules, or other HR procedures documented in the employee handbook.
    
    Ask HR policy questions against the Employee Handbook via GIA, with optional OpenAI post-processing.

    Returns: 
        A structured response containing the answer to the HR policy question, along with relevant sources from the Employee Handbook.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]

    q_preview = (req.question or "").replace("\n", " ")
    if len(q_preview) > 160:
        q_preview = q_preview[:160] + "…"

    logger.debug(
        "ask_file[%s] incoming model=%s stream=%s q_preview=%r",
        rid,
        req.model,
        bool(req.stream),
        q_preview,
    )

    key = await get_service_token(client, JWT)
    model_id = await ensure_model(client, req.model, JWT, MODEL_ALIAS)
    logger.debug("ask_file[%s] resolved_model=%s", rid, model_id)

    if not HARDCODED_FILE_ID and get_debug_mode():
        logger.warning(
            "ask_file[%s] HARDCODED_FILE_ID is not set; request may fail", rid
        )

    payload = {
        "model": model_id,
        "stream": bool(req.stream),
        "messages": [{"role": "user", "content": req.question}],
        "files": [{"id": HARDCODED_FILE_ID, "type": "file", "status": "processed"}],
    }
    logger.debug(
        f"~~~ payload: {payload} ~~~",
    )

    owui_resp = await post_chat_completions(client, payload)
    logger.debug(f"~~~ owui_resp: {owui_resp} ~~~")
    logger.debug(
        "ask_file[%s] received OWUI response keys=%s",
        rid,
        (
            list(owui_resp.keys())
            if isinstance(owui_resp, dict)
            else type(owui_resp).__name__
        ),
    )

    # Normalize OWUI output
    normalized_text, sources = normalize_owui_response(owui_resp)
    logger.debug(
        "ask_file[%s] normalized len=%d sources=%d",
        rid,
        len(normalized_text or ""),
        len(sources or []),
    )

    logger.debug("ask_file[%s] done", rid)
    logger.debug(f"This is the normalized_text: {normalized_text}")

    return {
        "normalized_text": normalized_text,
        "sources": sources,
        "instructions": (
            "Your response requires source mapping to the Employee Handbook and must include the page number(s) where the information was found. "
            f"Use {sources} to map page numbers to show employees where to find the information the link to the handbook is: https://gspnet4.sharepoint.com/sites/HR/Shared%20Documents/employee-handbook.pdf. "
            "DO NOT make up content - if you cannot find an answer, state the you cannot find the answer and refer the user to the Employee Handbook, their HRP, or contact hr@greshamsmith.com. "
        ),
    }


@app.post("/get-my-leadership", response_model=EmploymentResp, summary="Get my leadership & employment details")
async def ask_employment_details(req: AskReq = Body(...)):
    """
    Employee-specific leadership details. Use this when the user asks *who* their HRP, Director, MVP/EVP, or CLL is, or requests personal employment details like hire date, employee ID, nomination level/date, or length of service.

    Returns: 
        A structured response containing the employee's leadership details and relevant employment information.

    Raises: 
        HTTPException if the request fails or if no relevant information is found.

    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_employment_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    # 1) Get token (if your Flow requires it)
    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )

    # 3) Build structured, market-aware response
    payload = build_employment_payload(employee_details)
    return payload


@app.post("/get-my-vacation", response_model=VacationResp, summary="Get my vacation details")
async def ask_vacation_details(req: AskReq = Body(...)):
    """
    Employee-specific vacation details. Use this when the user asks about their vacation balance, upcoming time off, or related inquiries.

    Returns: 
        A structured response containing the employee's vacation details and relevant information.
    """
    rid = uuid.uuid4().hex[:8]
    logger.debug("ask_vacation_details[%s] model=%s", rid, req.model)
    logger.debug(f"{'~' * 25}This is the request: {req}")

    graph_auth = await get_graph_token_async()
    key = await get_service_token(client, JWT)

    current_user = await get_current_user_email(client, key)
    email = current_user.get("email")
    payload = {"CompanyEmailAddress": email}
    employee_details = await call_pa_workflow_async(payload, graph_auth)
    if not employee_details:
        raise HTTPException(
            status_code=502, detail="Power Automate workflow returned no data"
        )
    logger.debug(f"This is the employee details: {employee_details}")
    vp_token_response = await get_vantagepoint_token()
    if not vp_token_response:
        raise HTTPException(
            status_code=502, detail="Vantagepoint API token retrieval failed"
        )
    logger.debug(f"[GET Vantagepoint API Token: {vp_token_response}]")
    body = {
        "EEID": employee_details.get("EmployeeID")
    }
    vacation_details = await get_vacation_days(body, vp_token_response.get("access_token"))

    if not vacation_details:
        raise HTTPException(
            status_code=502, detail="Vantagepoint Stored Procedure returned no data"
        )
    
    linked_call = AskReq(
        question=f"What is my PTO accrual rate for {employee_details.get('YearsWithGreshamSmith')} and {employee_details.get('CLL')}",
        model=req.model,
        stream=True
    )
    
    return {
        "employee_id": vacation_details.get("employee_id"),
        "starting_balance": vacation_details.get("starting_balance"),
        "current_balance": vacation_details.get("current_balance"),
        "instructions": (
            "The return values are in hours - show the results in hours and days. Our standard work day is 8 hours. "
            "If no vacation balance is found, refer the user to their HRP or manager - do not offer to refer to the servicedesk@greshamsmith.com."
            f"Refer to the \"/ask-file\" endpoint for a breakdown on accrual details for individual employees using a company tenure using: {linked_call} "
            )
    }


File: auth\graph_auth.py
--------------------------------------------------
Content of auth\graph_auth.py:
# Microsoft Graph Authentication Script
import httpx
import logging
import os
from typing import Optional
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

async def get_graph_token_async() -> Optional[str]:
    """
    Acquire Microsoft Graph token for client credentials flow.
    Returns access token or None if acquisition fails.
    """
    GRAPH_TOKEN_URL = os.environ.get("GRAPH_TOKEN_URL")
    GRAPH_CLIENT_ID = os.environ.get("GRAPH_CLIENT_ID")
    GRAPH_SECRET = os.environ.get("GRAPH_SECRET")
    
    if not all([GRAPH_TOKEN_URL, GRAPH_CLIENT_ID, GRAPH_SECRET]):
        logger.error("GRAPH_* env vars missing; cannot acquire token")
        return None

    data = {
        "grant_type": "client_credentials",
        "client_id": GRAPH_CLIENT_ID,
        "client_secret": GRAPH_SECRET,
        # Power Automate resource (Flow) – confirm in your tenant; this often works:
        "scope": "https://service.flow.microsoft.com//.default",
    }

    try:
        async with httpx.AsyncClient(timeout=30) as ac:
            r = await ac.post(
                GRAPH_TOKEN_URL,
                data=data,
                headers={"Content-Type": "application/x-www-form-urlencoded"},
            )
        r.raise_for_status()
        token = r.json().get("access_token")
        if not token:
            logger.error("No access_token in token response: %s", r.text[:400])
        return token
    except httpx.HTTPError as e:
        logger.error("Failed to obtain token: %s", e)
        return None


File: auth\power_automate_auth.py
--------------------------------------------------
Content of auth\power_automate_auth.py:
# Power Automate Workflow Authentication and Communication Script
import httpx
import logging
import json
import os
from typing import Optional, Dict, Any
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

async def call_pa_workflow_async(payload: Dict[str, Any], token: Optional[str]) -> Optional[Dict[str, Any]]:
    """
    Call Power Automate workflow with optional authentication token.
    
    Args:
        payload: JSON payload to send to the workflow
        token: Optional bearer token for authentication
        
    Returns:
        Response JSON dict or None if call fails
    """
    logger.debug(f"call_pa_workflow_async payload: {json.dumps(payload, indent=2)} token: {'set' if token else 'unset'}")
    
    PA_URL = os.environ.get("PA_URL")
    if not PA_URL:
        logger.error("PA_URL not set")
        return None

    headers = {"Content-Type": "application/json"}
    # If your Flow is protected by Entra ID / custom connector, include the bearer:
    if token:
        headers["Authorization"] = f"Bearer {token}"

    try:
        async with httpx.AsyncClient(timeout=60) as ac:
            # r = await ac.post(PA_URL, json=payload, headers=headers)
            r = await ac.post(PA_URL, json=payload)
        if r.status_code == 200:
            return r.json()
        logger.error("PA workflow call failed %s: %s", r.status_code, r.text[:400])
        return None
    except httpx.HTTPError as e:
        logger.error("PA workflow call error: %s", e)
        return None


File: auth\service_auth.py
--------------------------------------------------
Content of auth\service_auth.py:
# Service Authentication Script
import httpx
import logging
import os
from fastapi import HTTPException
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

async def get_service_token(client: httpx.AsyncClient, jwt: str) -> str:
    """
    Exchange the bootstrap JWT for a service/API token via /api/v1/auths/api_key.
    Caches the token. Returns (token, token_type).
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")

    # Your env expects GET here; Accept JSON; client already has Bearer <JWT>
    try:
        r = await client.get("/api/v1/auths/api_key", headers={"Accept": "application/json", "Authorization": f"Bearer {jwt}"})
        r.raise_for_status()
        payload = r.json()
    except httpx.HTTPError as e:
        logger.error("Failed to fetch /api/v1/auths/api_key: %s", e)
        raise HTTPException(status_code=502, detail=f"GIA /api/v1/auths/api_key error: {e}")
    except Exception as e:
        logger.exception("Non-HTTP error parsing /api/v1/auths/api_key")
        raise HTTPException(status_code=502, detail=f"Bad /api/v1/auths/api_key payload: {e}")

    # Token fields per your sample: { "token": "...", "token_type": "Bearer", "email": ... }
    key = payload.get("api_key")
    if not key:
        raise HTTPException(status_code=502, detail="No 'api_key' in /api/v1/auths/ response")

    logger.debug(f"Returned key is: {key}")
    return key


async def get_current_user_email(client: httpx.AsyncClient, key: str) -> str:
    """
    Fetch the authenticated user's email from OWUI /api/v1/auths/.
    Uses service token if available, otherwise the bootstrap JWT.
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")

    # We can also refresh service token here; but GET works with JWT in many setups.
    try:
        r = await client.get("/api/v1/auths/", headers={"Accept": "application/json", "Authorization": f"Bearer {key}"})
        r.raise_for_status()
        payload = r.json()
    except httpx.HTTPError as e:
        logger.error("Failed to fetch /api/v1/auths/: %s", e)
        raise HTTPException(status_code=502, detail=f"GIA /api/v1/auths/ error: {e}")

    if not payload:
        raise HTTPException(status_code=502, detail="No payload in /api/v1/auths/ response")
    return payload


File: auth\vp_auth.py
--------------------------------------------------
Content of auth\vp_auth.py:
# Vantagepoint Authentication Script
import httpx
from utils import config
from urllib.parse import urlencode
import os
from dotenv import load_dotenv

load_dotenv()

VP_BASE_URL = os.environ.get("VP_BASE_URL")
VP_USERNAME = os.environ.get("VP_USERNAME")
VP_PASSWORD = os.environ.get("VP_PASSWORD")
VP_DATABASE = os.environ.get("VP_DATABASE")
VP_CLIENT_ID = os.environ.get("VP_CLIENT_ID")
VP_CLIENT_SECRET = os.environ.get("VP_CLIENT_SECRET")

async def get_vantagepoint_token():
    """
    Authenticate with Vantagepoint API and return the access token response.
    """
    url = f"{VP_BASE_URL}/api/token"
    payload_dict = {
        "Username": VP_USERNAME,
        "Password": VP_PASSWORD,
        "grant_type": "password",
        "Integrated": "N",
        "database": VP_DATABASE,
        "Client_Id": VP_CLIENT_ID,
        "client_secret": VP_CLIENT_SECRET,
    }
    payload = urlencode(payload_dict)
    headers = {
        "Content-Type": "application/x-www-form-urlencoded"
    }
    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers, data=payload)
        response.raise_for_status()
        return response.json()

if __name__ == "__main__":
    import asyncio
    token_response = asyncio.run(get_vantagepoint_token())
    print(token_response)


File: auth\__init__.py
--------------------------------------------------
Content of auth\__init__.py:
# Authentication Module - Central import for all auth functions
"""
Authentication module providing centralized access to all authentication functions.
Import this module to access authentication functionality across the application.
"""

from .service_auth import get_service_token, get_current_user_email
from .graph_auth import get_graph_token_async
from .power_automate_auth import call_pa_workflow_async
from .vp_auth import get_vantagepoint_token

__all__ = [
    'get_service_token',
    'get_current_user_email', 
    'get_graph_token_async',
    'call_pa_workflow_async',
    'get_vantagepoint_token'
]


File: test_scripts\simple_test_service_token.py
--------------------------------------------------
Content of test_scripts\simple_test_service_token.py:
"""
Simple test script for the get_service_token function.
This is a basic test to verify the service token functionality.
"""
import sys
import os
import asyncio
import httpx
from dotenv import load_dotenv

# Add the parent directory to the path so we can import from main
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

load_dotenv()

async def test_service_token():
    """Simple test for get_service_token function"""
    from main import OWUI, JWT
    
    print("Testing get_service_token()...")
    print(f"GIA URL: {OWUI}")
    print(f"JWT available: {'Yes' if JWT else 'No'}")
    
    if not JWT:
        print("ERROR: OWUI_JWT environment variable is required!")
        return
    
    # Initialize HTTP client
    client = httpx.AsyncClient(
        base_url=OWUI,
        headers={"Authorization": f"Bearer {JWT}"},
        timeout=60,
    )
    
    try:
        # Import and test the function
        from main import get_service_token
        
        # Set the global client (since the function expects it)
        import main
        main.client = client
        
        # Call the function
        service_token = await get_service_token()
        
        if service_token:
            print(f"✅ Success! Service token obtained")
            print(f"Token length: {len(service_token)}")
            print(f"Token preview: {service_token[:30]}...")
            
            # Test the token with a simple API call
            headers = {"Accept": "application/json", "Authorization": f"Bearer {service_token}"}
            response = await client.get("/api/models", headers=headers)
            
            print(f"API test status: {response.status_code}")
            if response.status_code == 200:
                print("✅ Service token works with API!")
                print(f"Response data: {response.json()}")
            else:
                print(f"⚠️  API call returned: {response.status_code}")
                
        else:
            print("❌ Failed to obtain service token")
            
    except Exception as e:
        print(f"❌ Error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await client.aclose()


if __name__ == "__main__":
    asyncio.run(test_service_token())


File: test_scripts\test_current_user_email.py
--------------------------------------------------
Content of test_scripts\test_current_user_email.py:
"""
Test script for the get_current_user_email function.
This script tests the live get_current_user_email function to identify and fix issues.
"""
import sys
import os
import asyncio
import httpx
from dotenv import load_dotenv

# Add the parent directory to the path so we can import from main
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Load environment variables
load_dotenv()

async def test_get_current_user_email():
    """Test the get_current_user_email function directly"""
    try:
        # Import the function and required variables
        from main import get_current_user_email, get_service_token, OWUI, JWT
        
        print("=" * 60)
        print("TESTING get_current_user_email() FUNCTION")
        print("=" * 60)
        
        # Check environment setup
        print(f"GIA_URL (OWUI): {OWUI}")
        print(f"JWT available: {'Yes' if JWT else 'No'}")
        print()
        
        if not JWT:
            print("❌ ERROR: OWUI_JWT environment variable is not set!")
            return False
        
        # Initialize the HTTP client (mimicking the startup event)
        print("🔄 Initializing HTTP client...")
        import main
        main.client = httpx.AsyncClient(
            base_url=OWUI,
            headers={"Authorization": f"Bearer {JWT}"},
            timeout=60,
        )
        print("✅ HTTP client initialized")
        
        print()
        print("🔄 First, getting service token...")
        
        # Get service token first
        service_token = await get_service_token()
        
        if service_token:
            print("✅ Service token obtained")
            print(f"Service token preview: {service_token[:20] + '...' if len(service_token) > 20 else service_token}")
            
            print()
            print("🔄 Testing get_current_user_email() with service token...")
            
            # Test with service token
            try:
                email = await get_current_user_email(service_token)
                print(f"✅ SUCCESS: Email obtained with service token: {email}")
            except Exception as e:
                print(f"❌ FAILED with service token: {e}")
                print(f"Exception type: {type(e).__name__}")
                import traceback
                traceback.print_exc()
            
            print()
            print("🔄 Testing get_current_user_email() with JWT...")
            
            # Test with JWT
            try:
                email = await get_current_user_email(JWT)
                print(f"✅ SUCCESS: Email obtained with JWT: {email}")
                return True
            except Exception as e:
                print(f"❌ FAILED with JWT: {e}")
                print(f"Exception type: {type(e).__name__}")
                import traceback
                traceback.print_exc()
                return False
        else:
            print("❌ Could not obtain service token")
            return False
            
    except Exception as e:
        print(f"❌ ERROR during testing: {str(e)}")
        print(f"Exception type: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Clean up the client if we created it
        import main
        if hasattr(main, 'client') and main.client:
            await main.client.aclose()
            print("🧹 HTTP client closed")


if __name__ == "__main__":
    # Run the async main function
    result = asyncio.run(test_get_current_user_email())
    
    # Exit with appropriate code
    sys.exit(0 if result else 1)


File: test_scripts\test_graph_and_pa.py
--------------------------------------------------
Content of test_scripts\test_graph_and_pa.py:
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from main import get_graph_token, call_pa_workflow

def main():
    email = "smiley.baltz@greshamsmith.com"
    print(f"Testing get_graph_token()...")
    token = get_graph_token()
    print(f"Token: {token}")
    if not token:
        print("Failed to obtain token. Aborting workflow call.")
        return
    print(f"Testing call_pa_workflow() with email: {email}")
    response = call_pa_workflow(email)
    print(f"Workflow response: {response}")

if __name__ == "__main__":
    main()


File: test_scripts\test_graph_token.py
--------------------------------------------------
Content of test_scripts\test_graph_token.py:
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from main import get_graph_token

def main():
    token = get_graph_token()
    if token:
        print(f"Access token: {token}")
    else:
        print("Failed to obtain token.")

if __name__ == "__main__":
    main()


File: test_scripts\test_service_token.py
--------------------------------------------------
Content of test_scripts\test_service_token.py:
"""
Test script for the get_service_token function.
This script tests the live get_service_token function to ensure it's returning actual data from the app instance.
"""
import sys
import os
import asyncio
import httpx
from dotenv import load_dotenv

# Add the parent directory to the path so we can import from main
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Load environment variables
load_dotenv()

async def test_get_service_token():
    """Test the get_service_token function directly"""
    try:
        # Import the function and required variables
        from main import get_service_token, OWUI, JWT
        
        print("=" * 60)
        print("TESTING get_service_token() FUNCTION")
        print("=" * 60)
        
        # Check environment setup
        print(f"GIA_URL (OWUI): {OWUI}")
        print(f"JWT available: {'Yes' if JWT else 'No'}")
        print(f"JWT preview: {JWT[:20] + '...' if JWT and len(JWT) > 20 else 'Not available'}")
        print()
        
        if not JWT:
            print("❌ ERROR: OWUI_JWT environment variable is not set!")
            return False
        
        # Initialize the HTTP client (mimicking the startup event)
        print("🔄 Initializing HTTP client...")
        global client
        from main import client
        if client is None:
            client = httpx.AsyncClient(
                base_url=OWUI,
                headers={"Authorization": f"Bearer {JWT}"},
                timeout=60,
            )
            print("✅ HTTP client initialized")
        else:
            print("✅ HTTP client already initialized")
        
        print()
        print("🔄 Testing get_service_token()...")
        
        # Call the function
        service_token = await get_service_token()
        
        if service_token:
            print("✅ SUCCESS: Service token obtained!")
            print(f"Token type: {type(service_token)}")
            print(f"Token length: {len(service_token) if isinstance(service_token, str) else 'N/A'}")
            print(f"Token preview: {service_token[:20] + '...' if isinstance(service_token, str) and len(service_token) > 20 else service_token}")
            
            # Validate token format (should be a non-empty string)
            if isinstance(service_token, str) and len(service_token) > 0:
                print("✅ Token format validation: PASSED")
                return True
            else:
                print("❌ Token format validation: FAILED - Token should be a non-empty string")
                return False
        else:
            print("❌ FAILED: No service token obtained")
            return False
            
    except Exception as e:
        print(f"❌ ERROR during testing: {str(e)}")
        print(f"Exception type: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Clean up the client if we created it
        if 'client' in locals() and client:
            await client.aclose()
            print("🧹 HTTP client closed")


async def test_service_token_with_api_call():
    """Test using the service token to make an actual API call"""
    try:
        from main import get_service_token, OWUI, JWT
        
        print("\n" + "=" * 60)
        print("TESTING SERVICE TOKEN WITH API CALL")
        print("=" * 60)
        
        # Initialize client
        client = httpx.AsyncClient(
            base_url=OWUI,
            headers={"Authorization": f"Bearer {JWT}"},
            timeout=60,
        )
        
        # Get service token
        print("🔄 Getting service token...")
        service_token = await get_service_token()
        
        if not service_token:
            print("❌ Could not obtain service token for API test")
            return False
        
        print("✅ Service token obtained for API test")
        
        # Test the token by making an API call to /api/models
        print("🔄 Testing service token with /api/models endpoint...")
        
        try:
            headers = {
                "Accept": "application/json",
                "Authorization": f"Bearer {service_token}"
            }
            
            response = await client.get("/api/models", headers=headers)
            
            print(f"API Response Status: {response.status_code}")
            
            if response.status_code == 200:
                print("✅ SUCCESS: Service token works with API!")
                
                # Try to parse the response
                try:
                    data = response.json()
                    print(f"Response type: {type(data)}")
                    if isinstance(data, list):
                        print(f"Number of models: {len(data)}")
                        if data:
                            print(f"First model preview: {data[0] if len(str(data[0])) < 100 else str(data[0])[:100] + '...'}")
                    elif isinstance(data, dict):
                        print(f"Response keys: {list(data.keys())}")
                    else:
                        print(f"Response preview: {str(data)[:200]}...")
                except Exception as parse_error:
                    print(f"⚠️  Could not parse JSON response: {parse_error}")
                    print(f"Raw response (first 200 chars): {response.text[:200]}...")
                
                return True
            else:
                print(f"❌ API call failed with status {response.status_code}")
                print(f"Response: {response.text[:200]}...")
                return False
                
        except httpx.HTTPError as api_error:
            print(f"❌ HTTP error during API call: {api_error}")
            return False
            
    except Exception as e:
        print(f"❌ ERROR during API testing: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        if 'client' in locals() and client:
            await client.aclose()


async def main():
    """Main test function"""
    print("🚀 Starting Service Token Test Suite")
    print(f"Timestamp: {asyncio.get_event_loop().time()}")
    print()
    
    # Test 1: Basic service token functionality
    test1_result = await test_get_service_token()
    
    # Test 2: Service token with actual API call
    test2_result = await test_service_token_with_api_call()
    
    # Summary
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    print(f"Test 1 (get_service_token): {'✅ PASSED' if test1_result else '❌ FAILED'}")
    print(f"Test 2 (API call with token): {'✅ PASSED' if test2_result else '❌ FAILED'}")
    
    overall_result = test1_result and test2_result
    print(f"\nOverall Result: {'✅ ALL TESTS PASSED' if overall_result else '❌ SOME TESTS FAILED'}")
    
    return overall_result


if __name__ == "__main__":
    # Run the async main function
    result = asyncio.run(main())
    
    # Exit with appropriate code
    sys.exit(0 if result else 1)


File: test_scripts\test_vp_auth_live.py
--------------------------------------------------
Content of test_scripts\test_vp_auth_live.py:
#!/usr/bin/env python3
"""
Live test script for Vantagepoint Authentication
Tests the actual authentication endpoint with real credentials
"""

import sys
import os
from datetime import datetime
import json

# Add the parent directory to the path so we can import from auth module
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from auth.vp_auth import get_vantagepoint_token
import httpx

def test_vp_authentication():
    """
    Test the Vantagepoint authentication with live data
    """
    print("=" * 60)
    print("VANTAGEPOINT AUTHENTICATION LIVE TEST")
    print("=" * 60)
    print(f"Test started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Check if required environment variables are set
    required_env_vars = [
        "VP_BASE_URL",
        "VP_USERNAME", 
        "VP_PASSWORD",
        "VP_DATABASE",
        "VP_CLIENT_ID",
        "VP_CLIENT_SECRET"
    ]
    
    print("Checking environment variables...")
    missing_vars = []
    for var in required_env_vars:
        value = os.environ.get(var)
        if value:
            if var in ["VP_PASSWORD", "VP_CLIENT_SECRET"]:
                print(f"✓ {var}: {'*' * len(value)}")  # Mask sensitive data
            else:
                print(f"✓ {var}: {value}")
        else:
            missing_vars.append(var)
            print(f"✗ {var}: NOT SET")
    
    if missing_vars:
        print(f"\nERROR: Missing required environment variables: {', '.join(missing_vars)}")
        print("Please set these variables in your .env file or environment.")
        return False
    
    print("\n" + "-" * 60)
    print("ATTEMPTING AUTHENTICATION...")
    print("-" * 60)
    
    try:
        # Call the authentication function
        token_response = get_vantagepoint_token()
        
        print("✓ Authentication successful!")
        print("\nResponse details:")
        print("-" * 30)
        
        # Pretty print the response
        for key, value in token_response.items():
            if key.lower() in ['access_token', 'refresh_token', 'token']:
                # Mask tokens for security but show first/last few characters
                if isinstance(value, str) and len(value) > 10:
                    masked_value = f"{value[:6]}...{value[-6:]}"
                    print(f"{key}: {masked_value}")
                else:
                    print(f"{key}: {'*' * 8}")
            else:
                print(f"{key}: {value}")
        
        # Additional token analysis
        print("\n" + "-" * 30)
        print("TOKEN ANALYSIS:")
        print("-" * 30)
        
        if 'access_token' in token_response:
            token = token_response['access_token']
            print(f"Access token length: {len(token)} characters")
            print(f"Token type: {type(token).__name__}")
        
        if 'expires_in' in token_response:
            expires_in = token_response['expires_in']
            print(f"Token expires in: {expires_in} seconds ({expires_in/3600:.1f} hours)")
        
        if 'token_type' in token_response:
            print(f"Token type: {token_response['token_type']}")
        
        return True
        
    except httpx.HTTPStatusError as e:
        print(f"✗ HTTP Error occurred:")
        print(f"  Status Code: {e.response.status_code}")
        print(f"  Reason: {e.response.reason_phrase}")
        print(f"  URL: {e.request.url}")
        
        try:
            error_detail = e.response.json()
            print(f"  Error Detail: {json.dumps(error_detail, indent=2)}")
        except:
            print(f"  Response Text: {e.response.text}")
        
        return False
        
    except httpx.RequestError as e:
        print(f"✗ Request Error occurred:")
        print(f"  Error: {str(e)}")
        print("  This could be a network connectivity issue or invalid URL.")
        return False
        
    except Exception as e:
        print(f"✗ Unexpected error occurred:")
        print(f"  Error Type: {type(e).__name__}")
        print(f"  Error Message: {str(e)}")
        return False

def test_endpoint_connectivity():
    """
    Test basic connectivity to the Vantagepoint endpoint
    """
    print("\n" + "=" * 60)
    print("ENDPOINT CONNECTIVITY TEST")
    print("=" * 60)
    
    base_url = os.environ.get("VP_BASE_URL")
    if not base_url:
        print("✗ VP_BASE_URL not set")
        return False
    
    print(f"Testing connectivity to: {base_url}")
    
    try:
        # Test basic connectivity
        response = httpx.get(base_url, timeout=10.0)
        print(f"✓ Endpoint is reachable")
        print(f"  Status Code: {response.status_code}")
        print(f"  Response Headers: {dict(response.headers)}")
        return True
        
    except httpx.TimeoutException:
        print(f"✗ Timeout connecting to {base_url}")
        return False
        
    except httpx.RequestError as e:
        print(f"✗ Connection error: {str(e)}")
        return False
        
    except Exception as e:
        print(f"✗ Unexpected error: {str(e)}")
        return False

if __name__ == "__main__":
    print("Starting Vantagepoint Authentication Live Tests...")
    print()
    
    # Test endpoint connectivity first
    connectivity_ok = test_endpoint_connectivity()
    
    # Test authentication
    auth_ok = test_vp_authentication()
    
    # Summary
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    print(f"Endpoint Connectivity: {'✓ PASS' if connectivity_ok else '✗ FAIL'}")
    print(f"Authentication Test: {'✓ PASS' if auth_ok else '✗ FAIL'}")
    print(f"Overall Result: {'✓ ALL TESTS PASSED' if (connectivity_ok and auth_ok) else '✗ SOME TESTS FAILED'}")
    print(f"Test completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Exit with appropriate code
    sys.exit(0 if (connectivity_ok and auth_ok) else 1)


File: test_scripts\__pycache__\test_auth_imports.py
--------------------------------------------------
Content of test_scripts\__pycache__\test_auth_imports.py:
# Test script to verify auth module imports work correctly
"""
Simple test to verify that all authentication functions can be imported correctly
from the new auth module structure.
"""

try:
    # Test importing from the main auth module
    from auth import (
        get_service_token,
        get_current_user_email,
        get_graph_token_async,
        call_pa_workflow_async,
        get_vantagepoint_token
    )
    print("✅ Successfully imported all auth functions from main auth module")
    
    # Test importing from individual modules
    from auth.service_auth import get_service_token, get_current_user_email
    from auth.graph_auth import get_graph_token_async
    from auth.power_automate_auth import call_pa_workflow_async
    from auth.vp_auth import get_vantagepoint_token
    print("✅ Successfully imported all auth functions from individual modules")
    
    # Test importing vantagepoint utilities
    from utils.vantagepoint import get_vacation_days
    print("✅ Successfully imported vantagepoint utilities")
    
    print("\n🎉 All authentication modules are properly structured and importable!")
    
except ImportError as e:
    print(f"❌ Import error: {e}")
except Exception as e:
    print(f"❌ Unexpected error: {e}")


File: utils\api_models.py
--------------------------------------------------
Content of utils\api_models.py:
# Pydantic models for API requests and responses
from typing import Optional, List
from pydantic import BaseModel, Field


class AskReq(BaseModel):
    question: str = Field(..., description="User question")
    model: str = Field(
        "gpt-5", description="Model id as registered in GIA (/api/models)"
    )
    stream: bool = Field(True, description="Use streamed responses (server-side)")


class AskResp(BaseModel):
    normalized_text: Optional[str] = None
    sources: Optional[list] = None
    instructions: Optional[str] = None


File: utils\config.py
--------------------------------------------------
Content of utils\config.py:
# app/config.py

import os
from dotenv import load_dotenv

# Load .env once at startup
load_dotenv()

# Access values globally
TOOL_NAME = "GIA:HR POLICY"

File: utils\datetime_utils.py
--------------------------------------------------
Content of utils\datetime_utils.py:
# Date and time utilities
from typing import Optional
from datetime import datetime, timezone


def years_between(iso_date: Optional[str]) -> Optional[float]:
    """
    Calculate years between an ISO date string and now.
    
    Args:
        iso_date: ISO format date string
        
    Returns:
        Number of years as float, or None if date is invalid
    """
    if not iso_date:
        return None
    try:
        dt = datetime.fromisoformat(iso_date.replace("Z", "")).replace(
            tzinfo=timezone.utc
        )
        now = datetime.now(timezone.utc)
        return round((now - dt).days / 365.25, 2)
    except Exception:
        return None


File: utils\employment_data.py
--------------------------------------------------
Content of utils\employment_data.py:
# Data transformation utilities for employment and HR data
from typing import Optional
from pydantic import BaseModel, Field
from utils.datetime_utils import years_between


class LeadershipInfo(BaseModel):
    hrp_employee_id: Optional[str] = None
    hrp_name: Optional[str] = None
    hrp_email: Optional[str] = None
    director_id: Optional[str] = None
    director_name: Optional[str] = None
    director_email: Optional[str] = None
    mvp_id: Optional[str] = None
    mvp_name: Optional[str] = None
    mvp_email: Optional[str] = None
    evp_id: Optional[str] = None
    evp_name: Optional[str] = None
    evp_email: Optional[str] = None


class EmploymentSummary(BaseModel):
    employee_id: Optional[str] = None
    display_name: Optional[str] = None
    email: Optional[str] = None
    cll: Optional[str] = None
    market: Optional[str] = None
    department: Optional[str] = None
    nomination_level: Optional[str] = None
    nomination_date: Optional[str] = None
    latest_hire_date: Optional[str] = None
    original_hire_date: Optional[str] = None
    years_with_gresham_smith: Optional[float] = None
    los_years: Optional[float] = None


class EmploymentResp(BaseModel):
    # What we'll send back from /get-my-leadership (aka ask_employment_details)
    leadership: LeadershipInfo
    summary: EmploymentSummary


def build_employment_payload(raw: dict) -> EmploymentResp:
    """
    Build structured employment response from raw employee data.
    
    Args:
        raw: Raw employee data dictionary
        
    Returns:
        EmploymentResp: Structured employment response
    """
    # Pull top-level fields with safe defaults
    market = (raw or {}).get("Market")
    leadership = LeadershipInfo(
        hrp_employee_id=raw.get("hrpEmployeeID"),
        hrp_name=raw.get("hrpName"),
        hrp_email=raw.get("hrpEmail"),
        director_id=raw.get("Director_ID"),
        director_name=raw.get("Director_Name"),
        director_email=raw.get("Director_Email"),
        mvp_id=raw.get("MVP_ID"),
        mvp_name=raw.get("MVP_Name"),
        mvp_email=raw.get("MVP_Email"),
        evp_id=raw.get("EVP_ID"),
        evp_name=raw.get("EVP_Name"),
        evp_email=raw.get("EVP_Email"),
    )

    # If NOT Corporate Services, we care about MVP/EVP; otherwise Director is primary.
    if market and market.strip().lower() != "corporate services":
        # If MVP/EVP missing, keep Director as fallback (already populated)
        pass  # data is already in the model
    else:
        # Corporate Services → Director path (already in model)
        pass

    summary = EmploymentSummary(
        employee_id=raw.get("EmployeeID"),
        display_name=raw.get("DisplayName"),
        email=raw.get("Email"),
        cll=raw.get("CLL"),
        market=market,
        department=raw.get("Department"),
        nomination_level=raw.get("NominationLevel"),
        nomination_date=raw.get("NominationDate"),
        latest_hire_date=raw.get("LatestHireDate"),
        original_hire_date=raw.get("OriginalHireDate"),
        years_with_gresham_smith=raw.get("YearsWithGreshamSmith"),
        los_years=years_between(raw.get("LatestHireDate")),
    )

    return EmploymentResp(leadership=leadership, summary=summary)


File: utils\environment.py
--------------------------------------------------
Content of utils\environment.py:
# Environment configuration and logging utilities
import os
import json
import logging
from typing import Dict, Any
from dotenv import load_dotenv
from utils.security import mask_token

load_dotenv()


def get_environment_config() -> Dict[str, Any]:
    """
    Load and return environment configuration with masked sensitive values for logging.
    
    Returns:
        Dict containing environment configuration
    """
    return {
        "GIA_URL": os.environ.get("GIA_URL", "http://localhost:8080"),
        "OWUI_JWT": mask_token(os.environ.get("OWUI_JWT"), 10),
        "HARDCODED_FILE_ID": os.environ.get("HARDCODED_FILE_ID"),
        "OPENAI_API_KEY": mask_token(os.environ.get("OPENAI_API_KEY"), 10),
        "OPENAI_MODEL": os.environ.get("OPENAI_MODEL", "gpt-4o-mini"),
        "DEBUG": os.environ.get("DEBUG", False),
        "VP_BASE_URL": os.environ.get("VP_BASE_URL"),
        "VP_SP_GETVACATION": os.environ.get("VP_SP_GETVACATION"),
    }


def log_environment_config(logger: logging.Logger) -> None:
    """
    Log environment configuration with masked sensitive values.
    
    Args:
        logger: Logger instance to use for logging
    """
    env_vars = get_environment_config()
    logger.debug("Loaded environment variables:\n%s", json.dumps(env_vars, indent=2))


def validate_required_env() -> None:
    """
    Validate that required environment variables are set.
    
    Raises:
        RuntimeError: If required environment variables are missing
    """
    jwt = os.environ.get("OWUI_JWT")
    if not jwt:
        raise RuntimeError("OWUI_JWT is required in the environment.")


# Environment variable getters
def get_owui_url() -> str:
    return os.environ.get("GIA_URL", "http://localhost:8080")


def get_owui_jwt() -> str:
    return os.environ.get("OWUI_JWT", "")


def get_hardcoded_file_id() -> str:
    return os.environ.get("HARDCODED_FILE_ID", "")


def get_openai_api_key() -> str:
    return os.environ.get("OPENAI_API_KEY", "")


def get_openai_model() -> str:
    return os.environ.get("OPENAI_MODEL", "gpt-4o-mini")


def get_debug_mode() -> bool:
    return bool(os.environ.get("DEBUG", False))


def get_vp_base_url() -> str:
    return os.environ.get("VP_BASE_URL", "")


def get_vp_procedure() -> str:
    return os.environ.get("VP_SP_GETVACATION", "")


File: utils\http_client.py
--------------------------------------------------
Content of utils\http_client.py:
# HTTP client utilities for interacting with external APIs
import json
import logging
from typing import Dict, Any
import httpx
from fastapi import HTTPException

logger = logging.getLogger(__name__)


async def ensure_model(client: httpx.AsyncClient, model_name: str, jwt: str, model_alias: Dict[str, str]) -> str:
    """
    Ensure OWUI recognizes the requested model. Applies MODEL_ALIAS mapping.
    Handles payloads that are:
      - ["gpt-5","gpt-4o", ...]
      - [{"id":"gpt-5"}, {"name":"gpt-4o"}, ...]
      - {"models":[...]} / {"data":[...]} wrappers
      - dict-of-dicts keyed by model id
      - or even a JSON string body (sigh)
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")

    desired = model_alias.get(model_name, model_name)

    # Make sure we have the service token
    from auth import get_service_token
    await get_service_token(client, jwt)

    desired = model_alias.get(model_name, model_name)
    try:
        r = await client.get("/api/models", headers={"Accept": "application/json", "Authorization": f"Bearer {jwt}"})
        r.raise_for_status()
        payload = r.json()
    except httpx.HTTPError as e:
        logger.error("Failed to fetch models from GIA: %s", e)
        raise HTTPException(status_code=502, detail=f"GIA /api/models error: {e}")
    except Exception as e:
        logger.exception("Non-HTTP error parsing /api/models")
        raise HTTPException(status_code=502, detail=f"Bad /api/models payload: {e}")

    models_set: set[str] = set()

    def add_from_list(items):
        for item in items:
            if isinstance(item, str):
                models_set.add(item)
            elif isinstance(item, dict):
                for k in ("id", "name", "model", "slug"):
                    v = item.get(k)
                    if isinstance(v, str):
                        models_set.add(v)

    if isinstance(payload, list):
        add_from_list(payload)
    elif isinstance(payload, dict):
        for key in ("models", "data", "items", "result"):
            v = payload.get(key)
            if isinstance(v, list):
                add_from_list(v)
        if not models_set:
            # dict-of-dicts: {"gpt-5": {...}, "gpt-4o": {...}}
            if payload and all(isinstance(v, (dict, str)) for v in payload.values()):
                models_set.update(map(str, payload.keys()))
        if not models_set:
            for k in ("id", "name", "model", "slug"):
                v = payload.get(k)
                if isinstance(v, str):
                    models_set.add(v)
    elif isinstance(payload, str):
        try:
            inner = json.loads(payload)
            if isinstance(inner, list):
                add_from_list(inner)
            elif isinstance(inner, dict):
                for key in ("models", "data", "items", "result"):
                    v = inner.get(key)
                    if isinstance(v, list):
                        add_from_list(v)
        except Exception:
            models_set.add(payload)

    if not models_set:
        logger.error("Unexpected /api/models payload: %r", payload)
        raise HTTPException(status_code=502, detail="Unexpected /api/models payload")

    if desired in models_set:
        return desired

    logger.warning(
        "Requested model '%s' not registered. Available: %s",
        desired,
        sorted(models_set),
    )
    raise HTTPException(
        status_code=400,
        detail={
            "error": f"Model '{model_name}' is not registered in GIA",
            "alias_applied": desired if desired != model_name else None,
            "available_models": sorted(models_set),
        },
    )


async def post_chat_completions(client: httpx.AsyncClient, payload: dict) -> dict:
    """
    Call OWUI /api/chat/completions and be tolerant:
    - JSON response
    - SSE-ish text/event-stream containing 'data: {json}'
    - NDJSON
    - text/plain with JSON as text
    - empty body (error)
    """
    if client is None:
        raise RuntimeError("HTTP client not initialized")
    try:
        # Ask politely for JSON
        r = await client.post(
            "/api/chat/completions",
            json=payload,
            headers={"Accept": "application/json"},
        )
        r.raise_for_status()
    except httpx.HTTPStatusError as e:
        logger.error(
            "OWUI /api/chat/completions %s: %s", e.response.status_code, e.response.text
        )
        raise HTTPException(status_code=e.response.status_code, detail=e.response.text)
    except httpx.HTTPError as e:
        logger.error("HTTP error calling /api/chat/completions: %s", e)
        raise HTTPException(status_code=502, detail=str(e))

    ctype = (r.headers.get("content-type") or "").lower()

    # JSON happy path
    if "application/json" in ctype:
        try:
            return r.json()
        except Exception as e:
            logger.error(
                "JSON parse failed despite application/json. Body (first 400): %r",
                r.text[:400],
            )
            raise HTTPException(
                status_code=502, detail=f"Bad JSON from /api/chat/completions: {e}"
            )

    # SSE stream
    if "text/event-stream" in ctype or "stream" in ctype:
        text = r.text
        events = []
        for line in text.splitlines():
            line = line.strip()
            if not line or not line.startswith("data:"):
                continue
            chunk = line[5:].strip()
            if chunk == "[DONE]":
                break
            try:
                events.append(json.loads(chunk))
            except Exception:
                logger.debug("Non-JSON SSE line: %r", line)
        if events:
            return {"stream": events}
        logger.error(
            "SSE response had no JSON 'data:' lines. First 400: %r", text[:400]
        )
        raise HTTPException(
            status_code=502, detail="Empty/invalid SSE body from /api/chat/completions"
        )

    # NDJSON
    if "ndjson" in ctype:
        objs = []
        for line in r.text.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                objs.append(json.loads(line))
            except Exception:
                logger.debug("Non-JSON NDJSON line: %r", line[:200])
        if objs:
            return {"ndjson": objs}
        raise HTTPException(
            status_code=502, detail="Invalid NDJSON body from /api/chat/completions"
        )

    # text/plain or unknown content-type
    txt = r.text.strip()
    if txt:
        try:
            return json.loads(txt)
        except Exception:
            logger.warning(
                "Non-JSON response (ctype=%s). Returning raw_text. First 400: %r",
                ctype,
                txt[:400],
            )
            return {"raw_text": txt, "content_type": ctype or None}

    logger.error("Empty 200 OK response from /api/chat/completions")
    raise HTTPException(
        status_code=502, detail="Empty response from /api/chat/completions"
    )


File: utils\response_processor.py
--------------------------------------------------
Content of utils\response_processor.py:
# Response processing utilities
import json
import logging
from typing import Tuple, List, Any

logger = logging.getLogger(__name__)


def normalize_owui_response(owui: dict) -> Tuple[str, list]:
    """
    Returns (assistant_text, sources_list)

    Supports:
      - {"stream": [ { "sources":[... ] }, {chunk}, {chunk}, ... ] }
      - {"raw_text": "..."} (fallback from post_chat_completions)
      - {"ndjson": [...]}  (rare)
      - Plain {"choices":[...]} JSON (if OWUI ever returns full JSON)
    """
    text_parts: list[str] = []
    sources: list[Any] = []

    if not isinstance(owui, dict):
        return (str(owui), sources)

    # 1) Stream shape
    if "stream" in owui and isinstance(owui["stream"], list):
        for i, item in enumerate(owui["stream"]):
            # first element often contains retrieval sources
            if i == 0 and isinstance(item, dict) and "sources" in item:
                try:
                    sources = item["sources"]
                except Exception:
                    sources = []
            # subsequent chunks with token deltas
            if isinstance(item, dict):
                for ch in item.get("choices", []):
                    delta = (ch or {}).get("delta") or {}
                    c = delta.get("content")
                    if isinstance(c, str):
                        text_parts.append(c)
        return ("".join(text_parts).strip(), sources)

    # 2) Raw text fallback
    if "raw_text" in owui:
        return (str(owui["raw_text"]).strip(), sources)

    # 3) NDJSON fallback
    if "ndjson" in owui and isinstance(owui["ndjson"], list):
        for line in owui["ndjson"]:
            if isinstance(line, dict):
                content = (((line.get("choices") or [{}])[0]).get("delta") or {}).get(
                    "content"
                )
                if isinstance(content, str):
                    text_parts.append(content)
        return ("".join(text_parts).strip(), sources)

    # 4) OpenAI-like full JSON (unlikely via OWUI, but harmless)
    if "choices" in owui:
        try:
            content = (((owui.get("choices") or [{}])[0]).get("message") or {}).get(
                "content"
            )
            if isinstance(content, str):
                return (content.strip(), sources)
        except Exception:
            pass

    logger.debug("Response from GIA: %r", owui)

    # last resort: stringify
    return (json.dumps(owui, ensure_ascii=False), sources)


File: utils\security.py
--------------------------------------------------
Content of utils\security.py:
# Security and token utilities
from typing import Optional


def mask_token(token: str | None, show_last: int = 10) -> str | None:
    """
    Mask sensitive tokens for logging purposes.
    
    Args:
        token: The token to mask
        show_last: Number of characters to show at the end
        
    Returns:
        Masked token string or None if token is None
    """
    if not token:
        return None
    if len(token) <= show_last:
        return "*" * len(token)
    return "*" * (len(token) - show_last) + token[-show_last:]


File: utils\vacation_data.py
--------------------------------------------------
Content of utils\vacation_data.py:
# Vacation data models and utilities
from typing import Optional
from pydantic import BaseModel


class VacationResp(BaseModel):
    employee_id: Optional[str] = None
    starting_balance: Optional[float] = None
    current_balance: Optional[float] = None
    instructions: Optional[str] = None


File: utils\vantagepoint.py
--------------------------------------------------
Content of utils\vantagepoint.py:
# Vantagepoint API utilities for vacation and employee data
import httpx
import logging
import json
import os
import re
import xmltodict
from typing import Optional, Dict, Any
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

VP_BASE_URL = os.environ.get("VP_BASE_URL")
PROCEDURE = os.environ.get("VP_SP_GETVACATION")

async def get_vacation_days(payload: Dict[str, Any], token: Optional[str]) -> Optional[Dict[str, Any]]:
    """
    Get vacation days for a specific employee using the Vantagepoint API.
    
    Args:
        payload (dict): Request payload containing employee information
        token (str): Access token for Vantagepoint API
        
    Returns:
        dict: Parsed vacation data or None if the API call fails
        
    Raises:
        httpx.HTTPError: If the API call fails
    """
    access_token = token
    
    url = f"{VP_BASE_URL}/api/Utilities/InvokeCustom/{PROCEDURE}"
    
    logger.debug(f"[GET /get_vacation_days] Request URL: {url}")
    logger.debug(f"[GET /get_vacation_days] Payload: {payload}")
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Accept": "application/xml",
        "Content-Type": "application/json"
    }
    
    async with httpx.AsyncClient() as client:
        response = await client.post(url, headers=headers, json=payload)
        response.raise_for_status()
    
    xml = response.text
    # Remove leading/trailing quotes if present
    xml = xml.strip()
    if xml.startswith('"') and xml.endswith('"'):
        xml = xml[1:-1]
    
    # Handle escaped characters - decode them properly
    xml = xml.encode().decode('unicode_escape')
    
    # Remove the schema block
    xml = re.sub(r'<xs:schema.*?</xs:schema>', '', xml, flags=re.DOTALL)
    # Remove empty <Table></Table> elements
    xml = re.sub(r'<Table>\s*</Table>', '', xml, flags=re.DOTALL)
    # Remove any control characters (non-printable)
    xml = re.sub(r'[^\x09\x0A\x0D\x20-\x7E]+', '', xml)
    # Strip leading/trailing whitespace again
    xml = xml.strip()
    
    logger.debug(f"[GET /get_vacation_days] Cleaned XML: {xml[:500]}...")  # Log first 500 chars for brevity
    
    # Parse the XML to dict
    parsed_xml = xmltodict.parse(xml)
    
    # Extract vacation balance data and clean up field names
    try:
        # Navigate to the Table data
        new_dataset = parsed_xml.get('NewDataSet', {})
        table_data = new_dataset.get('Table', {})
        
        # Extract and clean up the vacation data
        vacation_data = {
            "employee_id": table_data.get('Employee'),
            "starting_balance": float(table_data.get('Starting_x0020_Balance', 0)) if table_data.get('Starting_x0020_Balance') else None,
            "current_balance": float(table_data.get('Current_x0020_Balance', 0)) if table_data.get('Current_x0020_Balance') else None
        }
        
        logger.debug(f"Extracted vacation data: {vacation_data}")
        return vacation_data
        
    except Exception as e:
        logger.error(f"Error parsing vacation XML data: {e}")
        logger.debug(f"Parsed XML structure: {parsed_xml}")
        # Return the raw parsed XML as fallback
        return parsed_xml


